[2024-06-05 17:14:25 root] (main.py 192): INFO Namespace(batch_size=256, epochs=3, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/home/shivam/datasets/imagenet', data_set='IMNET', inat_category='name', output_dir='/home/pranav/DiffRate/learnt/LSMS', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=32, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.5, granularity=4, load_compression_rate=False, warmup_compression_rate=False, distributed=False)
[2024-06-05 17:14:29 root] (main.py 258): INFO Creating model: vit_deit_small_patch16_224
[2024-06-05 17:14:33 root] (main.py 346): INFO number of params: 22050664
[2024-06-05 17:14:33 root] (main.py 392): INFO Start training for 3 epochs
[2024-06-05 17:14:55 root] (engine.py 136): INFO merge kept number:[197, 197, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101]
[2024-06-05 17:14:55 root] (utils.py 285): INFO Epoch: [0]  [   0/5004]  eta: 1 day, 6:05:36  lr_architecture: 0.010000  loss_cls: 4.0760 (4.0760)  loss_tome: 0.0069 (0.0069)  etrr_loss: 0.0133 (0.0133)  loss_flops: 0.0673 (0.0673)  flops: 2.7594 (2.7594)  grad_norm: 0.0530 (0.0530)  time: 21.6500  data: 1.9490  max mem: 10030
[2024-06-05 17:14:59 root] (utils.py 285): INFO Epoch: [0]  [  10/5004]  eta: 3:14:41  lr_architecture: 0.010000  loss_cls: 4.0760 (3.8913)  loss_tome: 0.0625 (0.0511)  etrr_loss: 0.0132 (0.0132)  loss_flops: 0.0683 (0.0689)  flops: 2.7613 (2.7625)  grad_norm: 0.0437 (0.0381)  time: 2.3391  data: 0.1778  max mem: 10157
[2024-06-05 17:15:03 root] (utils.py 285): INFO Epoch: [0]  [  20/5004]  eta: 1:57:58  lr_architecture: 0.010000  loss_cls: 3.6888 (3.7127)  loss_tome: 0.0625 (0.0565)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0710)  flops: 2.7659 (2.7664)  grad_norm: 0.0276 (0.0320)  time: 0.4088  data: 0.0006  max mem: 10160
[2024-06-05 17:15:07 root] (utils.py 285): INFO Epoch: [0]  [  30/5004]  eta: 1:30:40  lr_architecture: 0.010000  loss_cls: 3.6097 (3.6715)  loss_tome: 0.0625 (0.0585)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0703)  flops: 2.7659 (2.7650)  grad_norm: 0.0227 (0.0296)  time: 0.4089  data: 0.0005  max mem: 10164
[2024-06-05 17:15:11 root] (utils.py 285): INFO Epoch: [0]  [  40/5004]  eta: 1:16:39  lr_architecture: 0.010000  loss_cls: 3.5374 (3.5781)  loss_tome: 0.0625 (0.0595)  etrr_loss: 0.0134 (0.0132)  loss_flops: 0.0646 (0.0674)  flops: 2.7541 (2.7593)  grad_norm: 0.0193 (0.0271)  time: 0.4083  data: 0.0004  max mem: 10167
[2024-06-05 17:15:15 root] (utils.py 285): INFO Epoch: [0]  [  50/5004]  eta: 1:08:11  lr_architecture: 0.010000  loss_cls: 3.4514 (3.5608)  loss_tome: 0.0625 (0.0600)  etrr_loss: 0.0143 (0.0136)  loss_flops: 0.0550 (0.0641)  flops: 2.7346 (2.7525)  grad_norm: 0.0188 (0.0256)  time: 0.4104  data: 0.0005  max mem: 10171
[2024-06-05 17:15:20 root] (utils.py 285): INFO Epoch: [0]  [  60/5004]  eta: 1:02:31  lr_architecture: 0.010000  loss_cls: 3.4892 (3.5165)  loss_tome: 0.0625 (0.0605)  etrr_loss: 0.0155 (0.0140)  loss_flops: 0.0446 (0.0598)  flops: 2.7113 (2.7430)  grad_norm: 0.0193 (0.0245)  time: 0.4148  data: 0.0007  max mem: 10174
[2024-06-05 17:15:24 root] (utils.py 285): INFO Epoch: [0]  [  70/5004]  eta: 0:58:21  lr_architecture: 0.010000  loss_cls: 3.3038 (3.4595)  loss_tome: 0.0625 (0.0607)  etrr_loss: 0.0169 (0.0145)  loss_flops: 0.0301 (0.0554)  flops: 2.6735 (2.7325)  grad_norm: 0.0136 (0.0233)  time: 0.4138  data: 0.0008  max mem: 10176
[2024-06-05 17:15:28 root] (utils.py 285): INFO Epoch: [0]  [  80/5004]  eta: 0:55:13  lr_architecture: 0.010000  loss_cls: 3.2059 (3.4331)  loss_tome: 0.0625 (0.0610)  etrr_loss: 0.0181 (0.0151)  loss_flops: 0.0259 (0.0512)  flops: 2.6609 (2.7217)  grad_norm: 0.0138 (0.0223)  time: 0.4108  data: 0.0007  max mem: 10177
[2024-06-05 17:15:32 root] (utils.py 285): INFO Epoch: [0]  [  90/5004]  eta: 0:52:45  lr_architecture: 0.010000  loss_cls: 3.2654 (3.4055)  loss_tome: 0.0625 (0.0611)  etrr_loss: 0.0195 (0.0157)  loss_flops: 0.0185 (0.0471)  flops: 2.6358 (2.7106)  grad_norm: 0.0141 (0.0216)  time: 0.4115  data: 0.0007  max mem: 10178
[2024-06-05 17:15:36 root] (engine.py 136): INFO merge kept number:[197, 197, 133, 108, 84, 101, 84, 101, 101, 84, 84, 101]
[2024-06-05 17:15:36 root] (utils.py 285): INFO Epoch: [0]  [ 100/5004]  eta: 0:50:46  lr_architecture: 0.010000  loss_cls: 3.3717 (3.4100)  loss_tome: 0.0625 (0.0613)  etrr_loss: 0.0211 (0.0163)  loss_flops: 0.0104 (0.0434)  flops: 2.6022 (2.6993)  grad_norm: 0.0149 (0.0213)  time: 0.4119  data: 0.0008  max mem: 10186
[2024-06-05 17:15:40 root] (utils.py 285): INFO Epoch: [0]  [ 110/5004]  eta: 0:49:09  lr_architecture: 0.010000  loss_cls: 3.4734 (3.4057)  loss_tome: 0.0625 (0.0614)  etrr_loss: 0.0218 (0.0168)  loss_flops: 0.0091 (0.0403)  flops: 2.5955 (2.6898)  grad_norm: 0.0161 (0.0208)  time: 0.4139  data: 0.0007  max mem: 10191
[2024-06-05 17:15:44 root] (utils.py 285): INFO Epoch: [0]  [ 120/5004]  eta: 0:47:47  lr_architecture: 0.010000  loss_cls: 3.3803 (3.3995)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0215 (0.0171)  loss_flops: 0.0099 (0.0378)  flops: 2.5995 (2.6827)  grad_norm: 0.0124 (0.0202)  time: 0.4153  data: 0.0007  max mem: 10194
[2024-06-05 17:15:48 root] (utils.py 285): INFO Epoch: [0]  [ 130/5004]  eta: 0:46:36  lr_architecture: 0.010000  loss_cls: 3.2880 (3.3826)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0202 (0.0173)  loss_flops: 0.0148 (0.0365)  flops: 2.6218 (2.6796)  grad_norm: 0.0119 (0.0197)  time: 0.4132  data: 0.0007  max mem: 10196
[2024-06-05 17:15:53 root] (utils.py 285): INFO Epoch: [0]  [ 140/5004]  eta: 0:45:34  lr_architecture: 0.010000  loss_cls: 3.2572 (3.3687)  loss_tome: 0.0625 (0.0616)  etrr_loss: 0.0171 (0.0172)  loss_flops: 0.0258 (0.0364)  flops: 2.6606 (2.6802)  grad_norm: 0.0110 (0.0191)  time: 0.4118  data: 0.0006  max mem: 10197
[2024-06-05 17:15:57 root] (utils.py 285): INFO Epoch: [0]  [ 150/5004]  eta: 0:44:40  lr_architecture: 0.010000  loss_cls: 3.2506 (3.3501)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0154 (0.0171)  loss_flops: 0.0441 (0.0373)  flops: 2.7100 (2.6830)  grad_norm: 0.0089 (0.0184)  time: 0.4116  data: 0.0006  max mem: 10201
[2024-06-05 17:16:01 root] (utils.py 285): INFO Epoch: [0]  [ 160/5004]  eta: 0:43:53  lr_architecture: 0.010000  loss_cls: 3.2376 (3.3448)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0143 (0.0169)  loss_flops: 0.0531 (0.0387)  flops: 2.7305 (2.6869)  grad_norm: 0.0099 (0.0180)  time: 0.4120  data: 0.0006  max mem: 10201
[2024-06-05 17:16:13 root] (main.py 192): INFO Namespace(batch_size=256, epochs=3, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/home/shivam/datasets/imagenet', data_set='IMNET', inat_category='name', output_dir='/home/pranav/DiffRate/learnt/LSMS', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=32, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.5, granularity=4, load_compression_rate=False, warmup_compression_rate=False, distributed=False)
[2024-06-05 17:16:16 root] (main.py 258): INFO Creating model: vit_deit_small_patch16_224
[2024-06-05 17:16:21 root] (main.py 346): INFO number of params: 22050664
[2024-06-05 17:16:21 root] (main.py 392): INFO Start training for 3 epochs
[2024-06-05 17:16:43 root] (engine.py 136): INFO merge kept number:[197, 197, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101]
[2024-06-05 17:16:43 root] (utils.py 285): INFO Epoch: [0]  [   0/5004]  eta: 1 day, 6:06:02  lr_architecture: 0.010000  loss_cls: 4.0759 (4.0759)  loss_tome: 0.0069 (0.0069)  etrr_loss: 0.0133 (0.0133)  loss_flops: 0.0673 (0.0673)  flops: 2.7594 (2.7594)  grad_norm: 0.0530 (0.0530)  time: 21.6552  data: 0.4494  max mem: 10030
[2024-06-05 17:16:47 root] (utils.py 285): INFO Epoch: [0]  [  10/5004]  eta: 3:14:42  lr_architecture: 0.010000  loss_cls: 4.0759 (3.8913)  loss_tome: 0.0625 (0.0511)  etrr_loss: 0.0132 (0.0132)  loss_flops: 0.0683 (0.0689)  flops: 2.7613 (2.7625)  grad_norm: 0.0437 (0.0381)  time: 2.3393  data: 0.0413  max mem: 10157
[2024-06-05 17:16:51 root] (utils.py 285): INFO Epoch: [0]  [  20/5004]  eta: 1:57:56  lr_architecture: 0.010000  loss_cls: 3.6887 (3.7127)  loss_tome: 0.0625 (0.0565)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0710)  flops: 2.7659 (2.7664)  grad_norm: 0.0276 (0.0320)  time: 0.4080  data: 0.0005  max mem: 10160
[2024-06-05 17:16:55 root] (utils.py 285): INFO Epoch: [0]  [  30/5004]  eta: 1:30:41  lr_architecture: 0.010000  loss_cls: 3.6096 (3.6715)  loss_tome: 0.0625 (0.0585)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0703)  flops: 2.7659 (2.7650)  grad_norm: 0.0227 (0.0296)  time: 0.4092  data: 0.0005  max mem: 10164
[2024-06-05 17:16:59 root] (utils.py 285): INFO Epoch: [0]  [  40/5004]  eta: 1:16:47  lr_architecture: 0.010000  loss_cls: 3.5370 (3.5781)  loss_tome: 0.0625 (0.0595)  etrr_loss: 0.0134 (0.0132)  loss_flops: 0.0646 (0.0674)  flops: 2.7541 (2.7593)  grad_norm: 0.0193 (0.0271)  time: 0.4119  data: 0.0005  max mem: 10167
[2024-06-05 17:17:03 root] (utils.py 285): INFO Epoch: [0]  [  50/5004]  eta: 1:08:16  lr_architecture: 0.010000  loss_cls: 3.4552 (3.5609)  loss_tome: 0.0625 (0.0600)  etrr_loss: 0.0143 (0.0136)  loss_flops: 0.0541 (0.0638)  flops: 2.7327 (2.7519)  grad_norm: 0.0188 (0.0256)  time: 0.4128  data: 0.0007  max mem: 10172
[2024-06-05 17:17:07 root] (utils.py 285): INFO Epoch: [0]  [  60/5004]  eta: 1:02:32  lr_architecture: 0.010000  loss_cls: 3.4892 (3.5166)  loss_tome: 0.0625 (0.0605)  etrr_loss: 0.0155 (0.0141)  loss_flops: 0.0438 (0.0594)  flops: 2.7094 (2.7421)  grad_norm: 0.0194 (0.0245)  time: 0.4121  data: 0.0007  max mem: 10174
[2024-06-05 17:17:11 root] (utils.py 285): INFO Epoch: [0]  [  70/5004]  eta: 0:58:23  lr_architecture: 0.010000  loss_cls: 3.3035 (3.4596)  loss_tome: 0.0625 (0.0607)  etrr_loss: 0.0174 (0.0146)  loss_flops: 0.0301 (0.0549)  flops: 2.6735 (2.7314)  grad_norm: 0.0136 (0.0233)  time: 0.4121  data: 0.0007  max mem: 10176
[2024-06-05 17:17:16 root] (utils.py 285): INFO Epoch: [0]  [  80/5004]  eta: 0:55:14  lr_architecture: 0.010000  loss_cls: 3.2073 (3.4332)  loss_tome: 0.0625 (0.0610)  etrr_loss: 0.0182 (0.0151)  loss_flops: 0.0253 (0.0508)  flops: 2.6590 (2.7209)  grad_norm: 0.0138 (0.0223)  time: 0.4112  data: 0.0007  max mem: 10177
[2024-06-05 17:17:20 root] (utils.py 285): INFO Epoch: [0]  [  90/5004]  eta: 0:52:46  lr_architecture: 0.010000  loss_cls: 3.2732 (3.4059)  loss_tome: 0.0625 (0.0611)  etrr_loss: 0.0195 (0.0157)  loss_flops: 0.0185 (0.0469)  flops: 2.6358 (2.7100)  grad_norm: 0.0141 (0.0216)  time: 0.4109  data: 0.0006  max mem: 10180
[2024-06-05 17:17:24 root] (engine.py 136): INFO merge kept number:[197, 197, 133, 108, 85, 101, 85, 101, 101, 85, 85, 101]
[2024-06-05 17:17:24 root] (utils.py 285): INFO Epoch: [0]  [ 100/5004]  eta: 0:50:46  lr_architecture: 0.010000  loss_cls: 3.3637 (3.4101)  loss_tome: 0.0625 (0.0613)  etrr_loss: 0.0209 (0.0163)  loss_flops: 0.0123 (0.0433)  flops: 2.6108 (2.6993)  grad_norm: 0.0146 (0.0213)  time: 0.4113  data: 0.0005  max mem: 10182
[2024-06-05 17:17:28 root] (utils.py 285): INFO Epoch: [0]  [ 110/5004]  eta: 0:49:07  lr_architecture: 0.010000  loss_cls: 3.4528 (3.4055)  loss_tome: 0.0625 (0.0614)  etrr_loss: 0.0215 (0.0167)  loss_flops: 0.0100 (0.0402)  flops: 2.6002 (2.6901)  grad_norm: 0.0146 (0.0208)  time: 0.4109  data: 0.0005  max mem: 10190
[2024-06-05 17:17:32 root] (utils.py 285): INFO Epoch: [0]  [ 120/5004]  eta: 0:47:44  lr_architecture: 0.010000  loss_cls: 3.3649 (3.3995)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0217 (0.0172)  loss_flops: 0.0091 (0.0376)  flops: 2.5955 (2.6823)  grad_norm: 0.0121 (0.0202)  time: 0.4116  data: 0.0005  max mem: 10193
[2024-06-05 17:17:36 root] (utils.py 285): INFO Epoch: [0]  [ 130/5004]  eta: 0:46:33  lr_architecture: 0.010000  loss_cls: 3.2879 (3.3832)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0212 (0.0174)  loss_flops: 0.0111 (0.0357)  flops: 2.6054 (2.6769)  grad_norm: 0.0116 (0.0198)  time: 0.4121  data: 0.0005  max mem: 10196
[2024-06-05 17:17:40 root] (utils.py 285): INFO Epoch: [0]  [ 140/5004]  eta: 0:45:32  lr_architecture: 0.010000  loss_cls: 3.2682 (3.3700)  loss_tome: 0.0625 (0.0616)  etrr_loss: 0.0198 (0.0176)  loss_flops: 0.0163 (0.0345)  flops: 2.6277 (2.6738)  grad_norm: 0.0104 (0.0192)  time: 0.4120  data: 0.0006  max mem: 10197
[2024-06-05 17:17:44 root] (utils.py 285): INFO Epoch: [0]  [ 150/5004]  eta: 0:44:38  lr_architecture: 0.010000  loss_cls: 3.2682 (3.3524)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0188 (0.0176)  loss_flops: 0.0214 (0.0340)  flops: 2.6461 (2.6732)  grad_norm: 0.0099 (0.0186)  time: 0.4122  data: 0.0007  max mem: 10199
[2024-06-05 17:17:48 root] (utils.py 285): INFO Epoch: [0]  [ 160/5004]  eta: 0:43:51  lr_architecture: 0.010000  loss_cls: 3.2560 (3.3478)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0166 (0.0175)  loss_flops: 0.0335 (0.0340)  flops: 2.6830 (2.6740)  grad_norm: 0.0102 (0.0181)  time: 0.4120  data: 0.0007  max mem: 10203
[2024-06-05 17:17:53 root] (utils.py 285): INFO Epoch: [0]  [ 170/5004]  eta: 0:43:08  lr_architecture: 0.010000  loss_cls: 3.2323 (3.3342)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0163 (0.0174)  loss_flops: 0.0364 (0.0344)  flops: 2.6909 (2.6757)  grad_norm: 0.0087 (0.0175)  time: 0.4121  data: 0.0006  max mem: 10203
[2024-06-05 17:17:57 root] (utils.py 285): INFO Epoch: [0]  [ 180/5004]  eta: 0:42:30  lr_architecture: 0.010000  loss_cls: 3.1013 (3.3156)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0154 (0.0173)  loss_flops: 0.0438 (0.0353)  flops: 2.7094 (2.6782)  grad_norm: 0.0065 (0.0170)  time: 0.4120  data: 0.0006  max mem: 10205
[2024-06-05 17:18:01 root] (utils.py 285): INFO Epoch: [0]  [ 190/5004]  eta: 0:41:55  lr_architecture: 0.010000  loss_cls: 3.0197 (3.3100)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0143 (0.0171)  loss_flops: 0.0528 (0.0367)  flops: 2.7298 (2.6819)  grad_norm: 0.0067 (0.0166)  time: 0.4119  data: 0.0005  max mem: 10207
[2024-06-05 17:18:05 root] (engine.py 136): INFO merge kept number:[197, 197, 150, 125, 95, 101, 95, 101, 101, 95, 95, 101]
[2024-06-05 17:18:05 root] (utils.py 285): INFO Epoch: [0]  [ 200/5004]  eta: 0:41:24  lr_architecture: 0.010000  loss_cls: 2.9447 (3.2926)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0120 (0.0168)  loss_flops: 0.0701 (0.0392)  flops: 2.7648 (2.6877)  grad_norm: 0.0068 (0.0161)  time: 0.4121  data: 0.0005  max mem: 10208
[2024-06-05 17:18:09 root] (utils.py 285): INFO Epoch: [0]  [ 210/5004]  eta: 0:40:55  lr_architecture: 0.010000  loss_cls: 3.2100 (3.2831)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0104 (0.0165)  loss_flops: 0.0989 (0.0426)  flops: 2.8144 (2.6945)  grad_norm: 0.0065 (0.0157)  time: 0.4134  data: 0.0005  max mem: 10209
[2024-06-05 17:18:13 root] (utils.py 285): INFO Epoch: [0]  [ 220/5004]  eta: 0:40:28  lr_architecture: 0.010000  loss_cls: 3.2100 (3.2693)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0091 (0.0161)  loss_flops: 0.1208 (0.0462)  flops: 2.8476 (2.7015)  grad_norm: 0.0063 (0.0153)  time: 0.4132  data: 0.0005  max mem: 10209
[2024-06-05 17:18:17 root] (utils.py 285): INFO Epoch: [0]  [ 230/5004]  eta: 0:40:04  lr_architecture: 0.010000  loss_cls: 3.1228 (3.2606)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0091 (0.0158)  loss_flops: 0.1222 (0.0499)  flops: 2.8496 (2.7085)  grad_norm: 0.0063 (0.0150)  time: 0.4122  data: 0.0004  max mem: 10209
[2024-06-05 17:18:22 root] (utils.py 285): INFO Epoch: [0]  [ 240/5004]  eta: 0:39:41  lr_architecture: 0.010000  loss_cls: 3.1688 (3.2548)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0084 (0.0155)  loss_flops: 0.1341 (0.0538)  flops: 2.8662 (2.7155)  grad_norm: 0.0061 (0.0147)  time: 0.4124  data: 0.0005  max mem: 10210
[2024-06-05 17:18:26 root] (utils.py 285): INFO Epoch: [0]  [ 250/5004]  eta: 0:39:19  lr_architecture: 0.010000  loss_cls: 3.1688 (3.2431)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0077 (0.0152)  loss_flops: 0.1481 (0.0574)  flops: 2.8848 (2.7221)  grad_norm: 0.0059 (0.0144)  time: 0.4123  data: 0.0005  max mem: 10210
[2024-06-05 17:18:36 root] (main.py 192): INFO Namespace(batch_size=256, epochs=3, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/home/shivam/datasets/imagenet', data_set='IMNET', inat_category='name', output_dir='/home/pranav/DiffRate/learnt/LSMS', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=32, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.5, granularity=4, load_compression_rate=False, warmup_compression_rate=False, distributed=False)
[2024-06-05 17:18:39 root] (main.py 258): INFO Creating model: vit_deit_small_patch16_224
[2024-06-05 17:18:44 root] (main.py 346): INFO number of params: 22050664
[2024-06-05 17:18:44 root] (main.py 392): INFO Start training for 3 epochs
[2024-06-05 17:19:06 root] (engine.py 136): INFO merge kept number:[197, 197, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101]
[2024-06-05 17:19:06 root] (utils.py 285): INFO Epoch: [0]  [   0/5004]  eta: 1 day, 6:03:42  lr_architecture: 0.010000  loss_cls: 4.0759 (4.0759)  loss_tome: 0.0069 (0.0069)  etrr_loss: 0.0133 (0.0133)  loss_flops: 0.0673 (0.0673)  flops: 2.7594 (2.7594)  grad_norm: 0.0530 (0.0530)  time: 21.6271  data: 1.5611  max mem: 10030
[2024-06-05 17:19:10 root] (utils.py 285): INFO Epoch: [0]  [  10/5004]  eta: 3:14:32  lr_architecture: 0.010000  loss_cls: 4.0759 (3.8913)  loss_tome: 0.0625 (0.0511)  etrr_loss: 0.0132 (0.0132)  loss_flops: 0.0683 (0.0689)  flops: 2.7613 (2.7625)  grad_norm: 0.0437 (0.0381)  time: 2.3373  data: 0.1424  max mem: 10157
[2024-06-05 17:19:14 root] (utils.py 285): INFO Epoch: [0]  [  20/5004]  eta: 1:57:53  lr_architecture: 0.010000  loss_cls: 3.6888 (3.7127)  loss_tome: 0.0625 (0.0565)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0710)  flops: 2.7659 (2.7664)  grad_norm: 0.0276 (0.0320)  time: 0.4088  data: 0.0005  max mem: 10160
[2024-06-05 17:19:18 root] (utils.py 285): INFO Epoch: [0]  [  30/5004]  eta: 1:30:39  lr_architecture: 0.010000  loss_cls: 3.6096 (3.6715)  loss_tome: 0.0625 (0.0585)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0703)  flops: 2.7659 (2.7650)  grad_norm: 0.0227 (0.0296)  time: 0.4095  data: 0.0004  max mem: 10164
[2024-06-05 17:19:22 root] (utils.py 285): INFO Epoch: [0]  [  40/5004]  eta: 1:16:40  lr_architecture: 0.010000  loss_cls: 3.5372 (3.5781)  loss_tome: 0.0625 (0.0595)  etrr_loss: 0.0134 (0.0132)  loss_flops: 0.0646 (0.0674)  flops: 2.7541 (2.7593)  grad_norm: 0.0193 (0.0271)  time: 0.4097  data: 0.0004  max mem: 10167
[2024-06-05 17:19:26 root] (utils.py 285): INFO Epoch: [0]  [  50/5004]  eta: 1:08:15  lr_architecture: 0.010000  loss_cls: 3.4553 (3.5609)  loss_tome: 0.0625 (0.0600)  etrr_loss: 0.0143 (0.0136)  loss_flops: 0.0541 (0.0638)  flops: 2.7327 (2.7519)  grad_norm: 0.0188 (0.0256)  time: 0.4128  data: 0.0005  max mem: 10172
[2024-06-05 17:19:30 root] (utils.py 285): INFO Epoch: [0]  [  60/5004]  eta: 1:02:35  lr_architecture: 0.010000  loss_cls: 3.4892 (3.5166)  loss_tome: 0.0625 (0.0605)  etrr_loss: 0.0155 (0.0141)  loss_flops: 0.0438 (0.0593)  flops: 2.7093 (2.7418)  grad_norm: 0.0194 (0.0245)  time: 0.4170  data: 0.0007  max mem: 10174
[2024-06-05 17:19:34 root] (utils.py 285): INFO Epoch: [0]  [  70/5004]  eta: 0:58:27  lr_architecture: 0.010000  loss_cls: 3.3041 (3.4596)  loss_tome: 0.0625 (0.0607)  etrr_loss: 0.0174 (0.0146)  loss_flops: 0.0301 (0.0549)  flops: 2.6735 (2.7312)  grad_norm: 0.0136 (0.0233)  time: 0.4155  data: 0.0007  max mem: 10176
[2024-06-05 17:19:39 root] (utils.py 285): INFO Epoch: [0]  [  80/5004]  eta: 0:55:17  lr_architecture: 0.010000  loss_cls: 3.2059 (3.4332)  loss_tome: 0.0625 (0.0610)  etrr_loss: 0.0182 (0.0151)  loss_flops: 0.0226 (0.0507)  flops: 2.6504 (2.7206)  grad_norm: 0.0138 (0.0223)  time: 0.4118  data: 0.0006  max mem: 10177
[2024-06-05 17:19:43 root] (utils.py 285): INFO Epoch: [0]  [  90/5004]  eta: 0:52:50  lr_architecture: 0.010000  loss_cls: 3.2733 (3.4059)  loss_tome: 0.0625 (0.0611)  etrr_loss: 0.0195 (0.0157)  loss_flops: 0.0185 (0.0467)  flops: 2.6358 (2.7096)  grad_norm: 0.0141 (0.0216)  time: 0.4122  data: 0.0006  max mem: 10180
[2024-06-05 17:19:47 root] (engine.py 136): INFO merge kept number:[197, 197, 133, 108, 85, 101, 85, 101, 101, 85, 85, 101]
[2024-06-05 17:19:47 root] (utils.py 285): INFO Epoch: [0]  [ 100/5004]  eta: 0:50:50  lr_architecture: 0.010000  loss_cls: 3.3637 (3.4101)  loss_tome: 0.0625 (0.0613)  etrr_loss: 0.0209 (0.0163)  loss_flops: 0.0123 (0.0432)  flops: 2.6108 (2.6991)  grad_norm: 0.0146 (0.0213)  time: 0.4124  data: 0.0006  max mem: 10182
[2024-06-05 17:19:51 root] (utils.py 285): INFO Epoch: [0]  [ 110/5004]  eta: 0:49:11  lr_architecture: 0.010000  loss_cls: 3.4527 (3.4055)  loss_tome: 0.0625 (0.0614)  etrr_loss: 0.0215 (0.0168)  loss_flops: 0.0100 (0.0401)  flops: 2.6002 (2.6899)  grad_norm: 0.0146 (0.0208)  time: 0.4112  data: 0.0005  max mem: 10190
[2024-06-05 17:19:55 root] (utils.py 285): INFO Epoch: [0]  [ 120/5004]  eta: 0:47:47  lr_architecture: 0.010000  loss_cls: 3.3644 (3.3995)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0218 (0.0172)  loss_flops: 0.0091 (0.0375)  flops: 2.5955 (2.6819)  grad_norm: 0.0121 (0.0202)  time: 0.4114  data: 0.0005  max mem: 10193
[2024-06-05 17:19:59 root] (utils.py 285): INFO Epoch: [0]  [ 130/5004]  eta: 0:46:36  lr_architecture: 0.010000  loss_cls: 3.2880 (3.3833)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0212 (0.0175)  loss_flops: 0.0111 (0.0356)  flops: 2.6054 (2.6766)  grad_norm: 0.0116 (0.0198)  time: 0.4116  data: 0.0005  max mem: 10196
[2024-06-05 17:20:03 root] (utils.py 285): INFO Epoch: [0]  [ 140/5004]  eta: 0:45:35  lr_architecture: 0.010000  loss_cls: 3.2684 (3.3700)  loss_tome: 0.0625 (0.0616)  etrr_loss: 0.0198 (0.0176)  loss_flops: 0.0163 (0.0344)  flops: 2.6277 (2.6735)  grad_norm: 0.0104 (0.0192)  time: 0.4116  data: 0.0005  max mem: 10197
[2024-06-05 17:20:07 root] (utils.py 285): INFO Epoch: [0]  [ 150/5004]  eta: 0:44:40  lr_architecture: 0.010000  loss_cls: 3.2684 (3.3525)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0188 (0.0176)  loss_flops: 0.0214 (0.0339)  flops: 2.6461 (2.6729)  grad_norm: 0.0099 (0.0186)  time: 0.4115  data: 0.0005  max mem: 10199
[2024-06-05 17:20:11 root] (utils.py 285): INFO Epoch: [0]  [ 160/5004]  eta: 0:43:53  lr_architecture: 0.010000  loss_cls: 3.2560 (3.3477)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0166 (0.0175)  loss_flops: 0.0335 (0.0340)  flops: 2.6830 (2.6738)  grad_norm: 0.0103 (0.0181)  time: 0.4115  data: 0.0005  max mem: 10203
[2024-06-05 17:20:16 root] (utils.py 285): INFO Epoch: [0]  [ 170/5004]  eta: 0:43:10  lr_architecture: 0.010000  loss_cls: 3.2323 (3.3337)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0163 (0.0174)  loss_flops: 0.0364 (0.0345)  flops: 2.6909 (2.6757)  grad_norm: 0.0087 (0.0175)  time: 0.4115  data: 0.0005  max mem: 10204
[2024-06-05 17:20:20 root] (utils.py 285): INFO Epoch: [0]  [ 180/5004]  eta: 0:42:31  lr_architecture: 0.010000  loss_cls: 3.1013 (3.3151)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0153 (0.0173)  loss_flops: 0.0447 (0.0352)  flops: 2.7113 (2.6780)  grad_norm: 0.0066 (0.0170)  time: 0.4117  data: 0.0005  max mem: 10206
[2024-06-05 17:20:24 root] (utils.py 285): INFO Epoch: [0]  [ 190/5004]  eta: 0:41:57  lr_architecture: 0.010000  loss_cls: 3.0146 (3.3095)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0142 (0.0171)  loss_flops: 0.0537 (0.0364)  flops: 2.7318 (2.6813)  grad_norm: 0.0070 (0.0166)  time: 0.4122  data: 0.0005  max mem: 10208
[2024-06-05 17:20:28 root] (engine.py 136): INFO merge kept number:[197, 197, 150, 125, 94, 101, 94, 101, 101, 94, 94, 101]
[2024-06-05 17:20:28 root] (utils.py 285): INFO Epoch: [0]  [ 200/5004]  eta: 0:41:25  lr_architecture: 0.010000  loss_cls: 2.9502 (3.2923)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0133 (0.0169)  loss_flops: 0.0626 (0.0384)  flops: 2.7503 (2.6861)  grad_norm: 0.0072 (0.0162)  time: 0.4122  data: 0.0005  max mem: 10208
[2024-06-05 17:20:32 root] (utils.py 285): INFO Epoch: [0]  [ 210/5004]  eta: 0:40:56  lr_architecture: 0.010000  loss_cls: 3.2139 (3.2829)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0110 (0.0166)  loss_flops: 0.0899 (0.0413)  flops: 2.7999 (2.6921)  grad_norm: 0.0065 (0.0157)  time: 0.4124  data: 0.0006  max mem: 10209
[2024-06-05 17:20:36 root] (utils.py 285): INFO Epoch: [0]  [ 220/5004]  eta: 0:40:29  lr_architecture: 0.010000  loss_cls: 3.2139 (3.2692)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0103 (0.0163)  loss_flops: 0.1014 (0.0443)  flops: 2.8184 (2.6983)  grad_norm: 0.0060 (0.0153)  time: 0.4131  data: 0.0007  max mem: 10210
[2024-06-05 17:20:40 root] (utils.py 285): INFO Epoch: [0]  [ 230/5004]  eta: 0:40:05  lr_architecture: 0.010000  loss_cls: 3.1287 (3.2608)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0096 (0.0160)  loss_flops: 0.1122 (0.0473)  flops: 2.8350 (2.7043)  grad_norm: 0.0066 (0.0150)  time: 0.4131  data: 0.0006  max mem: 10210
[2024-06-05 17:20:44 root] (utils.py 285): INFO Epoch: [0]  [ 240/5004]  eta: 0:39:42  lr_architecture: 0.010000  loss_cls: 3.1683 (3.2553)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0090 (0.0157)  loss_flops: 0.1236 (0.0505)  flops: 2.8516 (2.7105)  grad_norm: 0.0074 (0.0148)  time: 0.4128  data: 0.0005  max mem: 10211
[2024-06-05 17:20:49 root] (utils.py 285): INFO Epoch: [0]  [ 250/5004]  eta: 0:39:20  lr_architecture: 0.010000  loss_cls: 3.1683 (3.2435)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0087 (0.0154)  loss_flops: 0.1264 (0.0536)  flops: 2.8556 (2.7164)  grad_norm: 0.0069 (0.0144)  time: 0.4130  data: 0.0006  max mem: 10211
[2024-06-05 17:20:53 root] (utils.py 285): INFO Epoch: [0]  [ 260/5004]  eta: 0:39:00  lr_architecture: 0.010000  loss_cls: 3.1053 (3.2305)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0087 (0.0151)  loss_flops: 0.1279 (0.0563)  flops: 2.8576 (2.7216)  grad_norm: 0.0052 (0.0141)  time: 0.4130  data: 0.0005  max mem: 10213
[2024-06-05 17:21:03 root] (main.py 192): INFO Namespace(batch_size=256, epochs=3, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/home/shivam/datasets/imagenet', data_set='IMNET', inat_category='name', output_dir='/home/pranav/DiffRate/learnt/LSMS', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=32, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.5, granularity=4, load_compression_rate=False, warmup_compression_rate=False, distributed=False)
[2024-06-05 17:21:06 root] (main.py 258): INFO Creating model: vit_deit_small_patch16_224
[2024-06-05 17:21:11 root] (main.py 346): INFO number of params: 22050664
[2024-06-05 17:21:11 root] (main.py 392): INFO Start training for 3 epochs
[2024-06-05 17:21:33 root] (engine.py 136): INFO merge kept number:[197, 197, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101]
[2024-06-05 17:21:33 root] (utils.py 285): INFO Epoch: [0]  [   0/5004]  eta: 1 day, 6:07:44  lr_architecture: 0.010000  loss_cls: 4.0759 (4.0759)  loss_tome: 0.0069 (0.0069)  etrr_loss: 0.0133 (0.0133)  loss_flops: 0.0673 (0.0673)  flops: 2.7594 (2.7594)  grad_norm: 0.0530 (0.0530)  time: 21.6755  data: 4.1389  max mem: 10030
[2024-06-05 17:21:37 root] (utils.py 285): INFO Epoch: [0]  [  10/5004]  eta: 3:14:59  lr_architecture: 0.010000  loss_cls: 4.0759 (3.8913)  loss_tome: 0.0625 (0.0511)  etrr_loss: 0.0132 (0.0132)  loss_flops: 0.0683 (0.0689)  flops: 2.7613 (2.7625)  grad_norm: 0.0437 (0.0381)  time: 2.3426  data: 0.3768  max mem: 10157
[2024-06-05 17:21:41 root] (utils.py 285): INFO Epoch: [0]  [  20/5004]  eta: 1:58:12  lr_architecture: 0.010000  loss_cls: 3.6888 (3.7127)  loss_tome: 0.0625 (0.0565)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0710)  flops: 2.7659 (2.7664)  grad_norm: 0.0276 (0.0320)  time: 0.4104  data: 0.0006  max mem: 10160
[2024-06-05 17:21:45 root] (utils.py 285): INFO Epoch: [0]  [  30/5004]  eta: 1:30:55  lr_architecture: 0.010000  loss_cls: 3.6097 (3.6715)  loss_tome: 0.0625 (0.0585)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0703)  flops: 2.7659 (2.7650)  grad_norm: 0.0227 (0.0296)  time: 0.4116  data: 0.0006  max mem: 10164
[2024-06-05 17:21:49 root] (utils.py 285): INFO Epoch: [0]  [  40/5004]  eta: 1:16:55  lr_architecture: 0.010000  loss_cls: 3.5374 (3.5781)  loss_tome: 0.0625 (0.0595)  etrr_loss: 0.0134 (0.0132)  loss_flops: 0.0646 (0.0674)  flops: 2.7541 (2.7593)  grad_norm: 0.0193 (0.0271)  time: 0.4119  data: 0.0006  max mem: 10167
[2024-06-05 17:21:54 root] (utils.py 285): INFO Epoch: [0]  [  50/5004]  eta: 1:08:23  lr_architecture: 0.010000  loss_cls: 3.4552 (3.5609)  loss_tome: 0.0625 (0.0600)  etrr_loss: 0.0143 (0.0136)  loss_flops: 0.0550 (0.0640)  flops: 2.7346 (2.7522)  grad_norm: 0.0188 (0.0256)  time: 0.4123  data: 0.0007  max mem: 10172
[2024-06-05 17:21:58 root] (utils.py 285): INFO Epoch: [0]  [  60/5004]  eta: 1:02:38  lr_architecture: 0.010000  loss_cls: 3.4892 (3.5165)  loss_tome: 0.0625 (0.0605)  etrr_loss: 0.0155 (0.0140)  loss_flops: 0.0438 (0.0597)  flops: 2.7094 (2.7428)  grad_norm: 0.0194 (0.0245)  time: 0.4124  data: 0.0007  max mem: 10174
[2024-06-05 17:22:02 root] (utils.py 285): INFO Epoch: [0]  [  70/5004]  eta: 0:58:28  lr_architecture: 0.010000  loss_cls: 3.3038 (3.4594)  loss_tome: 0.0625 (0.0607)  etrr_loss: 0.0169 (0.0145)  loss_flops: 0.0301 (0.0553)  flops: 2.6735 (2.7322)  grad_norm: 0.0136 (0.0233)  time: 0.4124  data: 0.0006  max mem: 10176
[2024-06-05 17:22:06 root] (utils.py 285): INFO Epoch: [0]  [  80/5004]  eta: 0:55:22  lr_architecture: 0.010000  loss_cls: 3.2059 (3.4330)  loss_tome: 0.0625 (0.0610)  etrr_loss: 0.0181 (0.0151)  loss_flops: 0.0253 (0.0511)  flops: 2.6590 (2.7217)  grad_norm: 0.0138 (0.0223)  time: 0.4144  data: 0.0007  max mem: 10177
[2024-06-05 17:22:10 root] (utils.py 285): INFO Epoch: [0]  [  90/5004]  eta: 0:52:54  lr_architecture: 0.010000  loss_cls: 3.2654 (3.4055)  loss_tome: 0.0625 (0.0611)  etrr_loss: 0.0195 (0.0157)  loss_flops: 0.0185 (0.0471)  flops: 2.6358 (2.7106)  grad_norm: 0.0141 (0.0216)  time: 0.4145  data: 0.0007  max mem: 10178
[2024-06-05 17:22:14 root] (engine.py 136): INFO merge kept number:[197, 197, 133, 108, 84, 101, 84, 101, 101, 84, 84, 101]
[2024-06-05 17:22:14 root] (utils.py 285): INFO Epoch: [0]  [ 100/5004]  eta: 0:50:54  lr_architecture: 0.010000  loss_cls: 3.3718 (3.4097)  loss_tome: 0.0625 (0.0613)  etrr_loss: 0.0211 (0.0162)  loss_flops: 0.0118 (0.0434)  flops: 2.6088 (2.6995)  grad_norm: 0.0149 (0.0213)  time: 0.4125  data: 0.0007  max mem: 10186
[2024-06-05 17:22:18 root] (utils.py 285): INFO Epoch: [0]  [ 110/5004]  eta: 0:49:15  lr_architecture: 0.010000  loss_cls: 3.4525 (3.4052)  loss_tome: 0.0625 (0.0614)  etrr_loss: 0.0218 (0.0168)  loss_flops: 0.0091 (0.0403)  flops: 2.5955 (2.6899)  grad_norm: 0.0161 (0.0208)  time: 0.4121  data: 0.0007  max mem: 10190
[2024-06-05 17:22:22 root] (utils.py 285): INFO Epoch: [0]  [ 120/5004]  eta: 0:47:52  lr_architecture: 0.010000  loss_cls: 3.3647 (3.3993)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0220 (0.0172)  loss_flops: 0.0084 (0.0376)  flops: 2.5916 (2.6817)  grad_norm: 0.0121 (0.0203)  time: 0.4124  data: 0.0007  max mem: 10193
[2024-06-05 17:22:27 root] (utils.py 285): INFO Epoch: [0]  [ 130/5004]  eta: 0:46:41  lr_architecture: 0.010000  loss_cls: 3.2880 (3.3830)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0212 (0.0175)  loss_flops: 0.0111 (0.0357)  flops: 2.6054 (2.6764)  grad_norm: 0.0116 (0.0197)  time: 0.4131  data: 0.0008  max mem: 10196
[2024-06-05 17:22:31 root] (utils.py 285): INFO Epoch: [0]  [ 140/5004]  eta: 0:45:39  lr_architecture: 0.010000  loss_cls: 3.2683 (3.3698)  loss_tome: 0.0625 (0.0616)  etrr_loss: 0.0198 (0.0176)  loss_flops: 0.0163 (0.0345)  flops: 2.6277 (2.6734)  grad_norm: 0.0104 (0.0192)  time: 0.4128  data: 0.0008  max mem: 10197
[2024-06-05 17:22:35 root] (utils.py 285): INFO Epoch: [0]  [ 150/5004]  eta: 0:44:45  lr_architecture: 0.010000  loss_cls: 3.2683 (3.3523)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0188 (0.0176)  loss_flops: 0.0214 (0.0339)  flops: 2.6461 (2.6725)  grad_norm: 0.0099 (0.0186)  time: 0.4121  data: 0.0008  max mem: 10199
[2024-06-05 17:22:39 root] (utils.py 285): INFO Epoch: [0]  [ 160/5004]  eta: 0:43:57  lr_architecture: 0.010000  loss_cls: 3.2560 (3.3479)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0168 (0.0176)  loss_flops: 0.0284 (0.0339)  flops: 2.6685 (2.6734)  grad_norm: 0.0103 (0.0181)  time: 0.4120  data: 0.0007  max mem: 10202
[2024-06-05 17:22:43 root] (utils.py 285): INFO Epoch: [0]  [ 170/5004]  eta: 0:43:14  lr_architecture: 0.010000  loss_cls: 3.2322 (3.3344)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0163 (0.0175)  loss_flops: 0.0357 (0.0342)  flops: 2.6889 (2.6748)  grad_norm: 0.0090 (0.0175)  time: 0.4117  data: 0.0006  max mem: 10204
[2024-06-05 17:22:47 root] (utils.py 285): INFO Epoch: [0]  [ 180/5004]  eta: 0:42:35  lr_architecture: 0.010000  loss_cls: 3.1128 (3.3158)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0154 (0.0173)  loss_flops: 0.0438 (0.0349)  flops: 2.7094 (2.6771)  grad_norm: 0.0066 (0.0170)  time: 0.4119  data: 0.0006  max mem: 10205
[2024-06-05 17:22:51 root] (utils.py 285): INFO Epoch: [0]  [ 190/5004]  eta: 0:42:00  lr_architecture: 0.010000  loss_cls: 3.0219 (3.3104)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0143 (0.0172)  loss_flops: 0.0528 (0.0360)  flops: 2.7298 (2.6802)  grad_norm: 0.0069 (0.0166)  time: 0.4124  data: 0.0006  max mem: 10208
[2024-06-05 17:22:56 root] (engine.py 136): INFO merge kept number:[197, 197, 150, 125, 94, 101, 94, 101, 101, 94, 94, 101]
[2024-06-05 17:22:56 root] (utils.py 285): INFO Epoch: [0]  [ 200/5004]  eta: 0:41:29  lr_architecture: 0.010000  loss_cls: 2.9554 (3.2933)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0133 (0.0169)  loss_flops: 0.0626 (0.0380)  flops: 2.7503 (2.6849)  grad_norm: 0.0066 (0.0161)  time: 0.4135  data: 0.0007  max mem: 10208
[2024-06-05 17:23:00 root] (utils.py 285): INFO Epoch: [0]  [ 210/5004]  eta: 0:41:00  lr_architecture: 0.010000  loss_cls: 3.2250 (3.2837)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0111 (0.0166)  loss_flops: 0.0899 (0.0409)  flops: 2.7999 (2.6910)  grad_norm: 0.0062 (0.0157)  time: 0.4139  data: 0.0007  max mem: 10209
[2024-06-05 17:23:04 root] (utils.py 285): INFO Epoch: [0]  [ 220/5004]  eta: 0:40:33  lr_architecture: 0.010000  loss_cls: 3.2250 (3.2701)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0096 (0.0163)  loss_flops: 0.1122 (0.0442)  flops: 2.8350 (2.6976)  grad_norm: 0.0071 (0.0153)  time: 0.4131  data: 0.0006  max mem: 10209
[2024-06-05 17:23:08 root] (utils.py 285): INFO Epoch: [0]  [ 230/5004]  eta: 0:40:08  lr_architecture: 0.010000  loss_cls: 3.1134 (3.2616)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0095 (0.0160)  loss_flops: 0.1135 (0.0474)  flops: 2.8370 (2.7040)  grad_norm: 0.0066 (0.0150)  time: 0.4128  data: 0.0005  max mem: 10211
[2024-06-05 17:23:12 root] (utils.py 285): INFO Epoch: [0]  [ 240/5004]  eta: 0:39:45  lr_architecture: 0.010000  loss_cls: 3.1797 (3.2559)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0087 (0.0157)  loss_flops: 0.1264 (0.0512)  flops: 2.8555 (2.7110)  grad_norm: 0.0065 (0.0147)  time: 0.4130  data: 0.0005  max mem: 10212
[2024-06-05 17:23:16 root] (utils.py 285): INFO Epoch: [0]  [ 250/5004]  eta: 0:39:24  lr_architecture: 0.010000  loss_cls: 3.1797 (3.2439)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0075 (0.0153)  loss_flops: 0.1400 (0.0553)  flops: 2.8741 (2.7182)  grad_norm: 0.0056 (0.0144)  time: 0.4134  data: 0.0006  max mem: 10213
[2024-06-05 17:23:20 root] (utils.py 285): INFO Epoch: [0]  [ 260/5004]  eta: 0:39:03  lr_architecture: 0.010000  loss_cls: 3.1043 (3.2306)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0074 (0.0150)  loss_flops: 0.1542 (0.0591)  flops: 2.8927 (2.7249)  grad_norm: 0.0053 (0.0141)  time: 0.4133  data: 0.0006  max mem: 10213
[2024-06-05 17:23:24 root] (utils.py 285): INFO Epoch: [0]  [ 270/5004]  eta: 0:38:44  lr_architecture: 0.010000  loss_cls: 2.8578 (3.2217)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0074 (0.0148)  loss_flops: 0.1445 (0.0622)  flops: 2.8801 (2.7306)  grad_norm: 0.0061 (0.0139)  time: 0.4135  data: 0.0007  max mem: 10214
[2024-06-05 17:23:29 root] (utils.py 285): INFO Epoch: [0]  [ 280/5004]  eta: 0:38:27  lr_architecture: 0.010000  loss_cls: 3.3059 (3.2224)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0079 (0.0145)  loss_flops: 0.1445 (0.0655)  flops: 2.8801 (2.7364)  grad_norm: 0.0063 (0.0136)  time: 0.4154  data: 0.0008  max mem: 10217
[2024-06-05 17:23:33 root] (utils.py 285): INFO Epoch: [0]  [ 290/5004]  eta: 0:38:11  lr_architecture: 0.010000  loss_cls: 3.2302 (3.2090)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0072 (0.0143)  loss_flops: 0.1606 (0.0689)  flops: 2.9007 (2.7421)  grad_norm: 0.0063 (0.0134)  time: 0.4196  data: 0.0011  max mem: 10217
[2024-06-05 17:23:37 root] (engine.py 136): INFO merge kept number:[197, 197, 160, 132, 100, 101, 100, 101, 101, 100, 100, 101]
[2024-06-05 17:23:37 root] (utils.py 285): INFO Epoch: [0]  [ 300/5004]  eta: 0:37:55  lr_architecture: 0.010000  loss_cls: 2.8944 (3.1997)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0070 (0.0140)  loss_flops: 0.1638 (0.0722)  flops: 2.9047 (2.7477)  grad_norm: 0.0061 (0.0131)  time: 0.4176  data: 0.0009  max mem: 10217
[2024-06-05 17:23:41 root] (utils.py 285): INFO Epoch: [0]  [ 310/5004]  eta: 0:37:40  lr_architecture: 0.010000  loss_cls: 2.9418 (3.1928)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0065 (0.0138)  loss_flops: 0.1775 (0.0757)  flops: 2.9213 (2.7535)  grad_norm: 0.0056 (0.0129)  time: 0.4131  data: 0.0006  max mem: 10217
[2024-06-05 17:23:45 root] (utils.py 285): INFO Epoch: [0]  [ 320/5004]  eta: 0:37:26  lr_architecture: 0.010000  loss_cls: 3.2809 (3.2009)  loss_tome: 0.0625 (0.0635)  etrr_loss: 0.0062 (0.0135)  loss_flops: 0.1842 (0.0791)  flops: 2.9292 (2.7590)  grad_norm: 0.0062 (0.0128)  time: 0.4167  data: 0.0005  max mem: 10280
[2024-06-05 17:23:50 root] (utils.py 285): INFO Epoch: [0]  [ 330/5004]  eta: 0:37:13  lr_architecture: 0.010000  loss_cls: 3.2834 (3.1952)  loss_tome: 0.1111 (0.0649)  etrr_loss: 0.0065 (0.0133)  loss_flops: 0.1751 (0.0819)  flops: 2.9184 (2.7636)  grad_norm: 0.0060 (0.0126)  time: 0.4207  data: 0.0003  max mem: 10286
[2024-06-05 17:23:54 root] (utils.py 285): INFO Epoch: [0]  [ 340/5004]  eta: 0:37:00  lr_architecture: 0.010000  loss_cls: 3.2108 (3.1977)  loss_tome: 0.1111 (0.0663)  etrr_loss: 0.0068 (0.0131)  loss_flops: 0.1654 (0.0843)  flops: 2.9067 (2.7678)  grad_norm: 0.0059 (0.0124)  time: 0.4213  data: 0.0003  max mem: 10290
[2024-06-05 17:23:58 root] (utils.py 285): INFO Epoch: [0]  [ 350/5004]  eta: 0:36:48  lr_architecture: 0.010000  loss_cls: 3.2586 (3.1956)  loss_tome: 0.1111 (0.0675)  etrr_loss: 0.0070 (0.0130)  loss_flops: 0.1609 (0.0863)  flops: 2.9011 (2.7714)  grad_norm: 0.0060 (0.0123)  time: 0.4217  data: 0.0003  max mem: 10293
[2024-06-05 17:24:02 root] (utils.py 285): INFO Epoch: [0]  [ 360/5004]  eta: 0:36:37  lr_architecture: 0.010000  loss_cls: 3.1458 (3.1925)  loss_tome: 0.1111 (0.0687)  etrr_loss: 0.0072 (0.0128)  loss_flops: 0.1561 (0.0883)  flops: 2.8951 (2.7749)  grad_norm: 0.0062 (0.0121)  time: 0.4220  data: 0.0003  max mem: 10296
[2024-06-05 17:24:07 root] (utils.py 285): INFO Epoch: [0]  [ 370/5004]  eta: 0:36:27  lr_architecture: 0.010000  loss_cls: 3.1110 (3.1872)  loss_tome: 0.1111 (0.0699)  etrr_loss: 0.0069 (0.0126)  loss_flops: 0.1618 (0.0906)  flops: 2.9022 (2.7787)  grad_norm: 0.0053 (0.0120)  time: 0.4264  data: 0.0005  max mem: 10300
[2024-06-05 17:24:11 root] (utils.py 285): INFO Epoch: [0]  [ 380/5004]  eta: 0:36:16  lr_architecture: 0.010000  loss_cls: 3.1544 (3.1827)  loss_tome: 0.1111 (0.0710)  etrr_loss: 0.0062 (0.0125)  loss_flops: 0.1804 (0.0930)  flops: 2.9248 (2.7826)  grad_norm: 0.0050 (0.0118)  time: 0.4267  data: 0.0005  max mem: 10300
[2024-06-05 17:24:15 root] (utils.py 285): INFO Epoch: [0]  [ 390/5004]  eta: 0:36:06  lr_architecture: 0.010000  loss_cls: 3.1544 (3.1757)  loss_tome: 0.1111 (0.0720)  etrr_loss: 0.0062 (0.0123)  loss_flops: 0.1804 (0.0951)  flops: 2.9248 (2.7861)  grad_norm: 0.0045 (0.0117)  time: 0.4220  data: 0.0003  max mem: 10300
[2024-06-05 17:24:19 root] (engine.py 136): INFO merge kept number:[197, 197, 168, 146, 118, 94, 94, 101, 101, 94, 94, 101]
[2024-06-05 17:24:19 root] (utils.py 285): INFO Epoch: [0]  [ 400/5004]  eta: 0:35:55  lr_architecture: 0.010000  loss_cls: 3.2962 (3.1780)  loss_tome: 0.1111 (0.0730)  etrr_loss: 0.0063 (0.0122)  loss_flops: 0.1765 (0.0972)  flops: 2.9201 (2.7894)  grad_norm: 0.0050 (0.0116)  time: 0.4219  data: 0.0003  max mem: 10303
[2024-06-05 17:24:23 root] (utils.py 285): INFO Epoch: [0]  [ 410/5004]  eta: 0:35:46  lr_architecture: 0.010000  loss_cls: 3.3658 (3.1800)  loss_tome: 0.1111 (0.0739)  etrr_loss: 0.0062 (0.0120)  loss_flops: 0.1798 (0.0992)  flops: 2.9240 (2.7928)  grad_norm: 0.0049 (0.0114)  time: 0.4224  data: 0.0004  max mem: 10304
[2024-06-05 17:24:28 root] (utils.py 285): INFO Epoch: [0]  [ 420/5004]  eta: 0:35:36  lr_architecture: 0.010000  loss_cls: 3.1652 (3.1768)  loss_tome: 0.1111 (0.0748)  etrr_loss: 0.0060 (0.0119)  loss_flops: 0.1849 (0.1014)  flops: 2.9300 (2.7961)  grad_norm: 0.0048 (0.0112)  time: 0.4224  data: 0.0003  max mem: 10306
[2024-06-05 17:24:32 root] (utils.py 285): INFO Epoch: [0]  [ 430/5004]  eta: 0:35:27  lr_architecture: 0.010000  loss_cls: 3.2810 (3.1806)  loss_tome: 0.1111 (0.0756)  etrr_loss: 0.0055 (0.0117)  loss_flops: 0.1995 (0.1039)  flops: 2.9466 (2.8000)  grad_norm: 0.0051 (0.0111)  time: 0.4222  data: 0.0003  max mem: 10307
[2024-06-05 17:24:36 root] (utils.py 285): INFO Epoch: [0]  [ 440/5004]  eta: 0:35:18  lr_architecture: 0.010000  loss_cls: 3.3723 (3.1821)  loss_tome: 0.1111 (0.0764)  etrr_loss: 0.0045 (0.0115)  loss_flops: 0.2284 (0.1070)  flops: 2.9779 (2.8042)  grad_norm: 0.0050 (0.0110)  time: 0.4220  data: 0.0003  max mem: 10310
[2024-06-05 17:24:40 root] (utils.py 285): INFO Epoch: [0]  [ 450/5004]  eta: 0:35:09  lr_architecture: 0.010000  loss_cls: 3.1239 (3.1797)  loss_tome: 0.1111 (0.0772)  etrr_loss: 0.0040 (0.0114)  loss_flops: 0.2486 (0.1103)  flops: 2.9986 (2.8087)  grad_norm: 0.0047 (0.0109)  time: 0.4232  data: 0.0004  max mem: 10311
[2024-06-05 17:31:38 root] (main.py 192): INFO Namespace(batch_size=256, epochs=3, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/home/shivam/datasets/imagenet', data_set='IMNET', inat_category='name', output_dir='/home/pranav/DiffRate/learnt/LSMS', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=32, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.5, granularity=4, load_compression_rate=False, warmup_compression_rate=False, distributed=False)
[2024-06-05 17:31:41 root] (main.py 258): INFO Creating model: vit_deit_small_patch16_224
[2024-06-05 17:31:45 root] (main.py 346): INFO number of params: 22050664
[2024-06-05 17:31:45 root] (main.py 392): INFO Start training for 3 epochs
[2024-06-05 17:32:07 root] (engine.py 137): INFO merge kept number:[197, 197, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101]
[2024-06-05 17:32:07 root] (utils.py 285): INFO Epoch: [0]  [   0/5004]  eta: 1 day, 6:33:27  lr_architecture: 0.010000  loss_cls: 4.0759 (4.0759)  loss_etrr_per_merge: 0.0274 (0.0274)  loss_tome: 0.0069 (0.0069)  etrr_loss: 0.0133 (0.0133)  loss_flops: 0.0673 (0.0673)  flops: 2.7594 (2.7594)  grad_norm: 0.0530 (0.0530)  time: 21.9839  data: 0.0019  max mem: 10030
[2024-06-05 17:32:11 root] (utils.py 285): INFO Epoch: [0]  [  10/5004]  eta: 3:17:05  lr_architecture: 0.010000  loss_cls: 4.0759 (3.8913)  loss_etrr_per_merge: 0.0820 (0.0723)  loss_tome: 0.0625 (0.0511)  etrr_loss: 0.0132 (0.0132)  loss_flops: 0.0683 (0.0689)  flops: 2.7613 (2.7625)  grad_norm: 0.0437 (0.0381)  time: 2.3678  data: 0.0006  max mem: 10157
[2024-06-05 17:32:15 root] (utils.py 285): INFO Epoch: [0]  [  20/5004]  eta: 1:59:11  lr_architecture: 0.010000  loss_cls: 3.6888 (3.7127)  loss_etrr_per_merge: 0.0825 (0.0773)  loss_tome: 0.0625 (0.0565)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0710)  flops: 2.7659 (2.7664)  grad_norm: 0.0276 (0.0320)  time: 0.4074  data: 0.0005  max mem: 10160
[2024-06-05 17:32:19 root] (utils.py 285): INFO Epoch: [0]  [  30/5004]  eta: 1:31:29  lr_architecture: 0.010000  loss_cls: 3.6097 (3.6715)  loss_etrr_per_merge: 0.0825 (0.0789)  loss_tome: 0.0625 (0.0585)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0703)  flops: 2.7659 (2.7650)  grad_norm: 0.0227 (0.0296)  time: 0.4084  data: 0.0005  max mem: 10164
[2024-06-05 17:32:23 root] (utils.py 285): INFO Epoch: [0]  [  40/5004]  eta: 1:17:17  lr_architecture: 0.010000  loss_cls: 3.5372 (3.5781)  loss_etrr_per_merge: 0.0820 (0.0795)  loss_tome: 0.0625 (0.0595)  etrr_loss: 0.0134 (0.0132)  loss_flops: 0.0646 (0.0674)  flops: 2.7541 (2.7593)  grad_norm: 0.0193 (0.0271)  time: 0.4084  data: 0.0005  max mem: 10167
[2024-06-05 17:32:28 root] (utils.py 285): INFO Epoch: [0]  [  50/5004]  eta: 1:08:38  lr_architecture: 0.010000  loss_cls: 3.4513 (3.5608)  loss_etrr_per_merge: 0.0811 (0.0797)  loss_tome: 0.0625 (0.0600)  etrr_loss: 0.0143 (0.0136)  loss_flops: 0.0541 (0.0639)  flops: 2.7327 (2.7522)  grad_norm: 0.0188 (0.0256)  time: 0.4091  data: 0.0006  max mem: 10171
[2024-06-05 17:32:32 root] (utils.py 285): INFO Epoch: [0]  [  60/5004]  eta: 1:02:48  lr_architecture: 0.010000  loss_cls: 3.4892 (3.5165)  loss_etrr_per_merge: 0.0801 (0.0797)  loss_tome: 0.0625 (0.0605)  etrr_loss: 0.0155 (0.0140)  loss_flops: 0.0446 (0.0597)  flops: 2.7113 (2.7428)  grad_norm: 0.0194 (0.0245)  time: 0.4095  data: 0.0006  max mem: 10174
[2024-06-05 17:32:36 root] (utils.py 285): INFO Epoch: [0]  [  70/5004]  eta: 0:58:35  lr_architecture: 0.010000  loss_cls: 3.3035 (3.4595)  loss_etrr_per_merge: 0.0785 (0.0795)  loss_tome: 0.0625 (0.0607)  etrr_loss: 0.0169 (0.0145)  loss_flops: 0.0301 (0.0552)  flops: 2.6735 (2.7320)  grad_norm: 0.0136 (0.0233)  time: 0.4100  data: 0.0007  max mem: 10176
[2024-06-05 17:32:40 root] (utils.py 285): INFO Epoch: [0]  [  80/5004]  eta: 0:55:24  lr_architecture: 0.010000  loss_cls: 3.2077 (3.4330)  loss_etrr_per_merge: 0.0779 (0.0792)  loss_tome: 0.0625 (0.0610)  etrr_loss: 0.0182 (0.0151)  loss_flops: 0.0253 (0.0511)  flops: 2.6590 (2.7215)  grad_norm: 0.0138 (0.0223)  time: 0.4096  data: 0.0007  max mem: 10177
[2024-06-05 17:32:44 root] (utils.py 285): INFO Epoch: [0]  [  90/5004]  eta: 0:52:54  lr_architecture: 0.010000  loss_cls: 3.2654 (3.4054)  loss_etrr_per_merge: 0.0770 (0.0789)  loss_tome: 0.0625 (0.0611)  etrr_loss: 0.0195 (0.0157)  loss_flops: 0.0185 (0.0470)  flops: 2.6358 (2.7104)  grad_norm: 0.0141 (0.0216)  time: 0.4099  data: 0.0006  max mem: 10178
[2024-06-05 17:32:48 root] (engine.py 137): INFO merge kept number:[197, 197, 133, 108, 84, 101, 84, 101, 101, 84, 84, 101]
[2024-06-05 17:32:48 root] (utils.py 285): INFO Epoch: [0]  [ 100/5004]  eta: 0:50:54  lr_architecture: 0.010000  loss_cls: 3.3718 (3.4099)  loss_etrr_per_merge: 0.0757 (0.0786)  loss_tome: 0.0625 (0.0613)  etrr_loss: 0.0211 (0.0163)  loss_flops: 0.0104 (0.0433)  flops: 2.6022 (2.6992)  grad_norm: 0.0149 (0.0213)  time: 0.4110  data: 0.0006  max mem: 10186
[2024-06-05 17:32:52 root] (utils.py 285): INFO Epoch: [0]  [ 110/5004]  eta: 0:49:14  lr_architecture: 0.010000  loss_cls: 3.4735 (3.4056)  loss_etrr_per_merge: 0.0754 (0.0783)  loss_tome: 0.0625 (0.0614)  etrr_loss: 0.0218 (0.0168)  loss_flops: 0.0091 (0.0402)  flops: 2.5955 (2.6896)  grad_norm: 0.0161 (0.0208)  time: 0.4107  data: 0.0006  max mem: 10191
[2024-06-05 17:32:56 root] (utils.py 285): INFO Epoch: [0]  [ 120/5004]  eta: 0:47:50  lr_architecture: 0.010000  loss_cls: 3.3805 (3.3994)  loss_etrr_per_merge: 0.0756 (0.0781)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0215 (0.0171)  loss_flops: 0.0099 (0.0378)  flops: 2.5995 (2.6826)  grad_norm: 0.0124 (0.0203)  time: 0.4106  data: 0.0006  max mem: 10194
[2024-06-05 17:33:00 root] (utils.py 285): INFO Epoch: [0]  [ 130/5004]  eta: 0:46:38  lr_architecture: 0.010000  loss_cls: 3.2879 (3.3825)  loss_etrr_per_merge: 0.0765 (0.0780)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0202 (0.0173)  loss_flops: 0.0148 (0.0364)  flops: 2.6218 (2.6795)  grad_norm: 0.0119 (0.0197)  time: 0.4107  data: 0.0006  max mem: 10196
[2024-06-05 17:33:05 root] (utils.py 285): INFO Epoch: [0]  [ 140/5004]  eta: 0:45:36  lr_architecture: 0.010000  loss_cls: 3.2574 (3.3689)  loss_etrr_per_merge: 0.0781 (0.0781)  loss_tome: 0.0625 (0.0616)  etrr_loss: 0.0171 (0.0172)  loss_flops: 0.0258 (0.0363)  flops: 2.6606 (2.6800)  grad_norm: 0.0110 (0.0192)  time: 0.4102  data: 0.0005  max mem: 10197
[2024-06-05 17:33:09 root] (utils.py 285): INFO Epoch: [0]  [ 150/5004]  eta: 0:44:42  lr_architecture: 0.010000  loss_cls: 3.2506 (3.3503)  loss_etrr_per_merge: 0.0796 (0.0783)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0154 (0.0171)  loss_flops: 0.0382 (0.0372)  flops: 2.6955 (2.6827)  grad_norm: 0.0090 (0.0185)  time: 0.4107  data: 0.0005  max mem: 10201
[2024-06-05 17:33:13 root] (utils.py 285): INFO Epoch: [0]  [ 160/5004]  eta: 0:43:53  lr_architecture: 0.010000  loss_cls: 3.2357 (3.3451)  loss_etrr_per_merge: 0.0811 (0.0785)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0143 (0.0169)  loss_flops: 0.0531 (0.0382)  flops: 2.7305 (2.6858)  grad_norm: 0.0099 (0.0180)  time: 0.4110  data: 0.0005  max mem: 10202
[2024-06-05 17:33:17 root] (utils.py 285): INFO Epoch: [0]  [ 170/5004]  eta: 0:43:10  lr_architecture: 0.010000  loss_cls: 3.2357 (3.3308)  loss_etrr_per_merge: 0.0813 (0.0787)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0141 (0.0167)  loss_flops: 0.0550 (0.0396)  flops: 2.7345 (2.6895)  grad_norm: 0.0078 (0.0174)  time: 0.4103  data: 0.0005  max mem: 10203
[2024-06-05 17:33:21 root] (utils.py 285): INFO Epoch: [0]  [ 180/5004]  eta: 0:42:32  lr_architecture: 0.010000  loss_cls: 3.0873 (3.3120)  loss_etrr_per_merge: 0.0823 (0.0789)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0131 (0.0165)  loss_flops: 0.0650 (0.0411)  flops: 2.7549 (2.6932)  grad_norm: 0.0069 (0.0169)  time: 0.4113  data: 0.0005  max mem: 10204
[2024-06-05 17:33:25 root] (utils.py 285): INFO Epoch: [0]  [ 190/5004]  eta: 0:41:57  lr_architecture: 0.010000  loss_cls: 3.0142 (3.3061)  loss_etrr_per_merge: 0.0825 (0.0791)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0122 (0.0163)  loss_flops: 0.0670 (0.0430)  flops: 2.7589 (2.6977)  grad_norm: 0.0074 (0.0165)  time: 0.4120  data: 0.0005  max mem: 10207
[2024-06-05 17:33:29 root] (engine.py 137): INFO merge kept number:[197, 197, 150, 125, 96, 101, 96, 101, 101, 96, 96, 101]
[2024-06-05 17:33:29 root] (utils.py 285): INFO Epoch: [0]  [ 200/5004]  eta: 0:41:25  lr_architecture: 0.010000  loss_cls: 2.9445 (3.2889)  loss_etrr_per_merge: 0.0841 (0.0794)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0114 (0.0160)  loss_flops: 0.0864 (0.0457)  flops: 2.7939 (2.7033)  grad_norm: 0.0070 (0.0160)  time: 0.4112  data: 0.0005  max mem: 10207
[2024-06-05 17:33:33 root] (utils.py 285): INFO Epoch: [0]  [ 210/5004]  eta: 0:40:56  lr_architecture: 0.010000  loss_cls: 3.2091 (3.2794)  loss_etrr_per_merge: 0.0859 (0.0797)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0099 (0.0157)  loss_flops: 0.1083 (0.0491)  flops: 2.8290 (2.7100)  grad_norm: 0.0065 (0.0156)  time: 0.4111  data: 0.0006  max mem: 10208
[2024-06-05 17:33:37 root] (utils.py 285): INFO Epoch: [0]  [ 220/5004]  eta: 0:40:29  lr_architecture: 0.010000  loss_cls: 3.2091 (3.2657)  loss_etrr_per_merge: 0.0868 (0.0801)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0091 (0.0154)  loss_flops: 0.1208 (0.0524)  flops: 2.8476 (2.7163)  grad_norm: 0.0064 (0.0152)  time: 0.4113  data: 0.0005  max mem: 10209
[2024-06-05 17:33:42 root] (utils.py 285): INFO Epoch: [0]  [ 230/5004]  eta: 0:40:04  lr_architecture: 0.010000  loss_cls: 3.1346 (3.2575)  loss_etrr_per_merge: 0.0869 (0.0804)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0091 (0.0151)  loss_flops: 0.1222 (0.0555)  flops: 2.8496 (2.7221)  grad_norm: 0.0064 (0.0149)  time: 0.4112  data: 0.0005  max mem: 10210
[2024-06-05 17:33:46 root] (utils.py 285): INFO Epoch: [0]  [ 240/5004]  eta: 0:39:41  lr_architecture: 0.010000  loss_cls: 3.1689 (3.2519)  loss_etrr_per_merge: 0.0872 (0.0807)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0088 (0.0148)  loss_flops: 0.1264 (0.0587)  flops: 2.8556 (2.7280)  grad_norm: 0.0071 (0.0146)  time: 0.4118  data: 0.0005  max mem: 10210
[2024-06-05 17:33:50 root] (utils.py 285): INFO Epoch: [0]  [ 250/5004]  eta: 0:39:19  lr_architecture: 0.010000  loss_cls: 3.1689 (3.2404)  loss_etrr_per_merge: 0.0874 (0.0809)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0087 (0.0146)  loss_flops: 0.1293 (0.0615)  flops: 2.8595 (2.7332)  grad_norm: 0.0060 (0.0143)  time: 0.4123  data: 0.0006  max mem: 10213
[2024-06-05 17:34:01 root] (main.py 192): INFO Namespace(batch_size=256, epochs=3, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/home/shivam/datasets/imagenet', data_set='IMNET', inat_category='name', output_dir='/home/pranav/DiffRate/learnt/LSMS', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=32, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.5, granularity=4, load_compression_rate=False, warmup_compression_rate=False, distributed=False)
[2024-06-05 17:34:04 root] (main.py 258): INFO Creating model: vit_deit_small_patch16_224
[2024-06-05 17:34:08 root] (main.py 346): INFO number of params: 22050664
[2024-06-05 17:34:08 root] (main.py 392): INFO Start training for 3 epochs
[2024-06-05 17:34:31 root] (engine.py 137): INFO merge kept number:[197, 197, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101]
[2024-06-05 17:34:31 root] (utils.py 285): INFO Epoch: [0]  [   0/5004]  eta: 1 day, 6:46:31  lr_architecture: 0.010000  loss_cls: 4.0759 (4.0759)  loss_etrr_per_merge: 0.0274 (0.0274)  loss_tome: 0.0069 (0.0069)  etrr_loss: 0.0133 (0.0133)  loss_flops: 0.0673 (0.0673)  flops: 2.7594 (2.7594)  grad_norm: 0.0530 (0.0530)  time: 22.1407  data: 5.1862  max mem: 10030
[2024-06-05 17:34:35 root] (utils.py 285): INFO Epoch: [0]  [  10/5004]  eta: 3:18:28  lr_architecture: 0.010000  loss_cls: 4.0759 (3.8913)  loss_etrr_per_merge: 0.0820 (0.0723)  loss_tome: 0.0625 (0.0511)  etrr_loss: 0.0132 (0.0132)  loss_flops: 0.0683 (0.0689)  flops: 2.7613 (2.7625)  grad_norm: 0.0437 (0.0381)  time: 2.3845  data: 0.4720  max mem: 10157
[2024-06-05 17:34:39 root] (utils.py 285): INFO Epoch: [0]  [  20/5004]  eta: 1:59:56  lr_architecture: 0.010000  loss_cls: 3.6888 (3.7127)  loss_etrr_per_merge: 0.0825 (0.0773)  loss_tome: 0.0625 (0.0565)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0710)  flops: 2.7659 (2.7664)  grad_norm: 0.0276 (0.0320)  time: 0.4090  data: 0.0005  max mem: 10160
[2024-06-05 17:34:43 root] (utils.py 285): INFO Epoch: [0]  [  30/5004]  eta: 1:32:01  lr_architecture: 0.010000  loss_cls: 3.6097 (3.6715)  loss_etrr_per_merge: 0.0825 (0.0789)  loss_tome: 0.0625 (0.0585)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0703)  flops: 2.7659 (2.7650)  grad_norm: 0.0227 (0.0296)  time: 0.4093  data: 0.0005  max mem: 10164
[2024-06-05 17:34:47 root] (utils.py 285): INFO Epoch: [0]  [  40/5004]  eta: 1:17:45  lr_architecture: 0.010000  loss_cls: 3.5374 (3.5781)  loss_etrr_per_merge: 0.0820 (0.0795)  loss_tome: 0.0625 (0.0595)  etrr_loss: 0.0134 (0.0132)  loss_flops: 0.0646 (0.0674)  flops: 2.7541 (2.7593)  grad_norm: 0.0193 (0.0271)  time: 0.4106  data: 0.0006  max mem: 10167
[2024-06-05 17:34:51 root] (utils.py 285): INFO Epoch: [0]  [  50/5004]  eta: 1:09:01  lr_architecture: 0.010000  loss_cls: 3.4552 (3.5609)  loss_etrr_per_merge: 0.0811 (0.0797)  loss_tome: 0.0625 (0.0600)  etrr_loss: 0.0143 (0.0136)  loss_flops: 0.0541 (0.0638)  flops: 2.7327 (2.7519)  grad_norm: 0.0188 (0.0256)  time: 0.4111  data: 0.0007  max mem: 10172
[2024-06-05 17:34:55 root] (utils.py 285): INFO Epoch: [0]  [  60/5004]  eta: 1:03:09  lr_architecture: 0.010000  loss_cls: 3.4893 (3.5166)  loss_etrr_per_merge: 0.0800 (0.0796)  loss_tome: 0.0625 (0.0605)  etrr_loss: 0.0155 (0.0141)  loss_flops: 0.0438 (0.0593)  flops: 2.7093 (2.7418)  grad_norm: 0.0194 (0.0245)  time: 0.4113  data: 0.0007  max mem: 10174
[2024-06-05 17:34:59 root] (utils.py 285): INFO Epoch: [0]  [  70/5004]  eta: 0:58:55  lr_architecture: 0.010000  loss_cls: 3.3043 (3.4596)  loss_etrr_per_merge: 0.0785 (0.0794)  loss_tome: 0.0625 (0.0607)  etrr_loss: 0.0174 (0.0146)  loss_flops: 0.0301 (0.0549)  flops: 2.6735 (2.7312)  grad_norm: 0.0136 (0.0233)  time: 0.4120  data: 0.0008  max mem: 10176
[2024-06-05 17:35:03 root] (utils.py 285): INFO Epoch: [0]  [  80/5004]  eta: 0:55:42  lr_architecture: 0.010000  loss_cls: 3.2073 (3.4332)  loss_etrr_per_merge: 0.0779 (0.0792)  loss_tome: 0.0625 (0.0610)  etrr_loss: 0.0182 (0.0151)  loss_flops: 0.0253 (0.0508)  flops: 2.6590 (2.7208)  grad_norm: 0.0138 (0.0223)  time: 0.4111  data: 0.0007  max mem: 10177
[2024-06-05 17:35:08 root] (utils.py 285): INFO Epoch: [0]  [  90/5004]  eta: 0:53:12  lr_architecture: 0.010000  loss_cls: 3.2734 (3.4059)  loss_etrr_per_merge: 0.0770 (0.0789)  loss_tome: 0.0625 (0.0611)  etrr_loss: 0.0195 (0.0157)  loss_flops: 0.0185 (0.0468)  flops: 2.6358 (2.7098)  grad_norm: 0.0141 (0.0216)  time: 0.4121  data: 0.0007  max mem: 10180
[2024-06-05 17:35:12 root] (engine.py 137): INFO merge kept number:[197, 197, 133, 108, 85, 101, 85, 101, 101, 85, 85, 101]
[2024-06-05 17:35:12 root] (utils.py 285): INFO Epoch: [0]  [ 100/5004]  eta: 0:51:10  lr_architecture: 0.010000  loss_cls: 3.3637 (3.4101)  loss_etrr_per_merge: 0.0760 (0.0786)  loss_tome: 0.0625 (0.0613)  etrr_loss: 0.0209 (0.0163)  loss_flops: 0.0123 (0.0432)  flops: 2.6108 (2.6992)  grad_norm: 0.0146 (0.0213)  time: 0.4128  data: 0.0006  max mem: 10182
[2024-06-05 17:35:16 root] (utils.py 285): INFO Epoch: [0]  [ 110/5004]  eta: 0:49:29  lr_architecture: 0.010000  loss_cls: 3.4524 (3.4055)  loss_etrr_per_merge: 0.0756 (0.0783)  loss_tome: 0.0625 (0.0614)  etrr_loss: 0.0215 (0.0168)  loss_flops: 0.0100 (0.0402)  flops: 2.6002 (2.6900)  grad_norm: 0.0146 (0.0208)  time: 0.4114  data: 0.0005  max mem: 10190
[2024-06-05 17:35:20 root] (utils.py 285): INFO Epoch: [0]  [ 120/5004]  eta: 0:48:04  lr_architecture: 0.010000  loss_cls: 3.3649 (3.3995)  loss_etrr_per_merge: 0.0754 (0.0781)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0218 (0.0172)  loss_flops: 0.0091 (0.0376)  flops: 2.5955 (2.6820)  grad_norm: 0.0121 (0.0202)  time: 0.4114  data: 0.0005  max mem: 10193
[2024-06-05 17:35:24 root] (utils.py 285): INFO Epoch: [0]  [ 130/5004]  eta: 0:46:52  lr_architecture: 0.010000  loss_cls: 3.2879 (3.3833)  loss_etrr_per_merge: 0.0759 (0.0779)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0212 (0.0175)  loss_flops: 0.0111 (0.0357)  flops: 2.6054 (2.6767)  grad_norm: 0.0116 (0.0198)  time: 0.4119  data: 0.0006  max mem: 10196
[2024-06-05 17:35:28 root] (utils.py 285): INFO Epoch: [0]  [ 140/5004]  eta: 0:45:49  lr_architecture: 0.010000  loss_cls: 3.2684 (3.3700)  loss_etrr_per_merge: 0.0768 (0.0778)  loss_tome: 0.0625 (0.0616)  etrr_loss: 0.0198 (0.0176)  loss_flops: 0.0163 (0.0344)  flops: 2.6277 (2.6737)  grad_norm: 0.0104 (0.0192)  time: 0.4117  data: 0.0006  max mem: 10197
[2024-06-05 17:35:32 root] (utils.py 285): INFO Epoch: [0]  [ 150/5004]  eta: 0:44:54  lr_architecture: 0.010000  loss_cls: 3.2684 (3.3525)  loss_etrr_per_merge: 0.0775 (0.0779)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0188 (0.0176)  loss_flops: 0.0214 (0.0339)  flops: 2.6461 (2.6730)  grad_norm: 0.0099 (0.0186)  time: 0.4115  data: 0.0005  max mem: 10199
[2024-06-05 17:35:36 root] (utils.py 285): INFO Epoch: [0]  [ 160/5004]  eta: 0:44:05  lr_architecture: 0.010000  loss_cls: 3.2559 (3.3477)  loss_etrr_per_merge: 0.0791 (0.0780)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0166 (0.0175)  loss_flops: 0.0335 (0.0340)  flops: 2.6830 (2.6739)  grad_norm: 0.0103 (0.0181)  time: 0.4120  data: 0.0006  max mem: 10203
[2024-06-05 17:35:41 root] (utils.py 285): INFO Epoch: [0]  [ 170/5004]  eta: 0:43:22  lr_architecture: 0.010000  loss_cls: 3.2323 (3.3338)  loss_etrr_per_merge: 0.0794 (0.0781)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0163 (0.0174)  loss_flops: 0.0364 (0.0344)  flops: 2.6909 (2.6756)  grad_norm: 0.0087 (0.0175)  time: 0.4116  data: 0.0006  max mem: 10204
[2024-06-05 17:35:45 root] (utils.py 285): INFO Epoch: [0]  [ 180/5004]  eta: 0:42:43  lr_architecture: 0.010000  loss_cls: 3.1076 (3.3152)  loss_etrr_per_merge: 0.0803 (0.0782)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0153 (0.0173)  loss_flops: 0.0447 (0.0351)  flops: 2.7113 (2.6779)  grad_norm: 0.0066 (0.0170)  time: 0.4115  data: 0.0005  max mem: 10206
[2024-06-05 17:35:49 root] (utils.py 285): INFO Epoch: [0]  [ 190/5004]  eta: 0:42:07  lr_architecture: 0.010000  loss_cls: 3.0227 (3.3096)  loss_etrr_per_merge: 0.0811 (0.0784)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0142 (0.0171)  loss_flops: 0.0528 (0.0362)  flops: 2.7298 (2.6810)  grad_norm: 0.0070 (0.0166)  time: 0.4121  data: 0.0005  max mem: 10208
[2024-06-05 17:35:53 root] (engine.py 137): INFO merge kept number:[197, 197, 150, 125, 94, 101, 94, 101, 101, 94, 94, 101]
[2024-06-05 17:35:53 root] (utils.py 285): INFO Epoch: [0]  [ 200/5004]  eta: 0:41:35  lr_architecture: 0.010000  loss_cls: 2.9506 (3.2924)  loss_etrr_per_merge: 0.0821 (0.0786)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0133 (0.0169)  loss_flops: 0.0626 (0.0383)  flops: 2.7503 (2.6858)  grad_norm: 0.0072 (0.0162)  time: 0.4120  data: 0.0005  max mem: 10208
[2024-06-05 17:35:57 root] (utils.py 285): INFO Epoch: [0]  [ 210/5004]  eta: 0:41:05  lr_architecture: 0.010000  loss_cls: 3.2142 (3.2827)  loss_etrr_per_merge: 0.0844 (0.0789)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0110 (0.0166)  loss_flops: 0.0899 (0.0412)  flops: 2.7999 (2.6920)  grad_norm: 0.0066 (0.0157)  time: 0.4124  data: 0.0006  max mem: 10209
[2024-06-05 17:36:01 root] (utils.py 285): INFO Epoch: [0]  [ 220/5004]  eta: 0:40:38  lr_architecture: 0.010000  loss_cls: 3.2142 (3.2690)  loss_etrr_per_merge: 0.0861 (0.0793)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0096 (0.0162)  loss_flops: 0.1109 (0.0445)  flops: 2.8330 (2.6986)  grad_norm: 0.0058 (0.0153)  time: 0.4126  data: 0.0006  max mem: 10209
[2024-06-05 17:36:05 root] (utils.py 285): INFO Epoch: [0]  [ 230/5004]  eta: 0:40:13  lr_architecture: 0.010000  loss_cls: 3.1228 (3.2603)  loss_etrr_per_merge: 0.0869 (0.0796)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0091 (0.0159)  loss_flops: 0.1222 (0.0479)  flops: 2.8496 (2.7052)  grad_norm: 0.0059 (0.0150)  time: 0.4125  data: 0.0006  max mem: 10210
[2024-06-05 17:36:09 root] (utils.py 285): INFO Epoch: [0]  [ 240/5004]  eta: 0:39:50  lr_architecture: 0.010000  loss_cls: 3.1684 (3.2548)  loss_etrr_per_merge: 0.0870 (0.0799)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0090 (0.0156)  loss_flops: 0.1236 (0.0513)  flops: 2.8516 (2.7116)  grad_norm: 0.0067 (0.0147)  time: 0.4126  data: 0.0005  max mem: 10211
[2024-06-05 17:36:14 root] (utils.py 285): INFO Epoch: [0]  [ 250/5004]  eta: 0:39:28  lr_architecture: 0.010000  loss_cls: 3.1684 (3.2432)  loss_etrr_per_merge: 0.0880 (0.0803)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0083 (0.0153)  loss_flops: 0.1370 (0.0548)  flops: 2.8702 (2.7180)  grad_norm: 0.0067 (0.0144)  time: 0.4127  data: 0.0005  max mem: 10211
[2024-06-05 17:36:18 root] (utils.py 285): INFO Epoch: [0]  [ 260/5004]  eta: 0:39:07  lr_architecture: 0.010000  loss_cls: 3.1020 (3.2302)  loss_etrr_per_merge: 0.0874 (0.0805)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0083 (0.0151)  loss_flops: 0.1293 (0.0575)  flops: 2.8596 (2.7233)  grad_norm: 0.0051 (0.0141)  time: 0.4126  data: 0.0005  max mem: 10213
[2024-06-05 17:36:22 root] (utils.py 285): INFO Epoch: [0]  [ 270/5004]  eta: 0:38:48  lr_architecture: 0.010000  loss_cls: 2.8546 (3.2214)  loss_etrr_per_merge: 0.0868 (0.0808)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0091 (0.0149)  loss_flops: 0.1204 (0.0598)  flops: 2.8470 (2.7278)  grad_norm: 0.0063 (0.0140)  time: 0.4124  data: 0.0005  max mem: 10214
[2024-06-05 17:36:26 root] (utils.py 285): INFO Epoch: [0]  [ 280/5004]  eta: 0:38:30  lr_architecture: 0.010000  loss_cls: 3.3002 (3.2223)  loss_etrr_per_merge: 0.0868 (0.0810)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0091 (0.0146)  loss_flops: 0.1204 (0.0625)  flops: 2.8470 (2.7328)  grad_norm: 0.0063 (0.0137)  time: 0.4122  data: 0.0005  max mem: 10216
[2024-06-05 17:36:30 root] (utils.py 285): INFO Epoch: [0]  [ 290/5004]  eta: 0:38:12  lr_architecture: 0.010000  loss_cls: 3.2353 (3.2089)  loss_etrr_per_merge: 0.0887 (0.0813)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0078 (0.0144)  loss_flops: 0.1460 (0.0655)  flops: 2.8822 (2.7380)  grad_norm: 0.0061 (0.0135)  time: 0.4120  data: 0.0005  max mem: 10218
[2024-06-05 17:36:34 root] (engine.py 137): INFO merge kept number:[197, 197, 160, 130, 98, 101, 98, 101, 101, 98, 98, 101]
[2024-06-05 17:36:34 root] (utils.py 285): INFO Epoch: [0]  [ 300/5004]  eta: 0:37:56  lr_architecture: 0.010000  loss_cls: 2.8776 (3.1995)  loss_etrr_per_merge: 0.0889 (0.0815)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0077 (0.0142)  loss_flops: 0.1491 (0.0683)  flops: 2.8861 (2.7430)  grad_norm: 0.0062 (0.0132)  time: 0.4121  data: 0.0005  max mem: 10219
[2024-06-05 17:36:38 root] (utils.py 285): INFO Epoch: [0]  [ 310/5004]  eta: 0:37:40  lr_architecture: 0.010000  loss_cls: 2.9512 (3.1928)  loss_etrr_per_merge: 0.0890 (0.0818)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0076 (0.0140)  loss_flops: 0.1507 (0.0710)  flops: 2.8881 (2.7477)  grad_norm: 0.0058 (0.0130)  time: 0.4125  data: 0.0006  max mem: 10220
[2024-06-05 17:36:42 root] (utils.py 285): INFO Epoch: [0]  [ 320/5004]  eta: 0:37:25  lr_architecture: 0.010000  loss_cls: 3.2805 (3.2011)  loss_etrr_per_merge: 0.0899 (0.0821)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0070 (0.0137)  loss_flops: 0.1639 (0.0742)  flops: 2.9048 (2.7530)  grad_norm: 0.0069 (0.0129)  time: 0.4128  data: 0.0005  max mem: 10220
[2024-06-05 17:36:47 root] (utils.py 285): INFO Epoch: [0]  [ 330/5004]  eta: 0:37:12  lr_architecture: 0.010000  loss_cls: 3.3004 (3.1952)  loss_etrr_per_merge: 0.0920 (0.0829)  loss_tome: 0.0625 (0.0630)  etrr_loss: 0.0059 (0.0135)  loss_flops: 0.1910 (0.0779)  flops: 2.9371 (2.7588)  grad_norm: 0.0059 (0.0127)  time: 0.4152  data: 0.0004  max mem: 10281
[2024-06-05 17:36:51 root] (utils.py 285): INFO Epoch: [0]  [ 340/5004]  eta: 0:36:59  lr_architecture: 0.010000  loss_cls: 3.1893 (3.1977)  loss_etrr_per_merge: 0.1225 (0.0841)  loss_tome: 0.1111 (0.0644)  etrr_loss: 0.0057 (0.0133)  loss_flops: 0.1954 (0.0813)  flops: 2.9420 (2.7641)  grad_norm: 0.0049 (0.0125)  time: 0.4191  data: 0.0003  max mem: 10287
[2024-06-05 17:36:55 root] (utils.py 285): INFO Epoch: [0]  [ 350/5004]  eta: 0:36:47  lr_architecture: 0.010000  loss_cls: 3.2652 (3.1954)  loss_etrr_per_merge: 0.1225 (0.0852)  loss_tome: 0.1111 (0.0657)  etrr_loss: 0.0057 (0.0130)  loss_flops: 0.1919 (0.0845)  flops: 2.9381 (2.7691)  grad_norm: 0.0058 (0.0123)  time: 0.4211  data: 0.0003  max mem: 10291
[2024-06-05 17:36:59 root] (utils.py 285): INFO Epoch: [0]  [ 360/5004]  eta: 0:36:36  lr_architecture: 0.010000  loss_cls: 3.1500 (3.1922)  loss_etrr_per_merge: 0.1226 (0.0862)  loss_tome: 0.1111 (0.0670)  etrr_loss: 0.0057 (0.0128)  loss_flops: 0.1928 (0.0876)  flops: 2.9391 (2.7739)  grad_norm: 0.0060 (0.0122)  time: 0.4215  data: 0.0003  max mem: 10295
[2024-06-05 17:37:03 root] (utils.py 285): INFO Epoch: [0]  [ 370/5004]  eta: 0:36:25  lr_architecture: 0.010000  loss_cls: 3.1022 (3.1868)  loss_etrr_per_merge: 0.1226 (0.0872)  loss_tome: 0.1111 (0.0682)  etrr_loss: 0.0058 (0.0127)  loss_flops: 0.1921 (0.0903)  flops: 2.9383 (2.7782)  grad_norm: 0.0056 (0.0120)  time: 0.4214  data: 0.0003  max mem: 10296
[2024-06-05 17:37:08 root] (utils.py 285): INFO Epoch: [0]  [ 380/5004]  eta: 0:36:14  lr_architecture: 0.010000  loss_cls: 3.1528 (3.1822)  loss_etrr_per_merge: 0.1212 (0.0881)  loss_tome: 0.1111 (0.0693)  etrr_loss: 0.0063 (0.0125)  loss_flops: 0.1755 (0.0925)  flops: 2.9189 (2.7818)  grad_norm: 0.0053 (0.0119)  time: 0.4218  data: 0.0003  max mem: 10298
[2024-06-05 17:37:12 root] (utils.py 285): INFO Epoch: [0]  [ 390/5004]  eta: 0:36:03  lr_architecture: 0.010000  loss_cls: 3.1614 (3.1754)  loss_etrr_per_merge: 0.1212 (0.0889)  loss_tome: 0.1111 (0.0704)  etrr_loss: 0.0064 (0.0123)  loss_flops: 0.1755 (0.0945)  flops: 2.9189 (2.7853)  grad_norm: 0.0058 (0.0118)  time: 0.4218  data: 0.0003  max mem: 10298
[2024-06-05 17:37:16 root] (engine.py 137): INFO merge kept number:[197, 197, 168, 145, 117, 95, 95, 101, 101, 95, 95, 101]
[2024-06-05 17:37:16 root] (utils.py 285): INFO Epoch: [0]  [ 400/5004]  eta: 0:35:53  lr_architecture: 0.010000  loss_cls: 3.3005 (3.1778)  loss_etrr_per_merge: 0.1215 (0.0897)  loss_tome: 0.1111 (0.0714)  etrr_loss: 0.0063 (0.0122)  loss_flops: 0.1788 (0.0967)  flops: 2.9229 (2.7888)  grad_norm: 0.0053 (0.0116)  time: 0.4216  data: 0.0002  max mem: 10302
[2024-06-05 17:37:20 root] (utils.py 285): INFO Epoch: [0]  [ 410/5004]  eta: 0:35:43  lr_architecture: 0.010000  loss_cls: 3.3581 (3.1798)  loss_etrr_per_merge: 0.1223 (0.0906)  loss_tome: 0.1111 (0.0724)  etrr_loss: 0.0059 (0.0120)  loss_flops: 0.1873 (0.0994)  flops: 2.9327 (2.7929)  grad_norm: 0.0048 (0.0115)  time: 0.4216  data: 0.0002  max mem: 10304
[2024-06-05 17:37:25 root] (utils.py 285): INFO Epoch: [0]  [ 420/5004]  eta: 0:35:34  lr_architecture: 0.010000  loss_cls: 3.1646 (3.1765)  loss_etrr_per_merge: 0.1251 (0.0914)  loss_tome: 0.1111 (0.0733)  etrr_loss: 0.0049 (0.0118)  loss_flops: 0.2190 (0.1025)  flops: 2.9680 (2.7973)  grad_norm: 0.0046 (0.0113)  time: 0.4219  data: 0.0003  max mem: 10305
[2024-06-05 17:37:29 root] (utils.py 285): INFO Epoch: [0]  [ 430/5004]  eta: 0:35:25  lr_architecture: 0.010000  loss_cls: 3.2869 (3.1801)  loss_etrr_per_merge: 0.1274 (0.0923)  loss_tome: 0.1111 (0.0742)  etrr_loss: 0.0041 (0.0117)  loss_flops: 0.2474 (0.1061)  flops: 2.9974 (2.8021)  grad_norm: 0.0051 (0.0112)  time: 0.4219  data: 0.0003  max mem: 10305
[2024-06-05 17:37:33 root] (utils.py 285): INFO Epoch: [0]  [ 440/5004]  eta: 0:35:15  lr_architecture: 0.010000  loss_cls: 3.3738 (3.1814)  loss_etrr_per_merge: 0.1290 (0.0931)  loss_tome: 0.1111 (0.0750)  etrr_loss: 0.0036 (0.0115)  loss_flops: 0.2663 (0.1098)  flops: 3.0161 (2.8071)  grad_norm: 0.0049 (0.0111)  time: 0.4218  data: 0.0003  max mem: 10309
[2024-06-05 17:37:37 root] (utils.py 285): INFO Epoch: [0]  [ 450/5004]  eta: 0:35:07  lr_architecture: 0.010000  loss_cls: 3.1134 (3.1788)  loss_etrr_per_merge: 0.1297 (0.0941)  loss_tome: 0.1111 (0.0761)  etrr_loss: 0.0031 (0.0113)  loss_flops: 0.2746 (0.1139)  flops: 3.0240 (2.8123)  grad_norm: 0.0041 (0.0110)  time: 0.4227  data: 0.0003  max mem: 10366
[2024-06-05 17:37:42 root] (utils.py 285): INFO Epoch: [0]  [ 460/5004]  eta: 0:34:59  lr_architecture: 0.010000  loss_cls: 2.9916 (3.1720)  loss_etrr_per_merge: 0.1630 (0.0956)  loss_tome: 0.1736 (0.0782)  etrr_loss: 0.0030 (0.0111)  loss_flops: 0.2902 (0.1176)  flops: 3.0387 (2.8171)  grad_norm: 0.0047 (0.0108)  time: 0.4268  data: 0.0003  max mem: 10369
[2024-06-05 17:37:46 root] (utils.py 285): INFO Epoch: [0]  [ 470/5004]  eta: 0:34:51  lr_architecture: 0.010000  loss_cls: 2.7185 (3.1628)  loss_etrr_per_merge: 0.1626 (0.0970)  loss_tome: 0.1736 (0.0802)  etrr_loss: 0.0033 (0.0109)  loss_flops: 0.2765 (0.1209)  flops: 3.0259 (2.8215)  grad_norm: 0.0038 (0.0107)  time: 0.4302  data: 0.0003  max mem: 10371
[2024-06-05 17:37:50 root] (utils.py 285): INFO Epoch: [0]  [ 480/5004]  eta: 0:34:44  lr_architecture: 0.010000  loss_cls: 2.8620 (3.1601)  loss_etrr_per_merge: 0.1619 (0.0984)  loss_tome: 0.1736 (0.0822)  etrr_loss: 0.0035 (0.0108)  loss_flops: 0.2694 (0.1239)  flops: 3.0190 (2.8255)  grad_norm: 0.0038 (0.0106)  time: 0.4304  data: 0.0003  max mem: 10373
[2024-06-05 17:37:54 root] (utils.py 285): INFO Epoch: [0]  [ 490/5004]  eta: 0:34:36  lr_architecture: 0.010000  loss_cls: 3.0433 (3.1604)  loss_etrr_per_merge: 0.1619 (0.0997)  loss_tome: 0.1736 (0.0840)  etrr_loss: 0.0034 (0.0106)  loss_flops: 0.2684 (0.1269)  flops: 3.0180 (2.8295)  grad_norm: 0.0038 (0.0105)  time: 0.4304  data: 0.0003  max mem: 10375
[2024-06-05 17:37:59 root] (engine.py 137): INFO merge kept number:[197, 197, 174, 155, 129, 105, 105, 95, 101, 95, 95, 101]
[2024-06-05 17:37:59 root] (utils.py 285): INFO Epoch: [0]  [ 500/5004]  eta: 0:34:29  lr_architecture: 0.010000  loss_cls: 3.0975 (3.1578)  loss_etrr_per_merge: 0.1626 (0.1009)  loss_tome: 0.1736 (0.0858)  etrr_loss: 0.0033 (0.0105)  loss_flops: 0.2745 (0.1299)  flops: 3.0239 (2.8334)  grad_norm: 0.0037 (0.0103)  time: 0.4307  data: 0.0003  max mem: 10376
[2024-06-05 17:38:03 root] (utils.py 285): INFO Epoch: [0]  [ 510/5004]  eta: 0:34:22  lr_architecture: 0.010000  loss_cls: 3.2215 (3.1602)  loss_etrr_per_merge: 0.1630 (0.1022)  loss_tome: 0.1736 (0.0875)  etrr_loss: 0.0032 (0.0103)  loss_flops: 0.2776 (0.1329)  flops: 3.0269 (2.8373)  grad_norm: 0.0047 (0.0102)  time: 0.4308  data: 0.0003  max mem: 10381
[2024-06-05 17:38:07 root] (utils.py 285): INFO Epoch: [0]  [ 520/5004]  eta: 0:34:15  lr_architecture: 0.010000  loss_cls: 3.3044 (3.1599)  loss_etrr_per_merge: 0.1644 (0.1034)  loss_tome: 0.1736 (0.0892)  etrr_loss: 0.0029 (0.0102)  loss_flops: 0.2900 (0.1363)  flops: 3.0385 (2.8414)  grad_norm: 0.0048 (0.0102)  time: 0.4306  data: 0.0003  max mem: 10388
[2024-06-05 17:38:12 root] (utils.py 285): INFO Epoch: [0]  [ 530/5004]  eta: 0:34:08  lr_architecture: 0.010000  loss_cls: 3.1598 (3.1524)  loss_etrr_per_merge: 0.1677 (0.1046)  loss_tome: 0.1736 (0.0908)  etrr_loss: 0.0023 (0.0100)  loss_flops: 0.3215 (0.1400)  flops: 3.0670 (2.8459)  grad_norm: 0.0037 (0.0100)  time: 0.4308  data: 0.0003  max mem: 10391
[2024-06-05 17:38:16 root] (utils.py 285): INFO Epoch: [0]  [ 540/5004]  eta: 0:34:01  lr_architecture: 0.010000  loss_cls: 3.0882 (3.1492)  loss_etrr_per_merge: 0.1696 (0.1058)  loss_tome: 0.1736 (0.0923)  etrr_loss: 0.0020 (0.0099)  loss_flops: 0.3395 (0.1438)  flops: 3.0826 (2.8504)  grad_norm: 0.0034 (0.0099)  time: 0.4308  data: 0.0003  max mem: 10393
[2024-06-05 17:38:20 root] (utils.py 285): INFO Epoch: [0]  [ 550/5004]  eta: 0:33:55  lr_architecture: 0.010000  loss_cls: 3.1080 (3.1475)  loss_etrr_per_merge: 0.1706 (0.1070)  loss_tome: 0.1736 (0.0938)  etrr_loss: 0.0019 (0.0097)  loss_flops: 0.3476 (0.1474)  flops: 3.0896 (2.8547)  grad_norm: 0.0051 (0.0099)  time: 0.4312  data: 0.0003  max mem: 10395
[2024-06-05 17:38:25 root] (utils.py 285): INFO Epoch: [0]  [ 560/5004]  eta: 0:33:48  lr_architecture: 0.010000  loss_cls: 3.3485 (3.1499)  loss_etrr_per_merge: 0.1693 (0.1081)  loss_tome: 0.1736 (0.0952)  etrr_loss: 0.0020 (0.0096)  loss_flops: 0.3349 (0.1507)  flops: 3.0787 (2.8586)  grad_norm: 0.0049 (0.0098)  time: 0.4314  data: 0.0003  max mem: 10395
[2024-06-05 17:38:29 root] (utils.py 285): INFO Epoch: [0]  [ 570/5004]  eta: 0:33:41  lr_architecture: 0.010000  loss_cls: 3.3593 (3.1495)  loss_etrr_per_merge: 0.1686 (0.1092)  loss_tome: 0.1736 (0.0966)  etrr_loss: 0.0022 (0.0095)  loss_flops: 0.3271 (0.1538)  flops: 3.0719 (2.8623)  grad_norm: 0.0045 (0.0097)  time: 0.4311  data: 0.0003  max mem: 10397
[2024-06-05 17:38:33 root] (utils.py 285): INFO Epoch: [0]  [ 580/5004]  eta: 0:33:35  lr_architecture: 0.010000  loss_cls: 3.2349 (3.1488)  loss_etrr_per_merge: 0.1693 (0.1102)  loss_tome: 0.1736 (0.0979)  etrr_loss: 0.0020 (0.0094)  loss_flops: 0.3339 (0.1570)  flops: 3.0778 (2.8661)  grad_norm: 0.0036 (0.0096)  time: 0.4312  data: 0.0003  max mem: 10399
[2024-06-05 17:38:38 root] (utils.py 285): INFO Epoch: [0]  [ 590/5004]  eta: 0:33:29  lr_architecture: 0.010000  loss_cls: 3.1701 (3.1476)  loss_etrr_per_merge: 0.1706 (0.1113)  loss_tome: 0.1736 (0.0992)  etrr_loss: 0.0017 (0.0092)  loss_flops: 0.3454 (0.1604)  flops: 3.0877 (2.8700)  grad_norm: 0.0035 (0.0095)  time: 0.4312  data: 0.0004  max mem: 10399
[2024-06-05 17:38:42 root] (engine.py 137): INFO merge kept number:[197, 197, 178, 159, 138, 119, 119, 95, 101, 95, 95, 101]
[2024-06-05 17:38:42 root] (utils.py 285): INFO Epoch: [0]  [ 600/5004]  eta: 0:33:22  lr_architecture: 0.010000  loss_cls: 3.0674 (3.1443)  loss_etrr_per_merge: 0.1718 (0.1123)  loss_tome: 0.1736 (0.1004)  etrr_loss: 0.0016 (0.0091)  loss_flops: 0.3582 (0.1639)  flops: 3.0985 (2.8741)  grad_norm: 0.0029 (0.0094)  time: 0.4310  data: 0.0003  max mem: 10399
[2024-06-05 17:38:46 root] (utils.py 285): INFO Epoch: [0]  [ 610/5004]  eta: 0:33:16  lr_architecture: 0.010000  loss_cls: 3.0427 (3.1439)  loss_etrr_per_merge: 0.1738 (0.1133)  loss_tome: 0.1736 (0.1016)  etrr_loss: 0.0014 (0.0090)  loss_flops: 0.3785 (0.1674)  flops: 3.1152 (2.8780)  grad_norm: 0.0031 (0.0093)  time: 0.4314  data: 0.0003  max mem: 10402
[2024-06-05 17:38:51 root] (utils.py 285): INFO Epoch: [0]  [ 620/5004]  eta: 0:33:10  lr_architecture: 0.010000  loss_cls: 3.1745 (3.1449)  loss_etrr_per_merge: 0.1738 (0.1143)  loss_tome: 0.1736 (0.1028)  etrr_loss: 0.0014 (0.0088)  loss_flops: 0.3774 (0.1707)  flops: 3.1143 (2.8818)  grad_norm: 0.0032 (0.0092)  time: 0.4318  data: 0.0003  max mem: 10402
[2024-06-05 17:38:55 root] (utils.py 285): INFO Epoch: [0]  [ 630/5004]  eta: 0:33:04  lr_architecture: 0.010000  loss_cls: 3.1745 (3.1452)  loss_etrr_per_merge: 0.1728 (0.1152)  loss_tome: 0.1736 (0.1039)  etrr_loss: 0.0015 (0.0087)  loss_flops: 0.3666 (0.1737)  flops: 3.1055 (2.8852)  grad_norm: 0.0040 (0.0092)  time: 0.4317  data: 0.0003  max mem: 10402
[2024-06-05 17:38:59 root] (utils.py 285): INFO Epoch: [0]  [ 640/5004]  eta: 0:32:58  lr_architecture: 0.010000  loss_cls: 3.1330 (3.1421)  loss_etrr_per_merge: 0.1701 (0.1160)  loss_tome: 0.1736 (0.1050)  etrr_loss: 0.0019 (0.0086)  loss_flops: 0.3387 (0.1762)  flops: 3.0819 (2.8882)  grad_norm: 0.0035 (0.0091)  time: 0.4315  data: 0.0003  max mem: 10403
[2024-06-05 17:39:03 root] (utils.py 285): INFO Epoch: [0]  [ 650/5004]  eta: 0:32:52  lr_architecture: 0.010000  loss_cls: 3.0873 (3.1414)  loss_etrr_per_merge: 0.1693 (0.1168)  loss_tome: 0.1736 (0.1060)  etrr_loss: 0.0020 (0.0085)  loss_flops: 0.3308 (0.1783)  flops: 3.0751 (2.8908)  grad_norm: 0.0039 (0.0090)  time: 0.4316  data: 0.0003  max mem: 10404
[2024-06-05 17:39:08 root] (utils.py 285): INFO Epoch: [0]  [ 660/5004]  eta: 0:32:46  lr_architecture: 0.010000  loss_cls: 2.8801 (3.1343)  loss_etrr_per_merge: 0.1665 (0.1176)  loss_tome: 0.1736 (0.1071)  etrr_loss: 0.0025 (0.0084)  loss_flops: 0.3022 (0.1802)  flops: 3.0498 (2.8933)  grad_norm: 0.0041 (0.0089)  time: 0.4315  data: 0.0003  max mem: 10404
[2024-06-05 17:39:12 root] (utils.py 285): INFO Epoch: [0]  [ 670/5004]  eta: 0:32:40  lr_architecture: 0.010000  loss_cls: 3.0801 (3.1363)  loss_etrr_per_merge: 0.1667 (0.1183)  loss_tome: 0.1736 (0.1080)  etrr_loss: 0.0025 (0.0084)  loss_flops: 0.3045 (0.1821)  flops: 3.0518 (2.8956)  grad_norm: 0.0038 (0.0089)  time: 0.4312  data: 0.0003  max mem: 10404
[2024-06-05 17:39:16 root] (utils.py 285): INFO Epoch: [0]  [ 680/5004]  eta: 0:32:34  lr_architecture: 0.010000  loss_cls: 3.2426 (3.1364)  loss_etrr_per_merge: 0.1667 (0.1190)  loss_tome: 0.1736 (0.1090)  etrr_loss: 0.0024 (0.0083)  loss_flops: 0.3045 (0.1839)  flops: 3.0518 (2.8980)  grad_norm: 0.0038 (0.0088)  time: 0.4314  data: 0.0003  max mem: 10409
[2024-06-05 17:39:21 root] (utils.py 285): INFO Epoch: [0]  [ 690/5004]  eta: 0:32:28  lr_architecture: 0.010000  loss_cls: 2.8015 (3.1317)  loss_etrr_per_merge: 0.1672 (0.1197)  loss_tome: 0.1736 (0.1099)  etrr_loss: 0.0024 (0.0082)  loss_flops: 0.3080 (0.1858)  flops: 3.0549 (2.9003)  grad_norm: 0.0036 (0.0087)  time: 0.4317  data: 0.0003  max mem: 10409
[2024-06-05 17:39:25 root] (engine.py 137): INFO merge kept number:[197, 197, 181, 163, 142, 120, 120, 86, 101, 86, 86, 101]
[2024-06-05 17:39:25 root] (utils.py 285): INFO Epoch: [0]  [ 700/5004]  eta: 0:32:23  lr_architecture: 0.010000  loss_cls: 2.7775 (3.1283)  loss_etrr_per_merge: 0.1679 (0.1204)  loss_tome: 0.1736 (0.1108)  etrr_loss: 0.0023 (0.0081)  loss_flops: 0.3135 (0.1876)  flops: 3.0600 (2.9026)  grad_norm: 0.0032 (0.0087)  time: 0.4315  data: 0.0003  max mem: 10411
[2024-06-05 17:39:29 root] (utils.py 285): INFO Epoch: [0]  [ 710/5004]  eta: 0:32:17  lr_architecture: 0.010000  loss_cls: 2.8568 (3.1252)  loss_etrr_per_merge: 0.1681 (0.1211)  loss_tome: 0.1736 (0.1117)  etrr_loss: 0.0022 (0.0080)  loss_flops: 0.3158 (0.1894)  flops: 3.0619 (2.9048)  grad_norm: 0.0025 (0.0086)  time: 0.4315  data: 0.0003  max mem: 10411
[2024-06-05 17:39:34 root] (utils.py 285): INFO Epoch: [0]  [ 720/5004]  eta: 0:32:11  lr_architecture: 0.010000  loss_cls: 3.1594 (3.1208)  loss_etrr_per_merge: 0.1691 (0.1218)  loss_tome: 0.1736 (0.1126)  etrr_loss: 0.0021 (0.0079)  loss_flops: 0.3257 (0.1914)  flops: 3.0707 (2.9072)  grad_norm: 0.0031 (0.0085)  time: 0.4318  data: 0.0003  max mem: 10411
[2024-06-05 17:39:38 root] (utils.py 285): INFO Epoch: [0]  [ 730/5004]  eta: 0:32:06  lr_architecture: 0.010000  loss_cls: 3.1594 (3.1207)  loss_etrr_per_merge: 0.1703 (0.1224)  loss_tome: 0.1736 (0.1134)  etrr_loss: 0.0019 (0.0078)  loss_flops: 0.3382 (0.1936)  flops: 3.0816 (2.9097)  grad_norm: 0.0032 (0.0085)  time: 0.4322  data: 0.0003  max mem: 10411
[2024-06-05 17:39:42 root] (utils.py 285): INFO Epoch: [0]  [ 740/5004]  eta: 0:32:00  lr_architecture: 0.010000  loss_cls: 3.2458 (3.1231)  loss_etrr_per_merge: 0.1728 (0.1232)  loss_tome: 0.1736 (0.1142)  etrr_loss: 0.0015 (0.0078)  loss_flops: 0.3637 (0.1961)  flops: 3.1031 (2.9126)  grad_norm: 0.0036 (0.0084)  time: 0.4322  data: 0.0004  max mem: 10413
[2024-06-05 17:39:47 root] (utils.py 285): INFO Epoch: [0]  [ 750/5004]  eta: 0:31:54  lr_architecture: 0.010000  loss_cls: 3.2503 (3.1202)  loss_etrr_per_merge: 0.1756 (0.1239)  loss_tome: 0.1736 (0.1150)  etrr_loss: 0.0011 (0.0077)  loss_flops: 0.3927 (0.1990)  flops: 3.1267 (2.9156)  grad_norm: 0.0032 (0.0083)  time: 0.4318  data: 0.0004  max mem: 10413
[2024-06-05 17:39:51 root] (utils.py 285): INFO Epoch: [0]  [ 760/5004]  eta: 0:31:49  lr_architecture: 0.010000  loss_cls: 3.2813 (3.1185)  loss_etrr_per_merge: 0.1777 (0.1246)  loss_tome: 0.1736 (0.1158)  etrr_loss: 0.0009 (0.0076)  loss_flops: 0.4139 (0.2019)  flops: 3.1433 (2.9187)  grad_norm: 0.0032 (0.0083)  time: 0.4316  data: 0.0004  max mem: 10413
[2024-06-05 17:39:55 root] (utils.py 285): INFO Epoch: [0]  [ 770/5004]  eta: 0:31:43  lr_architecture: 0.010000  loss_cls: 3.3167 (3.1186)  loss_etrr_per_merge: 0.1783 (0.1253)  loss_tome: 0.1736 (0.1165)  etrr_loss: 0.0009 (0.0075)  loss_flops: 0.4202 (0.2047)  flops: 3.1482 (2.9216)  grad_norm: 0.0033 (0.0082)  time: 0.4317  data: 0.0004  max mem: 10413
[2024-06-05 17:40:00 root] (utils.py 285): INFO Epoch: [0]  [ 780/5004]  eta: 0:31:38  lr_architecture: 0.010000  loss_cls: 3.2825 (3.1193)  loss_etrr_per_merge: 0.1780 (0.1260)  loss_tome: 0.1736 (0.1173)  etrr_loss: 0.0009 (0.0074)  loss_flops: 0.4166 (0.2074)  flops: 3.1455 (2.9245)  grad_norm: 0.0031 (0.0081)  time: 0.4319  data: 0.0003  max mem: 10414
[2024-06-05 17:40:04 root] (utils.py 285): INFO Epoch: [0]  [ 790/5004]  eta: 0:31:33  lr_architecture: 0.010000  loss_cls: 3.0420 (3.1173)  loss_etrr_per_merge: 0.1788 (0.1266)  loss_tome: 0.1736 (0.1180)  etrr_loss: 0.0009 (0.0073)  loss_flops: 0.4243 (0.2102)  flops: 3.1514 (2.9274)  grad_norm: 0.0032 (0.0081)  time: 0.4321  data: 0.0004  max mem: 10415
[2024-06-05 17:40:08 root] (engine.py 137): INFO merge kept number:[197, 197, 183, 166, 145, 124, 124, 91, 101, 91, 91, 101]
[2024-06-05 17:40:08 root] (utils.py 285): INFO Epoch: [0]  [ 800/5004]  eta: 0:31:27  lr_architecture: 0.010000  loss_cls: 3.0420 (3.1175)  loss_etrr_per_merge: 0.1791 (0.1273)  loss_tome: 0.1736 (0.1187)  etrr_loss: 0.0009 (0.0072)  loss_flops: 0.4269 (0.2129)  flops: 3.1534 (2.9301)  grad_norm: 0.0034 (0.0080)  time: 0.4321  data: 0.0004  max mem: 10415
[2024-06-05 17:40:13 root] (utils.py 285): INFO Epoch: [0]  [ 810/5004]  eta: 0:31:22  lr_architecture: 0.010000  loss_cls: 2.7961 (3.1106)  loss_etrr_per_merge: 0.1772 (0.1279)  loss_tome: 0.1736 (0.1194)  etrr_loss: 0.0010 (0.0072)  loss_flops: 0.4067 (0.2152)  flops: 3.1377 (2.9327)  grad_norm: 0.0033 (0.0080)  time: 0.4322  data: 0.0003  max mem: 10416
[2024-06-05 17:40:17 root] (utils.py 285): INFO Epoch: [0]  [ 820/5004]  eta: 0:31:16  lr_architecture: 0.010000  loss_cls: 3.0441 (3.1113)  loss_etrr_per_merge: 0.1762 (0.1285)  loss_tome: 0.1736 (0.1200)  etrr_loss: 0.0011 (0.0071)  loss_flops: 0.3967 (0.2174)  flops: 3.1298 (2.9351)  grad_norm: 0.0036 (0.0079)  time: 0.4321  data: 0.0003  max mem: 10416
[2024-06-05 17:40:21 root] (utils.py 285): INFO Epoch: [0]  [ 830/5004]  eta: 0:31:11  lr_architecture: 0.010000  loss_cls: 3.2798 (3.1075)  loss_etrr_per_merge: 0.1759 (0.1291)  loss_tome: 0.1736 (0.1207)  etrr_loss: 0.0012 (0.0070)  loss_flops: 0.3941 (0.2195)  flops: 3.1278 (2.9374)  grad_norm: 0.0038 (0.0079)  time: 0.4318  data: 0.0003  max mem: 10416
[2024-06-05 17:40:26 root] (utils.py 285): INFO Epoch: [0]  [ 840/5004]  eta: 0:31:06  lr_architecture: 0.010000  loss_cls: 2.8308 (3.1061)  loss_etrr_per_merge: 0.1751 (0.1296)  loss_tome: 0.1736 (0.1213)  etrr_loss: 0.0013 (0.0070)  loss_flops: 0.3867 (0.2215)  flops: 3.1219 (2.9396)  grad_norm: 0.0038 (0.0079)  time: 0.4321  data: 0.0003  max mem: 10416
[2024-06-05 17:40:30 root] (utils.py 285): INFO Epoch: [0]  [ 850/5004]  eta: 0:31:01  lr_architecture: 0.010000  loss_cls: 3.1038 (3.1037)  loss_etrr_per_merge: 0.1759 (0.1302)  loss_tome: 0.1736 (0.1219)  etrr_loss: 0.0012 (0.0069)  loss_flops: 0.3943 (0.2236)  flops: 3.1279 (2.9418)  grad_norm: 0.0035 (0.0078)  time: 0.4323  data: 0.0003  max mem: 10416
[2024-06-05 17:40:34 root] (utils.py 285): INFO Epoch: [0]  [ 860/5004]  eta: 0:30:55  lr_architecture: 0.010000  loss_cls: 3.1188 (3.1032)  loss_etrr_per_merge: 0.1769 (0.1307)  loss_tome: 0.1736 (0.1225)  etrr_loss: 0.0010 (0.0068)  loss_flops: 0.4055 (0.2259)  flops: 3.1368 (2.9442)  grad_norm: 0.0035 (0.0078)  time: 0.4324  data: 0.0003  max mem: 10417
[2024-06-05 17:40:39 root] (utils.py 285): INFO Epoch: [0]  [ 870/5004]  eta: 0:30:50  lr_architecture: 0.010000  loss_cls: 3.1755 (3.1036)  loss_etrr_per_merge: 0.1780 (0.1313)  loss_tome: 0.1736 (0.1231)  etrr_loss: 0.0009 (0.0067)  loss_flops: 0.4156 (0.2280)  flops: 3.1447 (2.9465)  grad_norm: 0.0030 (0.0077)  time: 0.4321  data: 0.0004  max mem: 10419
[2024-06-05 17:40:43 root] (utils.py 285): INFO Epoch: [0]  [ 880/5004]  eta: 0:30:45  lr_architecture: 0.010000  loss_cls: 3.1037 (3.1003)  loss_etrr_per_merge: 0.1783 (0.1318)  loss_tome: 0.1736 (0.1237)  etrr_loss: 0.0009 (0.0067)  loss_flops: 0.4169 (0.2303)  flops: 3.1457 (2.9488)  grad_norm: 0.0030 (0.0077)  time: 0.4322  data: 0.0004  max mem: 10419
[2024-06-05 17:40:47 root] (utils.py 285): INFO Epoch: [0]  [ 890/5004]  eta: 0:30:40  lr_architecture: 0.010000  loss_cls: 3.0125 (3.0969)  loss_etrr_per_merge: 0.1783 (0.1323)  loss_tome: 0.1736 (0.1242)  etrr_loss: 0.0009 (0.0066)  loss_flops: 0.4159 (0.2323)  flops: 3.1449 (2.9510)  grad_norm: 0.0028 (0.0076)  time: 0.4324  data: 0.0003  max mem: 10422
[2024-06-05 17:40:52 root] (engine.py 137): INFO merge kept number:[197, 197, 185, 167, 147, 124, 124, 88, 101, 88, 88, 101]
[2024-06-05 17:40:52 root] (utils.py 285): INFO Epoch: [0]  [ 900/5004]  eta: 0:30:35  lr_architecture: 0.010000  loss_cls: 3.1301 (3.0969)  loss_etrr_per_merge: 0.1764 (0.1328)  loss_tome: 0.1736 (0.1248)  etrr_loss: 0.0011 (0.0066)  loss_flops: 0.3972 (0.2341)  flops: 3.1302 (2.9529)  grad_norm: 0.0028 (0.0076)  time: 0.4322  data: 0.0004  max mem: 10422
[2024-06-05 17:40:56 root] (utils.py 285): INFO Epoch: [0]  [ 910/5004]  eta: 0:30:29  lr_architecture: 0.010000  loss_cls: 3.2718 (3.0963)  loss_etrr_per_merge: 0.1764 (0.1333)  loss_tome: 0.1736 (0.1253)  etrr_loss: 0.0011 (0.0065)  loss_flops: 0.3972 (0.2359)  flops: 3.1302 (2.9549)  grad_norm: 0.0031 (0.0075)  time: 0.4323  data: 0.0004  max mem: 10422
[2024-06-05 17:41:00 root] (utils.py 285): INFO Epoch: [0]  [ 920/5004]  eta: 0:30:24  lr_architecture: 0.010000  loss_cls: 3.4102 (3.0976)  loss_etrr_per_merge: 0.1756 (0.1337)  loss_tome: 0.1736 (0.1258)  etrr_loss: 0.0011 (0.0064)  loss_flops: 0.3898 (0.2376)  flops: 3.1243 (2.9567)  grad_norm: 0.0031 (0.0075)  time: 0.4323  data: 0.0003  max mem: 10422
[2024-06-05 17:41:04 root] (utils.py 285): INFO Epoch: [0]  [ 930/5004]  eta: 0:30:19  lr_architecture: 0.010000  loss_cls: 3.3728 (3.1000)  loss_etrr_per_merge: 0.1764 (0.1342)  loss_tome: 0.1736 (0.1263)  etrr_loss: 0.0011 (0.0064)  loss_flops: 0.3983 (0.2393)  flops: 3.1311 (2.9586)  grad_norm: 0.0033 (0.0074)  time: 0.4322  data: 0.0003  max mem: 10422
[2024-06-05 17:41:09 root] (utils.py 285): INFO Epoch: [0]  [ 940/5004]  eta: 0:30:14  lr_architecture: 0.010000  loss_cls: 3.1659 (3.0989)  loss_etrr_per_merge: 0.1777 (0.1347)  loss_tome: 0.1736 (0.1268)  etrr_loss: 0.0010 (0.0063)  loss_flops: 0.4120 (0.2412)  flops: 3.1418 (2.9606)  grad_norm: 0.0033 (0.0074)  time: 0.4322  data: 0.0004  max mem: 10422
[2024-06-05 17:41:13 root] (utils.py 285): INFO Epoch: [0]  [ 950/5004]  eta: 0:30:09  lr_architecture: 0.010000  loss_cls: 2.7151 (3.0932)  loss_etrr_per_merge: 0.1780 (0.1351)  loss_tome: 0.1736 (0.1273)  etrr_loss: 0.0010 (0.0063)  loss_flops: 0.4146 (0.2430)  flops: 3.1439 (2.9625)  grad_norm: 0.0031 (0.0073)  time: 0.4320  data: 0.0004  max mem: 10422
[2024-06-05 17:41:17 root] (utils.py 285): INFO Epoch: [0]  [ 960/5004]  eta: 0:30:04  lr_architecture: 0.010000  loss_cls: 2.7504 (3.0933)  loss_etrr_per_merge: 0.1775 (0.1356)  loss_tome: 0.1736 (0.1278)  etrr_loss: 0.0010 (0.0062)  loss_flops: 0.4085 (0.2447)  flops: 3.1391 (2.9643)  grad_norm: 0.0036 (0.0073)  time: 0.4318  data: 0.0003  max mem: 10422
[2024-06-05 17:41:22 root] (utils.py 285): INFO Epoch: [0]  [ 970/5004]  eta: 0:29:59  lr_architecture: 0.010000  loss_cls: 3.1718 (3.0937)  loss_etrr_per_merge: 0.1772 (0.1360)  loss_tome: 0.1736 (0.1283)  etrr_loss: 0.0010 (0.0062)  loss_flops: 0.4060 (0.2463)  flops: 3.1372 (2.9661)  grad_norm: 0.0035 (0.0073)  time: 0.4319  data: 0.0003  max mem: 10423
[2024-06-05 17:41:26 root] (utils.py 285): INFO Epoch: [0]  [ 980/5004]  eta: 0:29:54  lr_architecture: 0.010000  loss_cls: 3.1619 (3.0936)  loss_etrr_per_merge: 0.1775 (0.1364)  loss_tome: 0.1736 (0.1288)  etrr_loss: 0.0010 (0.0061)  loss_flops: 0.4075 (0.2480)  flops: 3.1384 (2.9679)  grad_norm: 0.0030 (0.0072)  time: 0.4320  data: 0.0003  max mem: 10424
[2024-06-05 17:41:30 root] (utils.py 285): INFO Epoch: [0]  [ 990/5004]  eta: 0:29:49  lr_architecture: 0.010000  loss_cls: 3.2088 (3.0927)  loss_etrr_per_merge: 0.1780 (0.1368)  loss_tome: 0.1736 (0.1292)  etrr_loss: 0.0010 (0.0061)  loss_flops: 0.4127 (0.2497)  flops: 3.1424 (2.9697)  grad_norm: 0.0030 (0.0072)  time: 0.4319  data: 0.0003  max mem: 10424
[2024-06-05 17:41:35 root] (engine.py 137): INFO merge kept number:[197, 197, 186, 172, 148, 125, 125, 89, 101, 89, 89, 101]
[2024-06-05 17:41:35 root] (utils.py 285): INFO Epoch: [0]  [1000/5004]  eta: 0:29:44  lr_architecture: 0.010000  loss_cls: 3.0876 (3.0916)  loss_etrr_per_merge: 0.1788 (0.1373)  loss_tome: 0.1736 (0.1297)  etrr_loss: 0.0009 (0.0060)  loss_flops: 0.4204 (0.2515)  flops: 3.1484 (2.9715)  grad_norm: 0.0027 (0.0072)  time: 0.4319  data: 0.0004  max mem: 10428
[2024-06-05 17:41:39 root] (utils.py 285): INFO Epoch: [0]  [1010/5004]  eta: 0:29:39  lr_architecture: 0.010000  loss_cls: 3.0876 (3.0931)  loss_etrr_per_merge: 0.1788 (0.1377)  loss_tome: 0.1736 (0.1301)  etrr_loss: 0.0009 (0.0060)  loss_flops: 0.4204 (0.2531)  flops: 3.1484 (2.9732)  grad_norm: 0.0027 (0.0071)  time: 0.4320  data: 0.0004  max mem: 10428
[2024-06-05 17:41:43 root] (utils.py 285): INFO Epoch: [0]  [1020/5004]  eta: 0:29:34  lr_architecture: 0.010000  loss_cls: 3.3203 (3.0922)  loss_etrr_per_merge: 0.1780 (0.1381)  loss_tome: 0.1736 (0.1305)  etrr_loss: 0.0010 (0.0059)  loss_flops: 0.4117 (0.2546)  flops: 3.1416 (2.9749)  grad_norm: 0.0029 (0.0071)  time: 0.4324  data: 0.0003  max mem: 10432
[2024-06-05 17:41:48 root] (utils.py 285): INFO Epoch: [0]  [1030/5004]  eta: 0:29:31  lr_architecture: 0.010000  loss_cls: 3.0434 (3.0889)  loss_etrr_per_merge: 0.1788 (0.1385)  loss_tome: 0.1736 (0.1309)  etrr_loss: 0.0009 (0.0059)  loss_flops: 0.4193 (0.2564)  flops: 3.1475 (2.9767)  grad_norm: 0.0028 (0.0070)  time: 0.4537  data: 0.0003  max mem: 10432
[2024-06-05 17:41:52 root] (utils.py 285): INFO Epoch: [0]  [1040/5004]  eta: 0:29:26  lr_architecture: 0.010000  loss_cls: 3.0933 (3.0904)  loss_etrr_per_merge: 0.1824 (0.1389)  loss_tome: 0.1736 (0.1313)  etrr_loss: 0.0006 (0.0058)  loss_flops: 0.4556 (0.2584)  flops: 3.1750 (2.9786)  grad_norm: 0.0028 (0.0070)  time: 0.4535  data: 0.0004  max mem: 10432
[2024-06-05 17:41:57 root] (utils.py 285): INFO Epoch: [0]  [1050/5004]  eta: 0:29:21  lr_architecture: 0.010000  loss_cls: 3.1703 (3.0890)  loss_etrr_per_merge: 0.1841 (0.1393)  loss_tome: 0.1736 (0.1317)  etrr_loss: 0.0005 (0.0058)  loss_flops: 0.4731 (0.2605)  flops: 3.1878 (2.9807)  grad_norm: 0.0032 (0.0070)  time: 0.4321  data: 0.0003  max mem: 10432
[2024-06-05 17:42:01 root] (utils.py 285): INFO Epoch: [0]  [1060/5004]  eta: 0:29:16  lr_architecture: 0.010000  loss_cls: 3.1214 (3.0895)  loss_etrr_per_merge: 0.1858 (0.1398)  loss_tome: 0.1736 (0.1321)  etrr_loss: 0.0003 (0.0057)  loss_flops: 0.4920 (0.2628)  flops: 3.2015 (2.9829)  grad_norm: 0.0035 (0.0069)  time: 0.4316  data: 0.0003  max mem: 10432
[2024-06-05 17:42:05 root] (utils.py 285): INFO Epoch: [0]  [1070/5004]  eta: 0:29:11  lr_architecture: 0.010000  loss_cls: 3.1575 (3.0886)  loss_etrr_per_merge: 0.1867 (0.1402)  loss_tome: 0.1736 (0.1325)  etrr_loss: 0.0003 (0.0057)  loss_flops: 0.5016 (0.2650)  flops: 3.2083 (2.9849)  grad_norm: 0.0035 (0.0069)  time: 0.4314  data: 0.0003  max mem: 10432
[2024-06-05 17:42:10 root] (utils.py 285): INFO Epoch: [0]  [1080/5004]  eta: 0:29:06  lr_architecture: 0.010000  loss_cls: 3.1488 (3.0875)  loss_etrr_per_merge: 0.1856 (0.1406)  loss_tome: 0.1736 (0.1329)  etrr_loss: 0.0004 (0.0056)  loss_flops: 0.4892 (0.2671)  flops: 3.1994 (2.9869)  grad_norm: 0.0034 (0.0069)  time: 0.4316  data: 0.0003  max mem: 10432
[2024-06-05 17:42:14 root] (utils.py 285): INFO Epoch: [0]  [1090/5004]  eta: 0:29:01  lr_architecture: 0.010000  loss_cls: 2.9539 (3.0856)  loss_etrr_per_merge: 0.1858 (0.1411)  loss_tome: 0.1736 (0.1333)  etrr_loss: 0.0003 (0.0056)  loss_flops: 0.4920 (0.2692)  flops: 3.2014 (2.9889)  grad_norm: 0.0034 (0.0068)  time: 0.4320  data: 0.0003  max mem: 10432
[2024-06-05 17:42:18 root] (engine.py 137): INFO merge kept number:[197, 197, 187, 173, 152, 129, 129, 94, 101, 94, 94, 101]
[2024-06-05 17:42:18 root] (utils.py 285): INFO Epoch: [0]  [1100/5004]  eta: 0:28:56  lr_architecture: 0.010000  loss_cls: 2.9523 (3.0843)  loss_etrr_per_merge: 0.1882 (0.1415)  loss_tome: 0.1736 (0.1336)  etrr_loss: 0.0002 (0.0055)  loss_flops: 0.5158 (0.2715)  flops: 3.2182 (2.9910)  grad_norm: 0.0034 (0.0068)  time: 0.4324  data: 0.0003  max mem: 10432
[2024-06-05 17:42:23 root] (utils.py 285): INFO Epoch: [0]  [1110/5004]  eta: 0:28:51  lr_architecture: 0.010000  loss_cls: 3.2106 (3.0842)  loss_etrr_per_merge: 0.1885 (0.1419)  loss_tome: 0.1736 (0.1340)  etrr_loss: 0.0002 (0.0055)  loss_flops: 0.5188 (0.2737)  flops: 3.2203 (2.9931)  grad_norm: 0.0030 (0.0068)  time: 0.4323  data: 0.0003  max mem: 10432
[2024-06-05 17:42:27 root] (utils.py 285): INFO Epoch: [0]  [1120/5004]  eta: 0:28:46  lr_architecture: 0.010000  loss_cls: 3.2163 (3.0852)  loss_etrr_per_merge: 0.1885 (0.1423)  loss_tome: 0.1736 (0.1344)  etrr_loss: 0.0002 (0.0054)  loss_flops: 0.5188 (0.2759)  flops: 3.2203 (2.9951)  grad_norm: 0.0028 (0.0068)  time: 0.4315  data: 0.0003  max mem: 10432
[2024-06-05 17:42:31 root] (utils.py 285): INFO Epoch: [0]  [1130/5004]  eta: 0:28:41  lr_architecture: 0.010000  loss_cls: 3.2056 (3.0859)  loss_etrr_per_merge: 0.1885 (0.1427)  loss_tome: 0.1736 (0.1347)  etrr_loss: 0.0002 (0.0054)  loss_flops: 0.5188 (0.2781)  flops: 3.2203 (2.9971)  grad_norm: 0.0028 (0.0067)  time: 0.4314  data: 0.0003  max mem: 10432
[2024-06-05 17:42:36 root] (utils.py 285): INFO Epoch: [0]  [1140/5004]  eta: 0:28:36  lr_architecture: 0.010000  loss_cls: 3.1279 (3.0843)  loss_etrr_per_merge: 0.1885 (0.1431)  loss_tome: 0.1736 (0.1350)  etrr_loss: 0.0002 (0.0053)  loss_flops: 0.5188 (0.2801)  flops: 3.2203 (2.9990)  grad_norm: 0.0029 (0.0067)  time: 0.4317  data: 0.0003  max mem: 10432
[2024-06-05 17:42:40 root] (utils.py 285): INFO Epoch: [0]  [1150/5004]  eta: 0:28:32  lr_architecture: 0.010000  loss_cls: 3.0293 (3.0842)  loss_etrr_per_merge: 0.1885 (0.1435)  loss_tome: 0.1736 (0.1354)  etrr_loss: 0.0002 (0.0053)  loss_flops: 0.5188 (0.2822)  flops: 3.2203 (3.0010)  grad_norm: 0.0029 (0.0067)  time: 0.4314  data: 0.0003  max mem: 10432
[2024-06-05 17:42:44 root] (utils.py 285): INFO Epoch: [0]  [1160/5004]  eta: 0:28:27  lr_architecture: 0.010000  loss_cls: 3.2152 (3.0835)  loss_etrr_per_merge: 0.1894 (0.1439)  loss_tome: 0.1736 (0.1357)  etrr_loss: 0.0002 (0.0052)  loss_flops: 0.5274 (0.2844)  flops: 3.2263 (3.0029)  grad_norm: 0.0029 (0.0066)  time: 0.4318  data: 0.0003  max mem: 10433
[2024-06-05 17:42:49 root] (utils.py 285): INFO Epoch: [0]  [1170/5004]  eta: 0:28:22  lr_architecture: 0.010000  loss_cls: 3.2271 (3.0829)  loss_etrr_per_merge: 0.1903 (0.1443)  loss_tome: 0.1736 (0.1360)  etrr_loss: 0.0002 (0.0052)  loss_flops: 0.5361 (0.2865)  flops: 3.2322 (3.0049)  grad_norm: 0.0027 (0.0066)  time: 0.4319  data: 0.0003  max mem: 10433
[2024-06-05 17:42:53 root] (utils.py 285): INFO Epoch: [0]  [1180/5004]  eta: 0:28:17  lr_architecture: 0.010000  loss_cls: 3.2204 (3.0846)  loss_etrr_per_merge: 0.1910 (0.1447)  loss_tome: 0.1736 (0.1363)  etrr_loss: 0.0001 (0.0051)  loss_flops: 0.5419 (0.2887)  flops: 3.2361 (3.0069)  grad_norm: 0.0027 (0.0066)  time: 0.4315  data: 0.0003  max mem: 10433
[2024-06-05 17:42:57 root] (utils.py 285): INFO Epoch: [0]  [1190/5004]  eta: 0:28:12  lr_architecture: 0.010000  loss_cls: 3.3012 (3.0858)  loss_etrr_per_merge: 0.1906 (0.1451)  loss_tome: 0.1736 (0.1367)  etrr_loss: 0.0002 (0.0051)  loss_flops: 0.5390 (0.2907)  flops: 3.2341 (3.0087)  grad_norm: 0.0033 (0.0066)  time: 0.4317  data: 0.0003  max mem: 10433
[2024-06-05 17:43:02 root] (engine.py 137): INFO merge kept number:[197, 197, 188, 173, 152, 131, 131, 94, 101, 94, 94, 101]
[2024-06-05 17:43:02 root] (utils.py 285): INFO Epoch: [0]  [1200/5004]  eta: 0:28:07  lr_architecture: 0.010000  loss_cls: 3.2901 (3.0863)  loss_etrr_per_merge: 0.1900 (0.1455)  loss_tome: 0.1736 (0.1370)  etrr_loss: 0.0002 (0.0051)  loss_flops: 0.5332 (0.2927)  flops: 3.2302 (3.0106)  grad_norm: 0.0029 (0.0065)  time: 0.4316  data: 0.0003  max mem: 10433
[2024-06-05 17:43:06 root] (utils.py 285): INFO Epoch: [0]  [1210/5004]  eta: 0:28:03  lr_architecture: 0.010000  loss_cls: 3.1312 (3.0859)  loss_etrr_per_merge: 0.1903 (0.1459)  loss_tome: 0.1736 (0.1373)  etrr_loss: 0.0002 (0.0050)  loss_flops: 0.5362 (0.2947)  flops: 3.2322 (3.0124)  grad_norm: 0.0032 (0.0065)  time: 0.4320  data: 0.0003  max mem: 10433
[2024-06-05 17:43:10 root] (utils.py 285): INFO Epoch: [0]  [1220/5004]  eta: 0:27:58  lr_architecture: 0.010000  loss_cls: 3.0040 (3.0844)  loss_etrr_per_merge: 0.1913 (0.1462)  loss_tome: 0.1736 (0.1376)  etrr_loss: 0.0001 (0.0050)  loss_flops: 0.5462 (0.2969)  flops: 3.2390 (3.0144)  grad_norm: 0.0037 (0.0065)  time: 0.4324  data: 0.0003  max mem: 10433
[2024-06-05 17:43:15 root] (utils.py 285): INFO Epoch: [0]  [1230/5004]  eta: 0:27:53  lr_architecture: 0.010000  loss_cls: 3.0367 (3.0847)  loss_etrr_per_merge: 0.1957 (0.1466)  loss_tome: 0.1736 (0.1379)  etrr_loss: 0.0000 (0.0049)  loss_flops: 0.5910 (0.2994)  flops: 3.2688 (3.0165)  grad_norm: 0.0030 (0.0065)  time: 0.4321  data: 0.0003  max mem: 10433
[2024-06-05 17:43:19 root] (utils.py 285): INFO Epoch: [0]  [1240/5004]  eta: 0:27:48  lr_architecture: 0.010000  loss_cls: 3.0367 (3.0840)  loss_etrr_per_merge: 0.1957 (0.1470)  loss_tome: 0.1736 (0.1381)  etrr_loss: 0.0000 (0.0049)  loss_flops: 0.5910 (0.3017)  flops: 3.2688 (3.0185)  grad_norm: 0.0029 (0.0064)  time: 0.4319  data: 0.0003  max mem: 10433
[2024-06-05 17:43:23 root] (utils.py 285): INFO Epoch: [0]  [1250/5004]  eta: 0:27:43  lr_architecture: 0.010000  loss_cls: 2.9050 (3.0824)  loss_etrr_per_merge: 0.1963 (0.1474)  loss_tome: 0.1736 (0.1384)  etrr_loss: 0.0000 (0.0049)  loss_flops: 0.5984 (0.3041)  flops: 3.2736 (3.0205)  grad_norm: 0.0029 (0.0064)  time: 0.4319  data: 0.0003  max mem: 10433
[2024-06-05 17:43:28 root] (utils.py 285): INFO Epoch: [0]  [1260/5004]  eta: 0:27:39  lr_architecture: 0.010000  loss_cls: 3.0996 (3.0829)  loss_etrr_per_merge: 0.1960 (0.1478)  loss_tome: 0.1736 (0.1387)  etrr_loss: 0.0000 (0.0048)  loss_flops: 0.5953 (0.3064)  flops: 3.2716 (3.0225)  grad_norm: 0.0030 (0.0064)  time: 0.4320  data: 0.0003  max mem: 10433
[2024-06-05 17:43:32 root] (utils.py 285): INFO Epoch: [0]  [1270/5004]  eta: 0:27:34  lr_architecture: 0.010000  loss_cls: 3.1926 (3.0833)  loss_etrr_per_merge: 0.1960 (0.1482)  loss_tome: 0.1736 (0.1390)  etrr_loss: 0.0000 (0.0048)  loss_flops: 0.5953 (0.3087)  flops: 3.2716 (3.0245)  grad_norm: 0.0032 (0.0064)  time: 0.4321  data: 0.0003  max mem: 10433
[2024-06-05 17:43:36 root] (utils.py 285): INFO Epoch: [0]  [1280/5004]  eta: 0:27:29  lr_architecture: 0.010000  loss_cls: 3.2622 (3.0852)  loss_etrr_per_merge: 0.1960 (0.1486)  loss_tome: 0.1736 (0.1393)  etrr_loss: 0.0000 (0.0048)  loss_flops: 0.5953 (0.3110)  flops: 3.2716 (3.0265)  grad_norm: 0.0040 (0.0063)  time: 0.4319  data: 0.0003  max mem: 10433
[2024-06-05 17:43:40 root] (utils.py 285): INFO Epoch: [0]  [1290/5004]  eta: 0:27:24  lr_architecture: 0.010000  loss_cls: 3.3503 (3.0862)  loss_etrr_per_merge: 0.1957 (0.1489)  loss_tome: 0.1736 (0.1395)  etrr_loss: 0.0000 (0.0047)  loss_flops: 0.5924 (0.3132)  flops: 3.2697 (3.0283)  grad_norm: 0.0040 (0.0063)  time: 0.4317  data: 0.0003  max mem: 10433
[2024-06-05 17:43:45 root] (engine.py 137): INFO merge kept number:[197, 197, 189, 175, 152, 129, 129, 95, 101, 95, 95, 101]
[2024-06-05 17:43:45 root] (utils.py 285): INFO Epoch: [0]  [1300/5004]  eta: 0:27:20  lr_architecture: 0.010000  loss_cls: 3.1530 (3.0857)  loss_etrr_per_merge: 0.1935 (0.1493)  loss_tome: 0.1736 (0.1398)  etrr_loss: 0.0001 (0.0047)  loss_flops: 0.5700 (0.3150)  flops: 3.2550 (3.0300)  grad_norm: 0.0031 (0.0063)  time: 0.4320  data: 0.0003  max mem: 10433
[2024-06-05 17:43:49 root] (utils.py 285): INFO Epoch: [0]  [1310/5004]  eta: 0:27:15  lr_architecture: 0.010000  loss_cls: 2.9473 (3.0835)  loss_etrr_per_merge: 0.1910 (0.1496)  loss_tome: 0.1736 (0.1400)  etrr_loss: 0.0001 (0.0046)  loss_flops: 0.5436 (0.3167)  flops: 3.2373 (3.0315)  grad_norm: 0.0035 (0.0063)  time: 0.4324  data: 0.0003  max mem: 10433
[2024-06-05 17:43:53 root] (utils.py 285): INFO Epoch: [0]  [1320/5004]  eta: 0:27:10  lr_architecture: 0.010000  loss_cls: 2.8835 (3.0805)  loss_etrr_per_merge: 0.1879 (0.1499)  loss_tome: 0.1736 (0.1403)  etrr_loss: 0.0002 (0.0046)  loss_flops: 0.5122 (0.3181)  flops: 3.2157 (3.0328)  grad_norm: 0.0032 (0.0063)  time: 0.4320  data: 0.0003  max mem: 10433
[2024-06-05 17:43:58 root] (utils.py 285): INFO Epoch: [0]  [1330/5004]  eta: 0:27:05  lr_architecture: 0.010000  loss_cls: 2.9881 (3.0809)  loss_etrr_per_merge: 0.1861 (0.1501)  loss_tome: 0.1736 (0.1405)  etrr_loss: 0.0003 (0.0046)  loss_flops: 0.4941 (0.3194)  flops: 3.2029 (3.0341)  grad_norm: 0.0032 (0.0062)  time: 0.4320  data: 0.0003  max mem: 10433
[2024-06-05 17:44:02 root] (utils.py 285): INFO Epoch: [0]  [1340/5004]  eta: 0:27:01  lr_architecture: 0.010000  loss_cls: 3.4120 (3.0816)  loss_etrr_per_merge: 0.1853 (0.1504)  loss_tome: 0.1736 (0.1408)  etrr_loss: 0.0004 (0.0045)  loss_flops: 0.4846 (0.3205)  flops: 3.1961 (3.0352)  grad_norm: 0.0034 (0.0062)  time: 0.4322  data: 0.0003  max mem: 10433
[2024-06-05 17:44:06 root] (utils.py 285): INFO Epoch: [0]  [1350/5004]  eta: 0:26:56  lr_architecture: 0.010000  loss_cls: 3.2255 (3.0815)  loss_etrr_per_merge: 0.1821 (0.1506)  loss_tome: 0.1736 (0.1410)  etrr_loss: 0.0005 (0.0045)  loss_flops: 0.4523 (0.3215)  flops: 3.1726 (3.0362)  grad_norm: 0.0032 (0.0062)  time: 0.4319  data: 0.0003  max mem: 10433
[2024-06-05 17:44:11 root] (utils.py 285): INFO Epoch: [0]  [1360/5004]  eta: 0:26:51  lr_architecture: 0.010000  loss_cls: 3.1910 (3.0824)  loss_etrr_per_merge: 0.1821 (0.1509)  loss_tome: 0.1736 (0.1413)  etrr_loss: 0.0006 (0.0045)  loss_flops: 0.4523 (0.3224)  flops: 3.1726 (3.0373)  grad_norm: 0.0030 (0.0062)  time: 0.4318  data: 0.0003  max mem: 10433
[2024-06-05 17:44:15 root] (utils.py 285): INFO Epoch: [0]  [1370/5004]  eta: 0:26:47  lr_architecture: 0.010000  loss_cls: 3.3345 (3.0840)  loss_etrr_per_merge: 0.1830 (0.1511)  loss_tome: 0.1736 (0.1415)  etrr_loss: 0.0005 (0.0045)  loss_flops: 0.4615 (0.3235)  flops: 3.1793 (3.0383)  grad_norm: 0.0024 (0.0061)  time: 0.4317  data: 0.0003  max mem: 10433
[2024-06-05 17:44:19 root] (utils.py 285): INFO Epoch: [0]  [1380/5004]  eta: 0:26:42  lr_architecture: 0.010000  loss_cls: 3.2484 (3.0844)  loss_etrr_per_merge: 0.1841 (0.1513)  loss_tome: 0.1736 (0.1417)  etrr_loss: 0.0005 (0.0044)  loss_flops: 0.4735 (0.3246)  flops: 3.1881 (3.0394)  grad_norm: 0.0026 (0.0061)  time: 0.4315  data: 0.0003  max mem: 10433
[2024-06-05 17:44:24 root] (utils.py 285): INFO Epoch: [0]  [1390/5004]  eta: 0:26:37  lr_architecture: 0.010000  loss_cls: 3.1415 (3.0837)  loss_etrr_per_merge: 0.1841 (0.1516)  loss_tome: 0.1736 (0.1420)  etrr_loss: 0.0005 (0.0044)  loss_flops: 0.4733 (0.3257)  flops: 3.1880 (3.0405)  grad_norm: 0.0034 (0.0061)  time: 0.4319  data: 0.0003  max mem: 10433
[2024-06-05 17:44:28 root] (engine.py 137): INFO merge kept number:[197, 197, 189, 172, 151, 127, 127, 92, 101, 92, 92, 101]
[2024-06-05 17:44:28 root] (utils.py 285): INFO Epoch: [0]  [1400/5004]  eta: 0:26:33  lr_architecture: 0.010000  loss_cls: 3.1415 (3.0833)  loss_etrr_per_merge: 0.1835 (0.1518)  loss_tome: 0.1736 (0.1422)  etrr_loss: 0.0005 (0.0044)  loss_flops: 0.4680 (0.3267)  flops: 3.1841 (3.0415)  grad_norm: 0.0027 (0.0061)  time: 0.4326  data: 0.0003  max mem: 10433
[2024-06-05 17:44:32 root] (utils.py 285): INFO Epoch: [0]  [1410/5004]  eta: 0:26:28  lr_architecture: 0.010000  loss_cls: 3.2258 (3.0848)  loss_etrr_per_merge: 0.1850 (0.1520)  loss_tome: 0.1736 (0.1424)  etrr_loss: 0.0004 (0.0043)  loss_flops: 0.4828 (0.3279)  flops: 3.1948 (3.0427)  grad_norm: 0.0034 (0.0061)  time: 0.4327  data: 0.0003  max mem: 10433
[2024-06-05 17:44:37 root] (utils.py 285): INFO Epoch: [0]  [1420/5004]  eta: 0:26:23  lr_architecture: 0.010000  loss_cls: 3.1498 (3.0841)  loss_etrr_per_merge: 0.1867 (0.1523)  loss_tome: 0.1736 (0.1426)  etrr_loss: 0.0003 (0.0043)  loss_flops: 0.5007 (0.3292)  flops: 3.2076 (3.0439)  grad_norm: 0.0039 (0.0061)  time: 0.4325  data: 0.0004  max mem: 10433
[2024-06-05 17:44:41 root] (utils.py 285): INFO Epoch: [0]  [1430/5004]  eta: 0:26:19  lr_architecture: 0.010000  loss_cls: 3.0959 (3.0838)  loss_etrr_per_merge: 0.1888 (0.1525)  loss_tome: 0.1736 (0.1429)  etrr_loss: 0.0002 (0.0043)  loss_flops: 0.5219 (0.3305)  flops: 3.2224 (3.0451)  grad_norm: 0.0033 (0.0061)  time: 0.4323  data: 0.0003  max mem: 10433
[2024-06-05 17:44:45 root] (utils.py 285): INFO Epoch: [0]  [1440/5004]  eta: 0:26:14  lr_architecture: 0.010000  loss_cls: 3.0444 (3.0833)  loss_etrr_per_merge: 0.1879 (0.1528)  loss_tome: 0.1736 (0.1431)  etrr_loss: 0.0003 (0.0043)  loss_flops: 0.5121 (0.3317)  flops: 3.2156 (3.0463)  grad_norm: 0.0034 (0.0060)  time: 0.4319  data: 0.0003  max mem: 10433
[2024-06-05 17:44:50 root] (utils.py 285): INFO Epoch: [0]  [1450/5004]  eta: 0:26:09  lr_architecture: 0.010000  loss_cls: 3.2062 (3.0835)  loss_etrr_per_merge: 0.1864 (0.1530)  loss_tome: 0.1736 (0.1433)  etrr_loss: 0.0003 (0.0042)  loss_flops: 0.4967 (0.3328)  flops: 3.2048 (3.0473)  grad_norm: 0.0030 (0.0060)  time: 0.4320  data: 0.0003  max mem: 10433
[2024-06-05 17:44:54 root] (utils.py 285): INFO Epoch: [0]  [1460/5004]  eta: 0:26:05  lr_architecture: 0.010000  loss_cls: 3.2062 (3.0840)  loss_etrr_per_merge: 0.1838 (0.1532)  loss_tome: 0.1736 (0.1435)  etrr_loss: 0.0004 (0.0042)  loss_flops: 0.4707 (0.3337)  flops: 3.1861 (3.0482)  grad_norm: 0.0037 (0.0060)  time: 0.4323  data: 0.0003  max mem: 10433
[2024-06-05 17:44:58 root] (utils.py 285): INFO Epoch: [0]  [1470/5004]  eta: 0:26:00  lr_architecture: 0.010000  loss_cls: 3.1798 (3.0837)  loss_etrr_per_merge: 0.1833 (0.1534)  loss_tome: 0.1736 (0.1437)  etrr_loss: 0.0005 (0.0042)  loss_flops: 0.4653 (0.3346)  flops: 3.1822 (3.0491)  grad_norm: 0.0036 (0.0060)  time: 0.4319  data: 0.0003  max mem: 10433
[2024-06-05 17:45:03 root] (utils.py 285): INFO Epoch: [0]  [1480/5004]  eta: 0:25:55  lr_architecture: 0.010000  loss_cls: 2.8524 (3.0817)  loss_etrr_per_merge: 0.1824 (0.1536)  loss_tome: 0.1736 (0.1439)  etrr_loss: 0.0006 (0.0042)  loss_flops: 0.4585 (0.3354)  flops: 3.1771 (3.0500)  grad_norm: 0.0033 (0.0060)  time: 0.4316  data: 0.0003  max mem: 10433
[2024-06-05 17:45:07 root] (utils.py 285): INFO Epoch: [0]  [1490/5004]  eta: 0:25:51  lr_architecture: 0.010000  loss_cls: 2.6916 (3.0786)  loss_etrr_per_merge: 0.1824 (0.1538)  loss_tome: 0.1736 (0.1441)  etrr_loss: 0.0006 (0.0041)  loss_flops: 0.4585 (0.3363)  flops: 3.1771 (3.0509)  grad_norm: 0.0033 (0.0060)  time: 0.4318  data: 0.0003  max mem: 10433
[2024-06-05 17:45:11 root] (engine.py 137): INFO merge kept number:[197, 197, 190, 173, 149, 125, 125, 95, 101, 95, 95, 101]
[2024-06-05 17:45:11 root] (utils.py 285): INFO Epoch: [0]  [1500/5004]  eta: 0:25:46  lr_architecture: 0.010000  loss_cls: 2.8613 (3.0776)  loss_etrr_per_merge: 0.1856 (0.1540)  loss_tome: 0.1736 (0.1443)  etrr_loss: 0.0003 (0.0041)  loss_flops: 0.4910 (0.3375)  flops: 3.2007 (3.0520)  grad_norm: 0.0035 (0.0059)  time: 0.4322  data: 0.0003  max mem: 10433
[2024-06-05 17:45:16 root] (utils.py 285): INFO Epoch: [0]  [1510/5004]  eta: 0:25:41  lr_architecture: 0.010000  loss_cls: 3.0906 (3.0784)  loss_etrr_per_merge: 0.1870 (0.1543)  loss_tome: 0.1736 (0.1445)  etrr_loss: 0.0003 (0.0041)  loss_flops: 0.5063 (0.3386)  flops: 3.2116 (3.0531)  grad_norm: 0.0031 (0.0059)  time: 0.4318  data: 0.0003  max mem: 10433
[2024-06-05 17:45:20 root] (utils.py 285): INFO Epoch: [0]  [1520/5004]  eta: 0:25:37  lr_architecture: 0.010000  loss_cls: 3.2238 (3.0792)  loss_etrr_per_merge: 0.1864 (0.1545)  loss_tome: 0.1736 (0.1447)  etrr_loss: 0.0003 (0.0041)  loss_flops: 0.4995 (0.3396)  flops: 3.2068 (3.0541)  grad_norm: 0.0029 (0.0059)  time: 0.4313  data: 0.0003  max mem: 10433
[2024-06-05 17:45:24 root] (utils.py 285): INFO Epoch: [0]  [1530/5004]  eta: 0:25:32  lr_architecture: 0.010000  loss_cls: 3.0942 (3.0781)  loss_etrr_per_merge: 0.1864 (0.1547)  loss_tome: 0.1736 (0.1449)  etrr_loss: 0.0003 (0.0040)  loss_flops: 0.4995 (0.3407)  flops: 3.2068 (3.0551)  grad_norm: 0.0029 (0.0059)  time: 0.4315  data: 0.0002  max mem: 10433
[2024-06-05 17:45:29 root] (utils.py 285): INFO Epoch: [0]  [1540/5004]  eta: 0:25:28  lr_architecture: 0.010000  loss_cls: 3.0885 (3.0782)  loss_etrr_per_merge: 0.1867 (0.1549)  loss_tome: 0.1736 (0.1450)  etrr_loss: 0.0003 (0.0040)  loss_flops: 0.5023 (0.3417)  flops: 3.2088 (3.0560)  grad_norm: 0.0038 (0.0059)  time: 0.4316  data: 0.0003  max mem: 10433
[2024-06-05 17:45:33 root] (utils.py 285): INFO Epoch: [0]  [1550/5004]  eta: 0:25:23  lr_architecture: 0.010000  loss_cls: 3.1181 (3.0768)  loss_etrr_per_merge: 0.1864 (0.1551)  loss_tome: 0.1736 (0.1452)  etrr_loss: 0.0003 (0.0040)  loss_flops: 0.5007 (0.3428)  flops: 3.2076 (3.0570)  grad_norm: 0.0034 (0.0059)  time: 0.4316  data: 0.0003  max mem: 10433
[2024-06-05 17:45:37 root] (utils.py 285): INFO Epoch: [0]  [1560/5004]  eta: 0:25:18  lr_architecture: 0.010000  loss_cls: 3.1181 (3.0763)  loss_etrr_per_merge: 0.1870 (0.1553)  loss_tome: 0.1736 (0.1454)  etrr_loss: 0.0003 (0.0040)  loss_flops: 0.5076 (0.3439)  flops: 3.2124 (3.0581)  grad_norm: 0.0034 (0.0059)  time: 0.4317  data: 0.0003  max mem: 10433
[2024-06-05 17:45:41 root] (utils.py 285): INFO Epoch: [0]  [1570/5004]  eta: 0:25:14  lr_architecture: 0.010000  loss_cls: 2.8876 (3.0739)  loss_etrr_per_merge: 0.1870 (0.1555)  loss_tome: 0.1736 (0.1456)  etrr_loss: 0.0003 (0.0039)  loss_flops: 0.5076 (0.3448)  flops: 3.2124 (3.0590)  grad_norm: 0.0033 (0.0058)  time: 0.4317  data: 0.0003  max mem: 10433
[2024-06-05 17:45:46 root] (utils.py 285): INFO Epoch: [0]  [1580/5004]  eta: 0:25:09  lr_architecture: 0.010000  loss_cls: 2.8085 (3.0731)  loss_etrr_per_merge: 0.1858 (0.1557)  loss_tome: 0.1736 (0.1458)  etrr_loss: 0.0004 (0.0039)  loss_flops: 0.4951 (0.3458)  flops: 3.2036 (3.0599)  grad_norm: 0.0038 (0.0058)  time: 0.4323  data: 0.0003  max mem: 10433
[2024-06-05 17:45:50 root] (utils.py 285): INFO Epoch: [0]  [1590/5004]  eta: 0:25:05  lr_architecture: 0.010000  loss_cls: 3.1886 (3.0736)  loss_etrr_per_merge: 0.1847 (0.1559)  loss_tome: 0.1736 (0.1459)  etrr_loss: 0.0004 (0.0039)  loss_flops: 0.4839 (0.3466)  flops: 3.1957 (3.0607)  grad_norm: 0.0038 (0.0058)  time: 0.4330  data: 0.0004  max mem: 10433
[2024-06-05 17:45:54 root] (engine.py 137): INFO merge kept number:[197, 197, 190, 170, 147, 121, 121, 94, 101, 94, 94, 101]
[2024-06-05 17:45:54 root] (utils.py 285): INFO Epoch: [0]  [1600/5004]  eta: 0:25:00  lr_architecture: 0.010000  loss_cls: 3.2897 (3.0751)  loss_etrr_per_merge: 0.1824 (0.1560)  loss_tome: 0.1736 (0.1461)  etrr_loss: 0.0005 (0.0039)  loss_flops: 0.4610 (0.3473)  flops: 3.1790 (3.0615)  grad_norm: 0.0038 (0.0058)  time: 0.4324  data: 0.0004  max mem: 10433
[2024-06-05 17:45:59 root] (utils.py 285): INFO Epoch: [0]  [1610/5004]  eta: 0:24:55  lr_architecture: 0.010000  loss_cls: 3.2897 (3.0756)  loss_etrr_per_merge: 0.1824 (0.1562)  loss_tome: 0.1736 (0.1463)  etrr_loss: 0.0006 (0.0039)  loss_flops: 0.4610 (0.3481)  flops: 3.1790 (3.0623)  grad_norm: 0.0038 (0.0058)  time: 0.4321  data: 0.0003  max mem: 10433
[2024-06-05 17:46:03 root] (utils.py 285): INFO Epoch: [0]  [1620/5004]  eta: 0:24:51  lr_architecture: 0.010000  loss_cls: 3.2062 (3.0752)  loss_etrr_per_merge: 0.1847 (0.1564)  loss_tome: 0.1736 (0.1465)  etrr_loss: 0.0004 (0.0038)  loss_flops: 0.4840 (0.3489)  flops: 3.1957 (3.0631)  grad_norm: 0.0031 (0.0058)  time: 0.4323  data: 0.0003  max mem: 10433
[2024-06-05 17:46:07 root] (utils.py 285): INFO Epoch: [0]  [1630/5004]  eta: 0:24:46  lr_architecture: 0.010000  loss_cls: 3.1051 (3.0754)  loss_etrr_per_merge: 0.1844 (0.1565)  loss_tome: 0.1736 (0.1466)  etrr_loss: 0.0004 (0.0038)  loss_flops: 0.4812 (0.3497)  flops: 3.1937 (3.0638)  grad_norm: 0.0036 (0.0058)  time: 0.4326  data: 0.0003  max mem: 10433
[2024-06-05 17:46:12 root] (utils.py 285): INFO Epoch: [0]  [1640/5004]  eta: 0:24:42  lr_architecture: 0.010000  loss_cls: 3.2167 (3.0754)  loss_etrr_per_merge: 0.1850 (0.1567)  loss_tome: 0.1736 (0.1468)  etrr_loss: 0.0004 (0.0038)  loss_flops: 0.4867 (0.3506)  flops: 3.1976 (3.0647)  grad_norm: 0.0041 (0.0058)  time: 0.4325  data: 0.0004  max mem: 10433
[2024-06-05 17:46:16 root] (utils.py 285): INFO Epoch: [0]  [1650/5004]  eta: 0:24:37  lr_architecture: 0.010000  loss_cls: 2.8522 (3.0727)  loss_etrr_per_merge: 0.1856 (0.1569)  loss_tome: 0.1736 (0.1469)  etrr_loss: 0.0003 (0.0038)  loss_flops: 0.4922 (0.3516)  flops: 3.2015 (3.0656)  grad_norm: 0.0033 (0.0058)  time: 0.4328  data: 0.0003  max mem: 10433
[2024-06-05 17:46:20 root] (utils.py 285): INFO Epoch: [0]  [1660/5004]  eta: 0:24:32  lr_architecture: 0.010000  loss_cls: 2.5728 (3.0704)  loss_etrr_per_merge: 0.1897 (0.1571)  loss_tome: 0.1736 (0.1471)  etrr_loss: 0.0002 (0.0038)  loss_flops: 0.5347 (0.3528)  flops: 3.2312 (3.0667)  grad_norm: 0.0030 (0.0057)  time: 0.4328  data: 0.0003  max mem: 10433
[2024-06-05 17:46:25 root] (utils.py 285): INFO Epoch: [0]  [1670/5004]  eta: 0:24:28  lr_architecture: 0.010000  loss_cls: 2.8289 (3.0699)  loss_etrr_per_merge: 0.1913 (0.1573)  loss_tome: 0.1736 (0.1473)  etrr_loss: 0.0001 (0.0037)  loss_flops: 0.5492 (0.3541)  flops: 3.2411 (3.0678)  grad_norm: 0.0030 (0.0057)  time: 0.4326  data: 0.0003  max mem: 10433
[2024-06-05 17:46:29 root] (utils.py 285): INFO Epoch: [0]  [1680/5004]  eta: 0:24:23  lr_architecture: 0.010000  loss_cls: 3.1122 (3.0697)  loss_etrr_per_merge: 0.1967 (0.1576)  loss_tome: 0.1736 (0.1474)  etrr_loss: 0.0000 (0.0037)  loss_flops: 0.6031 (0.3556)  flops: 3.2766 (3.0691)  grad_norm: 0.0031 (0.0057)  time: 0.4329  data: 0.0003  max mem: 10433
[2024-06-05 17:46:42 root] (main.py 192): INFO Namespace(batch_size=256, epochs=3, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/home/shivam/datasets/imagenet', data_set='IMNET', inat_category='name', output_dir='/home/pranav/DiffRate/learnt/LSMS', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=32, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.5, granularity=4, load_compression_rate=False, warmup_compression_rate=False, distributed=False)
[2024-06-05 17:46:45 root] (main.py 258): INFO Creating model: vit_deit_small_patch16_224
[2024-06-05 17:46:49 root] (main.py 346): INFO number of params: 22050664
[2024-06-05 17:46:49 root] (main.py 392): INFO Start training for 3 epochs
[2024-06-05 17:49:17 root] (main.py 192): INFO Namespace(batch_size=256, epochs=3, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/home/shivam/datasets/imagenet', data_set='IMNET', inat_category='name', output_dir='/home/pranav/DiffRate/learnt/LSMS', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=32, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.5, granularity=4, load_compression_rate=False, warmup_compression_rate=False, distributed=False)
[2024-06-05 17:49:20 root] (main.py 258): INFO Creating model: vit_deit_small_patch16_224
[2024-06-05 17:49:25 root] (main.py 346): INFO number of params: 22050664
[2024-06-05 17:49:25 root] (main.py 392): INFO Start training for 3 epochs
[2024-06-05 17:49:54 root] (main.py 192): INFO Namespace(batch_size=256, epochs=3, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/home/shivam/datasets/imagenet', data_set='IMNET', inat_category='name', output_dir='/home/pranav/DiffRate/learnt/LSMS', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=32, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.5, granularity=4, load_compression_rate=False, warmup_compression_rate=False, distributed=False)
[2024-06-05 17:49:57 root] (main.py 258): INFO Creating model: vit_deit_small_patch16_224
[2024-06-05 17:50:06 root] (main.py 192): INFO Namespace(batch_size=256, epochs=3, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/home/shivam/datasets/imagenet', data_set='IMNET', inat_category='name', output_dir='/home/pranav/DiffRate/learnt/LSMS', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=32, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.5, granularity=4, load_compression_rate=False, warmup_compression_rate=False, distributed=False)
[2024-06-05 17:50:10 root] (main.py 258): INFO Creating model: vit_deit_small_patch16_224
[2024-06-05 17:50:14 root] (main.py 346): INFO number of params: 22050664
[2024-06-05 17:50:14 root] (main.py 392): INFO Start training for 3 epochs
[2024-06-05 17:50:35 root] (engine.py 138): INFO merge kept number:[197, 197, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101]
[2024-06-05 17:50:35 root] (utils.py 285): INFO Epoch: [0]  [   0/5004]  eta: 1 day, 5:34:29  lr_architecture: 0.010000  loss_cls: 4.0759 (4.0759)  loss_etrr_per_merge: 0.0274 (0.0274)  loss_tome: 0.0069 (0.0069)  etrr_loss: 0.0133 (0.0133)  loss_flops: 0.0673 (0.0673)  flops: 2.7594 (2.7594)  grad_norm: 0.0053 (0.0053)  time: 21.2769  data: 0.3320  max mem: 10030
[2024-06-05 17:50:40 root] (utils.py 285): INFO Epoch: [0]  [  10/5004]  eta: 3:12:16  lr_architecture: 0.010000  loss_cls: 4.0759 (3.8913)  loss_etrr_per_merge: 0.0820 (0.0723)  loss_tome: 0.0625 (0.0511)  etrr_loss: 0.0132 (0.0132)  loss_flops: 0.0683 (0.0689)  flops: 2.7613 (2.7625)  grad_norm: 0.0044 (0.0038)  time: 2.3100  data: 0.0307  max mem: 10157
[2024-06-05 17:50:44 root] (utils.py 285): INFO Epoch: [0]  [  20/5004]  eta: 1:56:53  lr_architecture: 0.010000  loss_cls: 3.6888 (3.7127)  loss_etrr_per_merge: 0.0825 (0.0773)  loss_tome: 0.0625 (0.0565)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0710)  flops: 2.7659 (2.7664)  grad_norm: 0.0028 (0.0032)  time: 0.4138  data: 0.0005  max mem: 10160
[2024-06-05 17:50:48 root] (utils.py 285): INFO Epoch: [0]  [  30/5004]  eta: 1:30:06  lr_architecture: 0.010000  loss_cls: 3.6097 (3.6715)  loss_etrr_per_merge: 0.0826 (0.0789)  loss_tome: 0.0625 (0.0585)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0712 (0.0705)  flops: 2.7668 (2.7655)  grad_norm: 0.0023 (0.0030)  time: 0.4142  data: 0.0006  max mem: 10164
[2024-06-05 17:50:52 root] (utils.py 285): INFO Epoch: [0]  [  40/5004]  eta: 1:16:21  lr_architecture: 0.010000  loss_cls: 3.5372 (3.5781)  loss_etrr_per_merge: 0.0820 (0.0795)  loss_tome: 0.0625 (0.0595)  etrr_loss: 0.0134 (0.0132)  loss_flops: 0.0646 (0.0676)  flops: 2.7541 (2.7597)  grad_norm: 0.0019 (0.0027)  time: 0.4143  data: 0.0006  max mem: 10167
[2024-06-05 17:50:56 root] (utils.py 285): INFO Epoch: [0]  [  50/5004]  eta: 1:07:58  lr_architecture: 0.010000  loss_cls: 3.4552 (3.5609)  loss_etrr_per_merge: 0.0811 (0.0797)  loss_tome: 0.0625 (0.0600)  etrr_loss: 0.0143 (0.0136)  loss_flops: 0.0541 (0.0640)  flops: 2.7327 (2.7522)  grad_norm: 0.0019 (0.0026)  time: 0.4149  data: 0.0006  max mem: 10172
[2024-06-05 17:51:00 root] (utils.py 285): INFO Epoch: [0]  [  60/5004]  eta: 1:02:18  lr_architecture: 0.010000  loss_cls: 3.4892 (3.5166)  loss_etrr_per_merge: 0.0800 (0.0797)  loss_tome: 0.0625 (0.0605)  etrr_loss: 0.0155 (0.0141)  loss_flops: 0.0438 (0.0594)  flops: 2.7093 (2.7421)  grad_norm: 0.0019 (0.0024)  time: 0.4147  data: 0.0007  max mem: 10174
[2024-06-05 17:51:04 root] (utils.py 285): INFO Epoch: [0]  [  70/5004]  eta: 0:58:12  lr_architecture: 0.010000  loss_cls: 3.3043 (3.4596)  loss_etrr_per_merge: 0.0785 (0.0795)  loss_tome: 0.0625 (0.0607)  etrr_loss: 0.0174 (0.0146)  loss_flops: 0.0301 (0.0550)  flops: 2.6735 (2.7314)  grad_norm: 0.0014 (0.0023)  time: 0.4136  data: 0.0007  max mem: 10176
[2024-06-05 17:51:09 root] (utils.py 285): INFO Epoch: [0]  [  80/5004]  eta: 0:55:06  lr_architecture: 0.010000  loss_cls: 3.2059 (3.4333)  loss_etrr_per_merge: 0.0775 (0.0792)  loss_tome: 0.0625 (0.0610)  etrr_loss: 0.0182 (0.0151)  loss_flops: 0.0220 (0.0507)  flops: 2.6484 (2.7206)  grad_norm: 0.0014 (0.0022)  time: 0.4127  data: 0.0007  max mem: 10177
[2024-06-05 17:51:13 root] (utils.py 285): INFO Epoch: [0]  [  90/5004]  eta: 0:52:39  lr_architecture: 0.010000  loss_cls: 3.2732 (3.4060)  loss_etrr_per_merge: 0.0770 (0.0789)  loss_tome: 0.0625 (0.0611)  etrr_loss: 0.0195 (0.0157)  loss_flops: 0.0185 (0.0468)  flops: 2.6358 (2.7096)  grad_norm: 0.0014 (0.0022)  time: 0.4123  data: 0.0007  max mem: 10180
[2024-06-05 17:51:17 root] (engine.py 138): INFO merge kept number:[197, 197, 133, 108, 85, 101, 85, 101, 101, 85, 85, 101]
[2024-06-05 17:51:17 root] (utils.py 285): INFO Epoch: [0]  [ 100/5004]  eta: 0:50:40  lr_architecture: 0.010000  loss_cls: 3.3637 (3.4101)  loss_etrr_per_merge: 0.0760 (0.0786)  loss_tome: 0.0625 (0.0613)  etrr_loss: 0.0209 (0.0163)  loss_flops: 0.0123 (0.0432)  flops: 2.6108 (2.6992)  grad_norm: 0.0015 (0.0021)  time: 0.4122  data: 0.0008  max mem: 10182
[2024-06-05 17:51:21 root] (utils.py 285): INFO Epoch: [0]  [ 110/5004]  eta: 0:49:03  lr_architecture: 0.010000  loss_cls: 3.4527 (3.4055)  loss_etrr_per_merge: 0.0756 (0.0783)  loss_tome: 0.0625 (0.0614)  etrr_loss: 0.0215 (0.0168)  loss_flops: 0.0100 (0.0402)  flops: 2.6002 (2.6900)  grad_norm: 0.0015 (0.0021)  time: 0.4122  data: 0.0009  max mem: 10190
[2024-06-05 17:51:25 root] (utils.py 285): INFO Epoch: [0]  [ 120/5004]  eta: 0:47:40  lr_architecture: 0.010000  loss_cls: 3.3647 (3.3995)  loss_etrr_per_merge: 0.0754 (0.0781)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0217 (0.0172)  loss_flops: 0.0091 (0.0376)  flops: 2.5955 (2.6821)  grad_norm: 0.0012 (0.0020)  time: 0.4118  data: 0.0008  max mem: 10193
[2024-06-05 17:51:29 root] (utils.py 285): INFO Epoch: [0]  [ 130/5004]  eta: 0:46:29  lr_architecture: 0.010000  loss_cls: 3.2880 (3.3833)  loss_etrr_per_merge: 0.0759 (0.0779)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0212 (0.0174)  loss_flops: 0.0111 (0.0357)  flops: 2.6054 (2.6768)  grad_norm: 0.0012 (0.0020)  time: 0.4117  data: 0.0007  max mem: 10196
[2024-06-05 17:51:33 root] (utils.py 285): INFO Epoch: [0]  [ 140/5004]  eta: 0:45:28  lr_architecture: 0.010000  loss_cls: 3.2683 (3.3700)  loss_etrr_per_merge: 0.0768 (0.0778)  loss_tome: 0.0625 (0.0616)  etrr_loss: 0.0198 (0.0176)  loss_flops: 0.0163 (0.0344)  flops: 2.6277 (2.6737)  grad_norm: 0.0010 (0.0019)  time: 0.4121  data: 0.0007  max mem: 10197
[2024-06-05 17:51:37 root] (utils.py 285): INFO Epoch: [0]  [ 150/5004]  eta: 0:44:35  lr_architecture: 0.010000  loss_cls: 3.2683 (3.3524)  loss_etrr_per_merge: 0.0775 (0.0779)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0188 (0.0176)  loss_flops: 0.0214 (0.0340)  flops: 2.6461 (2.6731)  grad_norm: 0.0010 (0.0019)  time: 0.4124  data: 0.0006  max mem: 10199
[2024-06-05 17:51:42 root] (utils.py 285): INFO Epoch: [0]  [ 160/5004]  eta: 0:43:48  lr_architecture: 0.010000  loss_cls: 3.2559 (3.3477)  loss_etrr_per_merge: 0.0791 (0.0780)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0166 (0.0175)  loss_flops: 0.0335 (0.0340)  flops: 2.6830 (2.6739)  grad_norm: 0.0010 (0.0018)  time: 0.4126  data: 0.0007  max mem: 10203
[2024-06-05 17:51:46 root] (utils.py 285): INFO Epoch: [0]  [ 170/5004]  eta: 0:43:06  lr_architecture: 0.010000  loss_cls: 3.2323 (3.3337)  loss_etrr_per_merge: 0.0794 (0.0781)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0163 (0.0174)  loss_flops: 0.0364 (0.0345)  flops: 2.6909 (2.6759)  grad_norm: 0.0009 (0.0018)  time: 0.4123  data: 0.0007  max mem: 10204
[2024-06-05 17:51:50 root] (utils.py 285): INFO Epoch: [0]  [ 180/5004]  eta: 0:42:28  lr_architecture: 0.010000  loss_cls: 3.1076 (3.3151)  loss_etrr_per_merge: 0.0803 (0.0782)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0153 (0.0173)  loss_flops: 0.0447 (0.0352)  flops: 2.7113 (2.6780)  grad_norm: 0.0007 (0.0017)  time: 0.4123  data: 0.0007  max mem: 10206
[2024-06-05 17:51:54 root] (utils.py 285): INFO Epoch: [0]  [ 190/5004]  eta: 0:41:53  lr_architecture: 0.010000  loss_cls: 3.0145 (3.3096)  loss_etrr_per_merge: 0.0812 (0.0784)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0142 (0.0171)  loss_flops: 0.0537 (0.0363)  flops: 2.7318 (2.6812)  grad_norm: 0.0007 (0.0017)  time: 0.4132  data: 0.0007  max mem: 10208
[2024-06-05 17:51:58 root] (engine.py 138): INFO merge kept number:[197, 197, 150, 125, 94, 101, 94, 101, 101, 94, 94, 101]
[2024-06-05 17:51:58 root] (utils.py 285): INFO Epoch: [0]  [ 200/5004]  eta: 0:41:22  lr_architecture: 0.010000  loss_cls: 2.9502 (3.2924)  loss_etrr_per_merge: 0.0821 (0.0786)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0133 (0.0169)  loss_flops: 0.0626 (0.0383)  flops: 2.7503 (2.6860)  grad_norm: 0.0007 (0.0016)  time: 0.4131  data: 0.0007  max mem: 10208
[2024-06-05 17:52:02 root] (utils.py 285): INFO Epoch: [0]  [ 210/5004]  eta: 0:40:53  lr_architecture: 0.010000  loss_cls: 3.2140 (3.2830)  loss_etrr_per_merge: 0.0844 (0.0789)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0110 (0.0166)  loss_flops: 0.0899 (0.0411)  flops: 2.7999 (2.6919)  grad_norm: 0.0006 (0.0016)  time: 0.4127  data: 0.0007  max mem: 10209
[2024-06-05 17:52:06 root] (utils.py 285): INFO Epoch: [0]  [ 220/5004]  eta: 0:40:27  lr_architecture: 0.010000  loss_cls: 3.2140 (3.2693)  loss_etrr_per_merge: 0.0853 (0.0793)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0103 (0.0163)  loss_flops: 0.1014 (0.0441)  flops: 2.8184 (2.6981)  grad_norm: 0.0006 (0.0015)  time: 0.4131  data: 0.0007  max mem: 10210
[2024-06-05 17:52:11 root] (utils.py 285): INFO Epoch: [0]  [ 230/5004]  eta: 0:40:02  lr_architecture: 0.010000  loss_cls: 3.1287 (3.2608)  loss_etrr_per_merge: 0.0862 (0.0796)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0096 (0.0160)  loss_flops: 0.1122 (0.0473)  flops: 2.8350 (2.7043)  grad_norm: 0.0007 (0.0015)  time: 0.4131  data: 0.0007  max mem: 10210
[2024-06-05 17:52:15 root] (utils.py 285): INFO Epoch: [0]  [ 240/5004]  eta: 0:39:39  lr_architecture: 0.010000  loss_cls: 3.1684 (3.2552)  loss_etrr_per_merge: 0.0870 (0.0799)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0090 (0.0157)  loss_flops: 0.1236 (0.0508)  flops: 2.8516 (2.7109)  grad_norm: 0.0007 (0.0015)  time: 0.4133  data: 0.0007  max mem: 10211
[2024-06-05 17:52:19 root] (utils.py 285): INFO Epoch: [0]  [ 250/5004]  eta: 0:39:18  lr_architecture: 0.010000  loss_cls: 3.1684 (3.2435)  loss_etrr_per_merge: 0.0880 (0.0802)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0083 (0.0154)  loss_flops: 0.1370 (0.0543)  flops: 2.8702 (2.7174)  grad_norm: 0.0007 (0.0014)  time: 0.4137  data: 0.0007  max mem: 10211
[2024-06-05 17:52:23 root] (utils.py 285): INFO Epoch: [0]  [ 260/5004]  eta: 0:38:58  lr_architecture: 0.010000  loss_cls: 3.1020 (3.2305)  loss_etrr_per_merge: 0.0881 (0.0805)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0082 (0.0151)  loss_flops: 0.1385 (0.0573)  flops: 2.8722 (2.7230)  grad_norm: 0.0005 (0.0014)  time: 0.4137  data: 0.0007  max mem: 10213
[2024-06-05 17:52:27 root] (utils.py 285): INFO Epoch: [0]  [ 270/5004]  eta: 0:38:39  lr_architecture: 0.010000  loss_cls: 2.8546 (3.2217)  loss_etrr_per_merge: 0.0868 (0.0807)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0091 (0.0149)  loss_flops: 0.1204 (0.0596)  flops: 2.8470 (2.7275)  grad_norm: 0.0006 (0.0014)  time: 0.4134  data: 0.0007  max mem: 10214
[2024-06-05 17:52:31 root] (utils.py 285): INFO Epoch: [0]  [ 280/5004]  eta: 0:38:21  lr_architecture: 0.010000  loss_cls: 3.3003 (3.2225)  loss_etrr_per_merge: 0.0868 (0.0810)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0091 (0.0147)  loss_flops: 0.1204 (0.0622)  flops: 2.8470 (2.7324)  grad_norm: 0.0006 (0.0014)  time: 0.4126  data: 0.0006  max mem: 10216
[2024-06-05 17:52:35 root] (utils.py 285): INFO Epoch: [0]  [ 290/5004]  eta: 0:38:05  lr_architecture: 0.010000  loss_cls: 3.2405 (3.2093)  loss_etrr_per_merge: 0.0887 (0.0813)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0077 (0.0144)  loss_flops: 0.1460 (0.0652)  flops: 2.8822 (2.7376)  grad_norm: 0.0006 (0.0013)  time: 0.4127  data: 0.0006  max mem: 10218
[2024-06-05 17:52:39 root] (engine.py 138): INFO merge kept number:[197, 197, 160, 130, 98, 101, 98, 101, 101, 98, 98, 101]
[2024-06-05 17:52:39 root] (utils.py 285): INFO Epoch: [0]  [ 300/5004]  eta: 0:37:49  lr_architecture: 0.010000  loss_cls: 2.8777 (3.1999)  loss_etrr_per_merge: 0.0889 (0.0815)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0077 (0.0142)  loss_flops: 0.1491 (0.0680)  flops: 2.8861 (2.7426)  grad_norm: 0.0006 (0.0013)  time: 0.4134  data: 0.0007  max mem: 10219
[2024-06-05 17:52:44 root] (utils.py 285): INFO Epoch: [0]  [ 310/5004]  eta: 0:37:33  lr_architecture: 0.010000  loss_cls: 2.9513 (3.1932)  loss_etrr_per_merge: 0.0890 (0.0818)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0076 (0.0140)  loss_flops: 0.1507 (0.0710)  flops: 2.8881 (2.7477)  grad_norm: 0.0006 (0.0013)  time: 0.4132  data: 0.0007  max mem: 10220
[2024-06-05 17:52:48 root] (utils.py 285): INFO Epoch: [0]  [ 320/5004]  eta: 0:37:19  lr_architecture: 0.010000  loss_cls: 3.2873 (3.2014)  loss_etrr_per_merge: 0.0899 (0.0823)  loss_tome: 0.0625 (0.0624)  etrr_loss: 0.0065 (0.0137)  loss_flops: 0.1639 (0.0746)  flops: 2.9048 (2.7535)  grad_norm: 0.0007 (0.0013)  time: 0.4142  data: 0.0007  max mem: 10276
[2024-06-05 17:52:52 root] (utils.py 285): INFO Epoch: [0]  [ 330/5004]  eta: 0:37:06  lr_architecture: 0.010000  loss_cls: 3.3004 (3.1956)  loss_etrr_per_merge: 0.1215 (0.0835)  loss_tome: 0.1111 (0.0639)  etrr_loss: 0.0060 (0.0135)  loss_flops: 0.1893 (0.0781)  flops: 2.9351 (2.7589)  grad_norm: 0.0007 (0.0013)  time: 0.4185  data: 0.0006  max mem: 10282
[2024-06-05 17:52:56 root] (utils.py 285): INFO Epoch: [0]  [ 340/5004]  eta: 0:36:54  lr_architecture: 0.010000  loss_cls: 3.1915 (3.1980)  loss_etrr_per_merge: 0.1219 (0.0846)  loss_tome: 0.1111 (0.0653)  etrr_loss: 0.0061 (0.0133)  loss_flops: 0.1859 (0.0811)  flops: 2.9312 (2.7638)  grad_norm: 0.0005 (0.0013)  time: 0.4213  data: 0.0004  max mem: 10288
[2024-06-05 17:53:00 root] (utils.py 285): INFO Epoch: [0]  [ 350/5004]  eta: 0:36:42  lr_architecture: 0.010000  loss_cls: 3.2876 (3.1959)  loss_etrr_per_merge: 0.1209 (0.0856)  loss_tome: 0.1111 (0.0666)  etrr_loss: 0.0065 (0.0131)  loss_flops: 0.1736 (0.0836)  flops: 2.9167 (2.7680)  grad_norm: 0.0006 (0.0012)  time: 0.4217  data: 0.0004  max mem: 10291
[2024-06-05 17:53:05 root] (utils.py 285): INFO Epoch: [0]  [ 360/5004]  eta: 0:36:31  lr_architecture: 0.010000  loss_cls: 3.1536 (3.1928)  loss_etrr_per_merge: 0.1208 (0.0866)  loss_tome: 0.1111 (0.0678)  etrr_loss: 0.0066 (0.0129)  loss_flops: 0.1719 (0.0861)  flops: 2.9146 (2.7721)  grad_norm: 0.0006 (0.0012)  time: 0.4220  data: 0.0003  max mem: 10294
[2024-06-05 17:53:09 root] (utils.py 285): INFO Epoch: [0]  [ 370/5004]  eta: 0:36:20  lr_architecture: 0.010000  loss_cls: 3.1055 (3.1872)  loss_etrr_per_merge: 0.1212 (0.0875)  loss_tome: 0.1111 (0.0690)  etrr_loss: 0.0064 (0.0127)  loss_flops: 0.1755 (0.0886)  flops: 2.9189 (2.7762)  grad_norm: 0.0006 (0.0012)  time: 0.4216  data: 0.0003  max mem: 10296
[2024-06-05 17:53:13 root] (utils.py 285): INFO Epoch: [0]  [ 380/5004]  eta: 0:36:09  lr_architecture: 0.010000  loss_cls: 3.1613 (3.1826)  loss_etrr_per_merge: 0.1212 (0.0884)  loss_tome: 0.1111 (0.0701)  etrr_loss: 0.0064 (0.0126)  loss_flops: 0.1755 (0.0907)  flops: 2.9189 (2.7798)  grad_norm: 0.0005 (0.0012)  time: 0.4222  data: 0.0003  max mem: 10300
[2024-06-05 17:53:17 root] (utils.py 285): INFO Epoch: [0]  [ 390/5004]  eta: 0:35:59  lr_architecture: 0.010000  loss_cls: 3.1613 (3.1758)  loss_etrr_per_merge: 0.1206 (0.0892)  loss_tome: 0.1111 (0.0711)  etrr_loss: 0.0067 (0.0124)  loss_flops: 0.1683 (0.0927)  flops: 2.9102 (2.7831)  grad_norm: 0.0006 (0.0012)  time: 0.4225  data: 0.0003  max mem: 10300
[2024-06-05 17:53:22 root] (engine.py 138): INFO merge kept number:[197, 197, 168, 146, 117, 94, 94, 101, 101, 94, 94, 101]
[2024-06-05 17:53:22 root] (utils.py 285): INFO Epoch: [0]  [ 400/5004]  eta: 0:35:49  lr_architecture: 0.010000  loss_cls: 3.3005 (3.1781)  loss_etrr_per_merge: 0.1208 (0.0900)  loss_tome: 0.1111 (0.0721)  etrr_loss: 0.0065 (0.0123)  loss_flops: 0.1699 (0.0947)  flops: 2.9121 (2.7865)  grad_norm: 0.0005 (0.0012)  time: 0.4224  data: 0.0003  max mem: 10303
[2024-06-05 17:53:26 root] (utils.py 285): INFO Epoch: [0]  [ 410/5004]  eta: 0:35:40  lr_architecture: 0.010000  loss_cls: 3.3566 (3.1801)  loss_etrr_per_merge: 0.1215 (0.0908)  loss_tome: 0.1111 (0.0731)  etrr_loss: 0.0063 (0.0121)  loss_flops: 0.1781 (0.0971)  flops: 2.9221 (2.7902)  grad_norm: 0.0005 (0.0012)  time: 0.4225  data: 0.0004  max mem: 10304
[2024-06-05 17:53:30 root] (utils.py 285): INFO Epoch: [0]  [ 420/5004]  eta: 0:35:30  lr_architecture: 0.010000  loss_cls: 3.1628 (3.1768)  loss_etrr_per_merge: 0.1241 (0.0916)  loss_tome: 0.1111 (0.0740)  etrr_loss: 0.0052 (0.0119)  loss_flops: 0.2073 (0.0998)  flops: 2.9553 (2.7942)  grad_norm: 0.0005 (0.0011)  time: 0.4227  data: 0.0004  max mem: 10305
[2024-06-05 17:53:34 root] (utils.py 285): INFO Epoch: [0]  [ 430/5004]  eta: 0:35:21  lr_architecture: 0.010000  loss_cls: 3.2839 (3.1803)  loss_etrr_per_merge: 0.1254 (0.0924)  loss_tome: 0.1111 (0.0748)  etrr_loss: 0.0048 (0.0118)  loss_flops: 0.2228 (0.1031)  flops: 2.9720 (2.7988)  grad_norm: 0.0005 (0.0011)  time: 0.4228  data: 0.0004  max mem: 10307
[2024-06-05 17:53:56 root] (main.py 192): INFO Namespace(batch_size=256, epochs=3, model='vit_deit_small_patch16_224', multi_reso=False, input_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.0, sched='cosine', lr=0.0005, arch_lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, arch_min_lr=0.001, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', data_path='/home/shivam/datasets/imagenet', data_set='IMNET', inat_category='name', output_dir='/home/pranav/DiffRate/learnt/LSMS', device='cuda', seed=0, resume='', autoresume=False, start_epoch=0, eval=False, dist_eval=True, num_workers=32, pin_mem=True, world_size=1, port='15662', dist_url='env://', target_flops=2.5, granularity=4, load_compression_rate=False, warmup_compression_rate=False, distributed=False)
[2024-06-05 17:53:59 root] (main.py 258): INFO Creating model: vit_deit_small_patch16_224
[2024-06-05 17:54:04 root] (main.py 346): INFO number of params: 22050664
[2024-06-05 17:54:04 root] (main.py 392): INFO Start training for 3 epochs
[2024-06-05 17:54:26 root] (engine.py 138): INFO merge kept number:[197, 197, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101]
[2024-06-05 17:54:26 root] (utils.py 285): INFO Epoch: [0]  [   0/5004]  eta: 1 day, 6:39:08  lr_architecture: 0.010000  loss_cls: 4.0760 (4.0760)  loss_etrr_per_merge: 0.0274 (0.0274)  loss_tome: 0.0069 (0.0069)  etrr_loss: 0.0133 (0.0133)  loss_flops: 0.0673 (0.0673)  flops: 2.7594 (2.7594)  grad_norm: 0.0053 (0.0053)  time: 22.0520  data: 5.6177  max mem: 10030
[2024-06-05 17:54:30 root] (utils.py 285): INFO Epoch: [0]  [  10/5004]  eta: 3:17:52  lr_architecture: 0.010000  loss_cls: 4.0760 (3.8913)  loss_etrr_per_merge: 0.0820 (0.0723)  loss_tome: 0.0625 (0.0511)  etrr_loss: 0.0132 (0.0132)  loss_flops: 0.0683 (0.0689)  flops: 2.7613 (2.7625)  grad_norm: 0.0044 (0.0038)  time: 2.3773  data: 0.5112  max mem: 10157
[2024-06-05 17:54:34 root] (utils.py 285): INFO Epoch: [0]  [  20/5004]  eta: 1:59:36  lr_architecture: 0.010000  loss_cls: 3.6888 (3.7128)  loss_etrr_per_merge: 0.0825 (0.0773)  loss_tome: 0.0625 (0.0565)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0707 (0.0710)  flops: 2.7659 (2.7664)  grad_norm: 0.0028 (0.0032)  time: 0.4094  data: 0.0006  max mem: 10160
[2024-06-05 17:54:38 root] (utils.py 285): INFO Epoch: [0]  [  30/5004]  eta: 1:31:47  lr_architecture: 0.010000  loss_cls: 3.6097 (3.6715)  loss_etrr_per_merge: 0.0826 (0.0789)  loss_tome: 0.0625 (0.0585)  etrr_loss: 0.0129 (0.0130)  loss_flops: 0.0712 (0.0705)  flops: 2.7668 (2.7655)  grad_norm: 0.0023 (0.0030)  time: 0.4088  data: 0.0006  max mem: 10164
[2024-06-05 17:54:42 root] (utils.py 285): INFO Epoch: [0]  [  40/5004]  eta: 1:17:33  lr_architecture: 0.010000  loss_cls: 3.5374 (3.5782)  loss_etrr_per_merge: 0.0820 (0.0795)  loss_tome: 0.0625 (0.0595)  etrr_loss: 0.0134 (0.0132)  loss_flops: 0.0646 (0.0674)  flops: 2.7541 (2.7593)  grad_norm: 0.0019 (0.0027)  time: 0.4096  data: 0.0006  max mem: 10167
[2024-06-05 17:54:46 root] (utils.py 285): INFO Epoch: [0]  [  50/5004]  eta: 1:08:57  lr_architecture: 0.010000  loss_cls: 3.4514 (3.5609)  loss_etrr_per_merge: 0.0811 (0.0797)  loss_tome: 0.0625 (0.0600)  etrr_loss: 0.0144 (0.0136)  loss_flops: 0.0541 (0.0640)  flops: 2.7327 (2.7522)  grad_norm: 0.0019 (0.0026)  time: 0.4133  data: 0.0007  max mem: 10171
[2024-06-05 17:54:51 root] (utils.py 285): INFO Epoch: [0]  [  60/5004]  eta: 1:03:10  lr_architecture: 0.010000  loss_cls: 3.4892 (3.5166)  loss_etrr_per_merge: 0.0801 (0.0797)  loss_tome: 0.0625 (0.0605)  etrr_loss: 0.0155 (0.0141)  loss_flops: 0.0446 (0.0594)  flops: 2.7113 (2.7421)  grad_norm: 0.0019 (0.0024)  time: 0.4168  data: 0.0007  max mem: 10174
[2024-06-05 17:54:55 root] (utils.py 285): INFO Epoch: [0]  [  70/5004]  eta: 0:58:57  lr_architecture: 0.010000  loss_cls: 3.3041 (3.4596)  loss_etrr_per_merge: 0.0785 (0.0795)  loss_tome: 0.0625 (0.0607)  etrr_loss: 0.0174 (0.0146)  loss_flops: 0.0301 (0.0550)  flops: 2.6735 (2.7314)  grad_norm: 0.0014 (0.0023)  time: 0.4159  data: 0.0007  max mem: 10176
[2024-06-05 17:54:59 root] (utils.py 285): INFO Epoch: [0]  [  80/5004]  eta: 0:55:44  lr_architecture: 0.010000  loss_cls: 3.2059 (3.4332)  loss_etrr_per_merge: 0.0775 (0.0792)  loss_tome: 0.0625 (0.0610)  etrr_loss: 0.0182 (0.0151)  loss_flops: 0.0220 (0.0507)  flops: 2.6484 (2.7206)  grad_norm: 0.0014 (0.0022)  time: 0.4126  data: 0.0007  max mem: 10177
[2024-06-05 17:55:03 root] (utils.py 285): INFO Epoch: [0]  [  90/5004]  eta: 0:53:13  lr_architecture: 0.010000  loss_cls: 3.2733 (3.4060)  loss_etrr_per_merge: 0.0770 (0.0789)  loss_tome: 0.0625 (0.0611)  etrr_loss: 0.0195 (0.0157)  loss_flops: 0.0185 (0.0468)  flops: 2.6358 (2.7096)  grad_norm: 0.0014 (0.0022)  time: 0.4111  data: 0.0005  max mem: 10180
[2024-06-05 17:55:07 root] (engine.py 138): INFO merge kept number:[197, 197, 133, 108, 85, 101, 85, 101, 101, 85, 85, 101]
[2024-06-05 17:55:07 root] (utils.py 285): INFO Epoch: [0]  [ 100/5004]  eta: 0:51:11  lr_architecture: 0.010000  loss_cls: 3.3637 (3.4102)  loss_etrr_per_merge: 0.0760 (0.0786)  loss_tome: 0.0625 (0.0613)  etrr_loss: 0.0209 (0.0163)  loss_flops: 0.0123 (0.0432)  flops: 2.6108 (2.6991)  grad_norm: 0.0015 (0.0021)  time: 0.4121  data: 0.0006  max mem: 10182
[2024-06-05 17:55:11 root] (utils.py 285): INFO Epoch: [0]  [ 110/5004]  eta: 0:49:30  lr_architecture: 0.010000  loss_cls: 3.4527 (3.4055)  loss_etrr_per_merge: 0.0756 (0.0783)  loss_tome: 0.0625 (0.0614)  etrr_loss: 0.0215 (0.0167)  loss_flops: 0.0100 (0.0402)  flops: 2.6002 (2.6902)  grad_norm: 0.0015 (0.0021)  time: 0.4124  data: 0.0007  max mem: 10190
[2024-06-05 17:55:15 root] (utils.py 285): INFO Epoch: [0]  [ 120/5004]  eta: 0:48:05  lr_architecture: 0.010000  loss_cls: 3.3647 (3.3993)  loss_etrr_per_merge: 0.0757 (0.0781)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0214 (0.0171)  loss_flops: 0.0103 (0.0377)  flops: 2.6014 (2.6828)  grad_norm: 0.0012 (0.0020)  time: 0.4115  data: 0.0006  max mem: 10193
[2024-06-05 17:55:19 root] (utils.py 285): INFO Epoch: [0]  [ 130/5004]  eta: 0:46:53  lr_architecture: 0.010000  loss_cls: 3.2889 (3.3829)  loss_etrr_per_merge: 0.0758 (0.0780)  loss_tome: 0.0625 (0.0615)  etrr_loss: 0.0212 (0.0174)  loss_flops: 0.0107 (0.0359)  flops: 2.6034 (2.6777)  grad_norm: 0.0012 (0.0020)  time: 0.4116  data: 0.0006  max mem: 10196
[2024-06-05 17:55:23 root] (utils.py 285): INFO Epoch: [0]  [ 140/5004]  eta: 0:45:50  lr_architecture: 0.010000  loss_cls: 3.2689 (3.3697)  loss_etrr_per_merge: 0.0768 (0.0779)  loss_tome: 0.0625 (0.0616)  etrr_loss: 0.0198 (0.0175)  loss_flops: 0.0163 (0.0347)  flops: 2.6277 (2.6748)  grad_norm: 0.0010 (0.0019)  time: 0.4121  data: 0.0006  max mem: 10197
[2024-06-05 17:55:28 root] (utils.py 285): INFO Epoch: [0]  [ 150/5004]  eta: 0:44:55  lr_architecture: 0.010000  loss_cls: 3.2689 (3.3522)  loss_etrr_per_merge: 0.0775 (0.0779)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0188 (0.0176)  loss_flops: 0.0214 (0.0341)  flops: 2.6461 (2.6738)  grad_norm: 0.0010 (0.0019)  time: 0.4118  data: 0.0006  max mem: 10199
[2024-06-05 17:55:32 root] (utils.py 285): INFO Epoch: [0]  [ 160/5004]  eta: 0:44:06  lr_architecture: 0.010000  loss_cls: 3.2559 (3.3478)  loss_etrr_per_merge: 0.0785 (0.0780)  loss_tome: 0.0625 (0.0617)  etrr_loss: 0.0175 (0.0175)  loss_flops: 0.0284 (0.0341)  flops: 2.6685 (2.6745)  grad_norm: 0.0010 (0.0018)  time: 0.4114  data: 0.0005  max mem: 10202
[2024-06-05 17:55:36 root] (utils.py 285): INFO Epoch: [0]  [ 170/5004]  eta: 0:43:23  lr_architecture: 0.010000  loss_cls: 3.2419 (3.3343)  loss_etrr_per_merge: 0.0793 (0.0781)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0163 (0.0174)  loss_flops: 0.0357 (0.0343)  flops: 2.6889 (2.6757)  grad_norm: 0.0009 (0.0018)  time: 0.4116  data: 0.0005  max mem: 10203
[2024-06-05 17:55:40 root] (utils.py 285): INFO Epoch: [0]  [ 180/5004]  eta: 0:42:43  lr_architecture: 0.010000  loss_cls: 3.1212 (3.3159)  loss_etrr_per_merge: 0.0802 (0.0782)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0154 (0.0173)  loss_flops: 0.0438 (0.0349)  flops: 2.7094 (2.6777)  grad_norm: 0.0007 (0.0017)  time: 0.4120  data: 0.0005  max mem: 10205
[2024-06-05 17:55:44 root] (utils.py 285): INFO Epoch: [0]  [ 190/5004]  eta: 0:42:08  lr_architecture: 0.010000  loss_cls: 3.0338 (3.3107)  loss_etrr_per_merge: 0.0804 (0.0783)  loss_tome: 0.0625 (0.0618)  etrr_loss: 0.0152 (0.0172)  loss_flops: 0.0455 (0.0356)  flops: 2.7133 (2.6799)  grad_norm: 0.0007 (0.0017)  time: 0.4119  data: 0.0005  max mem: 10207
[2024-06-05 17:55:48 root] (engine.py 138): INFO merge kept number:[197, 197, 150, 123, 92, 101, 92, 101, 101, 92, 92, 101]
[2024-06-05 17:55:48 root] (utils.py 285): INFO Epoch: [0]  [ 200/5004]  eta: 0:41:36  lr_architecture: 0.010000  loss_cls: 2.9680 (3.2938)  loss_etrr_per_merge: 0.0812 (0.0785)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0142 (0.0170)  loss_flops: 0.0537 (0.0370)  flops: 2.7318 (2.6835)  grad_norm: 0.0007 (0.0016)  time: 0.4120  data: 0.0005  max mem: 10208
[2024-06-05 17:55:52 root] (utils.py 285): INFO Epoch: [0]  [ 210/5004]  eta: 0:41:06  lr_architecture: 0.010000  loss_cls: 3.2204 (3.2841)  loss_etrr_per_merge: 0.0829 (0.0788)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0119 (0.0167)  loss_flops: 0.0712 (0.0392)  flops: 2.7668 (2.6884)  grad_norm: 0.0007 (0.0016)  time: 0.4122  data: 0.0005  max mem: 10208
[2024-06-05 17:55:56 root] (utils.py 285): INFO Epoch: [0]  [ 220/5004]  eta: 0:40:39  lr_architecture: 0.010000  loss_cls: 3.2204 (3.2706)  loss_etrr_per_merge: 0.0845 (0.0790)  loss_tome: 0.0625 (0.0619)  etrr_loss: 0.0110 (0.0165)  loss_flops: 0.0911 (0.0416)  flops: 2.8019 (2.6937)  grad_norm: 0.0006 (0.0015)  time: 0.4122  data: 0.0005  max mem: 10209
[2024-06-05 17:56:01 root] (utils.py 285): INFO Epoch: [0]  [ 230/5004]  eta: 0:40:14  lr_architecture: 0.010000  loss_cls: 3.1289 (3.2623)  loss_etrr_per_merge: 0.0846 (0.0793)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0109 (0.0162)  loss_flops: 0.0923 (0.0441)  flops: 2.8039 (2.6990)  grad_norm: 0.0007 (0.0015)  time: 0.4128  data: 0.0005  max mem: 10211
[2024-06-05 17:56:05 root] (utils.py 285): INFO Epoch: [0]  [ 240/5004]  eta: 0:39:50  lr_architecture: 0.010000  loss_cls: 3.2125 (3.2569)  loss_etrr_per_merge: 0.0858 (0.0796)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0100 (0.0159)  loss_flops: 0.1065 (0.0471)  flops: 2.8264 (2.7048)  grad_norm: 0.0007 (0.0015)  time: 0.4130  data: 0.0005  max mem: 10213
[2024-06-05 17:56:09 root] (utils.py 285): INFO Epoch: [0]  [ 250/5004]  eta: 0:39:28  lr_architecture: 0.010000  loss_cls: 3.2125 (3.2451)  loss_etrr_per_merge: 0.0867 (0.0799)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0092 (0.0156)  loss_flops: 0.1190 (0.0500)  flops: 2.8449 (2.7105)  grad_norm: 0.0006 (0.0015)  time: 0.4127  data: 0.0005  max mem: 10214
[2024-06-05 17:56:13 root] (utils.py 285): INFO Epoch: [0]  [ 260/5004]  eta: 0:39:08  lr_architecture: 0.010000  loss_cls: 3.0945 (3.2320)  loss_etrr_per_merge: 0.0868 (0.0801)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0091 (0.0154)  loss_flops: 0.1203 (0.0525)  flops: 2.8469 (2.7154)  grad_norm: 0.0006 (0.0014)  time: 0.4131  data: 0.0006  max mem: 10214
[2024-06-05 17:56:17 root] (utils.py 285): INFO Epoch: [0]  [ 270/5004]  eta: 0:38:51  lr_architecture: 0.010000  loss_cls: 2.8682 (3.2230)  loss_etrr_per_merge: 0.0860 (0.0803)  loss_tome: 0.0625 (0.0620)  etrr_loss: 0.0098 (0.0152)  loss_flops: 0.1092 (0.0543)  flops: 2.8304 (2.7192)  grad_norm: 0.0006 (0.0014)  time: 0.4201  data: 0.0008  max mem: 10215
[2024-06-05 17:56:21 root] (utils.py 285): INFO Epoch: [0]  [ 280/5004]  eta: 0:38:33  lr_architecture: 0.010000  loss_cls: 3.2896 (3.2240)  loss_etrr_per_merge: 0.0853 (0.0805)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0102 (0.0150)  loss_flops: 0.1010 (0.0562)  flops: 2.8179 (2.7231)  grad_norm: 0.0007 (0.0014)  time: 0.4214  data: 0.0008  max mem: 10217
[2024-06-05 17:56:26 root] (utils.py 285): INFO Epoch: [0]  [ 290/5004]  eta: 0:38:16  lr_architecture: 0.010000  loss_cls: 3.2427 (3.2107)  loss_etrr_per_merge: 0.0864 (0.0808)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0094 (0.0148)  loss_flops: 0.1145 (0.0585)  flops: 2.8384 (2.7274)  grad_norm: 0.0007 (0.0014)  time: 0.4145  data: 0.0006  max mem: 10219
[2024-06-05 17:56:30 root] (engine.py 138): INFO merge kept number:[197, 197, 161, 133, 98, 101, 98, 101, 101, 98, 98, 101]
[2024-06-05 17:56:30 root] (utils.py 285): INFO Epoch: [0]  [ 300/5004]  eta: 0:38:00  lr_architecture: 0.010000  loss_cls: 2.8765 (3.2012)  loss_etrr_per_merge: 0.0874 (0.0810)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0087 (0.0146)  loss_flops: 0.1288 (0.0613)  flops: 2.8589 (2.7324)  grad_norm: 0.0006 (0.0013)  time: 0.4130  data: 0.0005  max mem: 10219
[2024-06-05 17:56:34 root] (utils.py 285): INFO Epoch: [0]  [ 310/5004]  eta: 0:37:44  lr_architecture: 0.010000  loss_cls: 2.9540 (3.1943)  loss_etrr_per_merge: 0.0894 (0.0813)  loss_tome: 0.0625 (0.0621)  etrr_loss: 0.0073 (0.0143)  loss_flops: 0.1569 (0.0649)  flops: 2.8961 (2.7384)  grad_norm: 0.0006 (0.0013)  time: 0.4127  data: 0.0005  max mem: 10221
[2024-06-05 17:56:38 root] (utils.py 285): INFO Epoch: [0]  [ 320/5004]  eta: 0:37:30  lr_architecture: 0.010000  loss_cls: 3.2844 (3.2022)  loss_etrr_per_merge: 0.0921 (0.0829)  loss_tome: 0.0625 (0.0643)  etrr_loss: 0.0057 (0.0141)  loss_flops: 0.1971 (0.0692)  flops: 2.9440 (2.7450)  grad_norm: 0.0006 (0.0013)  time: 0.4182  data: 0.0004  max mem: 10341
[2024-06-05 17:56:42 root] (utils.py 285): INFO Epoch: [0]  [ 330/5004]  eta: 0:37:19  lr_architecture: 0.010000  loss_cls: 3.2844 (3.1963)  loss_etrr_per_merge: 0.1529 (0.0850)  loss_tome: 0.1736 (0.0676)  etrr_loss: 0.0057 (0.0138)  loss_flops: 0.1987 (0.0729)  flops: 2.9458 (2.7508)  grad_norm: 0.0006 (0.0013)  time: 0.4273  data: 0.0004  max mem: 10347
[2024-06-05 17:56:47 root] (utils.py 285): INFO Epoch: [0]  [ 340/5004]  eta: 0:37:07  lr_architecture: 0.010000  loss_cls: 3.2201 (3.1988)  loss_etrr_per_merge: 0.1525 (0.0870)  loss_tome: 0.1736 (0.0707)  etrr_loss: 0.0061 (0.0136)  loss_flops: 0.1852 (0.0762)  flops: 2.9303 (2.7560)  grad_norm: 0.0005 (0.0013)  time: 0.4297  data: 0.0004  max mem: 10349
[2024-06-05 17:56:51 root] (utils.py 285): INFO Epoch: [0]  [ 350/5004]  eta: 0:36:56  lr_architecture: 0.010000  loss_cls: 3.2480 (3.1962)  loss_etrr_per_merge: 0.1525 (0.0889)  loss_tome: 0.1736 (0.0736)  etrr_loss: 0.0061 (0.0134)  loss_flops: 0.1852 (0.0793)  flops: 2.9303 (2.7610)  grad_norm: 0.0005 (0.0012)  time: 0.4294  data: 0.0003  max mem: 10353
[2024-06-05 17:56:55 root] (utils.py 285): INFO Epoch: [0]  [ 360/5004]  eta: 0:36:45  lr_architecture: 0.010000  loss_cls: 3.1343 (3.1929)  loss_etrr_per_merge: 0.1527 (0.0907)  loss_tome: 0.1736 (0.0764)  etrr_loss: 0.0060 (0.0132)  loss_flops: 0.1861 (0.0823)  flops: 2.9314 (2.7658)  grad_norm: 0.0005 (0.0012)  time: 0.4300  data: 0.0003  max mem: 10357
[2024-06-05 17:57:00 root] (utils.py 285): INFO Epoch: [0]  [ 370/5004]  eta: 0:36:35  lr_architecture: 0.010000  loss_cls: 3.1130 (3.1874)  loss_etrr_per_merge: 0.1531 (0.0923)  loss_tome: 0.1736 (0.0790)  etrr_loss: 0.0059 (0.0130)  loss_flops: 0.1887 (0.0852)  flops: 2.9343 (2.7704)  grad_norm: 0.0005 (0.0012)  time: 0.4301  data: 0.0003  max mem: 10360
[2024-06-05 17:57:04 root] (utils.py 285): INFO Epoch: [0]  [ 380/5004]  eta: 0:36:25  lr_architecture: 0.010000  loss_cls: 3.1406 (3.1825)  loss_etrr_per_merge: 0.1529 (0.0939)  loss_tome: 0.1736 (0.0815)  etrr_loss: 0.0059 (0.0128)  loss_flops: 0.1853 (0.0877)  flops: 2.9305 (2.7744)  grad_norm: 0.0005 (0.0012)  time: 0.4305  data: 0.0004  max mem: 10361
[2024-06-05 17:57:08 root] (utils.py 285): INFO Epoch: [0]  [ 390/5004]  eta: 0:36:15  lr_architecture: 0.010000  loss_cls: 3.1406 (3.1755)  loss_etrr_per_merge: 0.1517 (0.0954)  loss_tome: 0.1736 (0.0839)  etrr_loss: 0.0063 (0.0126)  loss_flops: 0.1746 (0.0899)  flops: 2.9179 (2.7781)  grad_norm: 0.0005 (0.0012)  time: 0.4310  data: 0.0004  max mem: 10366
[2024-06-05 17:57:12 root] (engine.py 138): INFO merge kept number:[197, 197, 169, 149, 121, 98, 98, 89, 101, 89, 89, 101]
[2024-06-05 17:57:12 root] (utils.py 285): INFO Epoch: [0]  [ 400/5004]  eta: 0:36:06  lr_architecture: 0.010000  loss_cls: 3.3020 (3.1777)  loss_etrr_per_merge: 0.1517 (0.0968)  loss_tome: 0.1736 (0.0861)  etrr_loss: 0.0063 (0.0125)  loss_flops: 0.1739 (0.0920)  flops: 2.9170 (2.7815)  grad_norm: 0.0005 (0.0012)  time: 0.4311  data: 0.0004  max mem: 10368
[2024-06-05 17:57:17 root] (utils.py 285): INFO Epoch: [0]  [ 410/5004]  eta: 0:35:57  lr_architecture: 0.010000  loss_cls: 3.3414 (3.1796)  loss_etrr_per_merge: 0.1515 (0.0981)  loss_tome: 0.1736 (0.0882)  etrr_loss: 0.0064 (0.0123)  loss_flops: 0.1706 (0.0938)  flops: 2.9131 (2.7846)  grad_norm: 0.0005 (0.0011)  time: 0.4306  data: 0.0004  max mem: 10370
[2024-06-05 17:57:21 root] (utils.py 285): INFO Epoch: [0]  [ 420/5004]  eta: 0:35:48  lr_architecture: 0.010000  loss_cls: 3.1442 (3.1762)  loss_etrr_per_merge: 0.1510 (0.0994)  loss_tome: 0.1736 (0.0903)  etrr_loss: 0.0066 (0.0122)  loss_flops: 0.1634 (0.0954)  flops: 2.9043 (2.7874)  grad_norm: 0.0005 (0.0011)  time: 0.4303  data: 0.0003  max mem: 10373
[2024-06-05 17:57:25 root] (utils.py 285): INFO Epoch: [0]  [ 430/5004]  eta: 0:35:39  lr_architecture: 0.010000  loss_cls: 3.2798 (3.1797)  loss_etrr_per_merge: 0.1504 (0.1006)  loss_tome: 0.1736 (0.0922)  etrr_loss: 0.0067 (0.0121)  loss_flops: 0.1579 (0.0968)  flops: 2.8974 (2.7899)  grad_norm: 0.0005 (0.0011)  time: 0.4306  data: 0.0003  max mem: 10378
[2024-06-05 17:57:30 root] (utils.py 285): INFO Epoch: [0]  [ 440/5004]  eta: 0:35:30  lr_architecture: 0.010000  loss_cls: 3.3699 (3.1811)  loss_etrr_per_merge: 0.1506 (0.1017)  loss_tome: 0.1736 (0.0940)  etrr_loss: 0.0067 (0.0119)  loss_flops: 0.1587 (0.0983)  flops: 2.8983 (2.7924)  grad_norm: 0.0005 (0.0011)  time: 0.4303  data: 0.0003  max mem: 10378
[2024-06-05 17:57:34 root] (utils.py 285): INFO Epoch: [0]  [ 450/5004]  eta: 0:35:22  lr_architecture: 0.010000  loss_cls: 3.1203 (3.1785)  loss_etrr_per_merge: 0.1513 (0.1028)  loss_tome: 0.1736 (0.0958)  etrr_loss: 0.0063 (0.0118)  loss_flops: 0.1642 (0.0999)  flops: 2.9052 (2.7951)  grad_norm: 0.0004 (0.0011)  time: 0.4301  data: 0.0003  max mem: 10388
[2024-06-05 17:57:38 root] (utils.py 285): INFO Epoch: [0]  [ 460/5004]  eta: 0:35:14  lr_architecture: 0.010000  loss_cls: 2.9959 (3.1716)  loss_etrr_per_merge: 0.1527 (0.1039)  loss_tome: 0.1736 (0.0975)  etrr_loss: 0.0060 (0.0117)  loss_flops: 0.1740 (0.1016)  flops: 2.9171 (2.7979)  grad_norm: 0.0004 (0.0011)  time: 0.4310  data: 0.0003  max mem: 10388
[2024-06-05 17:57:43 root] (utils.py 285): INFO Epoch: [0]  [ 470/5004]  eta: 0:35:06  lr_architecture: 0.010000  loss_cls: 2.7328 (3.1624)  loss_etrr_per_merge: 0.1527 (0.1050)  loss_tome: 0.1736 (0.0991)  etrr_loss: 0.0059 (0.0116)  loss_flops: 0.1740 (0.1031)  flops: 2.9171 (2.8004)  grad_norm: 0.0004 (0.0011)  time: 0.4311  data: 0.0003  max mem: 10392
[2024-06-05 17:57:47 root] (utils.py 285): INFO Epoch: [0]  [ 480/5004]  eta: 0:34:58  lr_architecture: 0.010000  loss_cls: 2.8694 (3.1596)  loss_etrr_per_merge: 0.1527 (0.1060)  loss_tome: 0.1736 (0.1006)  etrr_loss: 0.0059 (0.0114)  loss_flops: 0.1732 (0.1046)  flops: 2.9162 (2.8028)  grad_norm: 0.0004 (0.0011)  time: 0.4310  data: 0.0003  max mem: 10392
[2024-06-05 17:57:51 root] (utils.py 285): INFO Epoch: [0]  [ 490/5004]  eta: 0:34:51  lr_architecture: 0.010000  loss_cls: 3.0309 (3.1600)  loss_etrr_per_merge: 0.1531 (0.1069)  loss_tome: 0.1736 (0.1021)  etrr_loss: 0.0057 (0.0113)  loss_flops: 0.1766 (0.1063)  flops: 2.9203 (2.8055)  grad_norm: 0.0004 (0.0010)  time: 0.4315  data: 0.0003  max mem: 10393
[2024-06-05 17:57:56 root] (engine.py 138): INFO merge kept number:[197, 197, 174, 157, 134, 113, 113, 80, 101, 80, 80, 101]
[2024-06-05 17:57:56 root] (utils.py 285): INFO Epoch: [0]  [ 500/5004]  eta: 0:34:43  lr_architecture: 0.010000  loss_cls: 3.0905 (3.1573)  loss_etrr_per_merge: 0.1549 (0.1079)  loss_tome: 0.1736 (0.1036)  etrr_loss: 0.0053 (0.0112)  loss_flops: 0.1917 (0.1082)  flops: 2.9378 (2.8083)  grad_norm: 0.0004 (0.0010)  time: 0.4317  data: 0.0003  max mem: 10395
[2024-06-05 17:58:00 root] (utils.py 285): INFO Epoch: [0]  [ 510/5004]  eta: 0:34:36  lr_architecture: 0.010000  loss_cls: 3.2248 (3.1599)  loss_etrr_per_merge: 0.1551 (0.1088)  loss_tome: 0.1736 (0.1049)  etrr_loss: 0.0051 (0.0111)  loss_flops: 0.1934 (0.1098)  flops: 2.9398 (2.8109)  grad_norm: 0.0004 (0.0010)  time: 0.4318  data: 0.0004  max mem: 10395
[2024-06-05 17:58:04 root] (utils.py 285): INFO Epoch: [0]  [ 520/5004]  eta: 0:34:29  lr_architecture: 0.010000  loss_cls: 3.3040 (3.1595)  loss_etrr_per_merge: 0.1557 (0.1098)  loss_tome: 0.1736 (0.1062)  etrr_loss: 0.0049 (0.0110)  loss_flops: 0.1994 (0.1119)  flops: 2.9466 (2.8139)  grad_norm: 0.0004 (0.0010)  time: 0.4315  data: 0.0004  max mem: 10397
[2024-06-05 17:58:09 root] (utils.py 285): INFO Epoch: [0]  [ 530/5004]  eta: 0:34:21  lr_architecture: 0.010000  loss_cls: 3.1519 (3.1520)  loss_etrr_per_merge: 0.1602 (0.1108)  loss_tome: 0.1736 (0.1075)  etrr_loss: 0.0039 (0.0108)  loss_flops: 0.2406 (0.1146)  flops: 2.9905 (2.8175)  grad_norm: 0.0004 (0.0010)  time: 0.4314  data: 0.0003  max mem: 10398
[2024-06-05 17:58:13 root] (utils.py 285): INFO Epoch: [0]  [ 540/5004]  eta: 0:34:14  lr_architecture: 0.010000  loss_cls: 3.0812 (3.1489)  loss_etrr_per_merge: 0.1621 (0.1117)  loss_tome: 0.1736 (0.1087)  etrr_loss: 0.0034 (0.0107)  loss_flops: 0.2592 (0.1173)  flops: 3.0091 (2.8210)  grad_norm: 0.0004 (0.0010)  time: 0.4318  data: 0.0004  max mem: 10398
[2024-06-05 17:58:17 root] (utils.py 285): INFO Epoch: [0]  [ 550/5004]  eta: 0:34:08  lr_architecture: 0.010000  loss_cls: 3.1284 (3.1473)  loss_etrr_per_merge: 0.1621 (0.1126)  loss_tome: 0.1736 (0.1099)  etrr_loss: 0.0034 (0.0105)  loss_flops: 0.2592 (0.1198)  flops: 3.0091 (2.8244)  grad_norm: 0.0004 (0.0010)  time: 0.4320  data: 0.0004  max mem: 10398
[2024-06-05 17:58:21 root] (utils.py 285): INFO Epoch: [0]  [ 560/5004]  eta: 0:34:01  lr_architecture: 0.010000  loss_cls: 3.3555 (3.1498)  loss_etrr_per_merge: 0.1621 (0.1135)  loss_tome: 0.1736 (0.1110)  etrr_loss: 0.0034 (0.0104)  loss_flops: 0.2593 (0.1223)  flops: 3.0092 (2.8276)  grad_norm: 0.0005 (0.0010)  time: 0.4314  data: 0.0004  max mem: 10399
[2024-06-05 17:58:26 root] (utils.py 285): INFO Epoch: [0]  [ 570/5004]  eta: 0:33:54  lr_architecture: 0.010000  loss_cls: 3.3705 (3.1494)  loss_etrr_per_merge: 0.1628 (0.1144)  loss_tome: 0.1736 (0.1121)  etrr_loss: 0.0032 (0.0103)  loss_flops: 0.2654 (0.1251)  flops: 3.0152 (2.8312)  grad_norm: 0.0004 (0.0010)  time: 0.4311  data: 0.0004  max mem: 10402
[2024-06-05 17:58:30 root] (utils.py 285): INFO Epoch: [0]  [ 580/5004]  eta: 0:33:47  lr_architecture: 0.010000  loss_cls: 3.2251 (3.1486)  loss_etrr_per_merge: 0.1658 (0.1153)  loss_tome: 0.1736 (0.1132)  etrr_loss: 0.0027 (0.0102)  loss_flops: 0.2944 (0.1281)  flops: 3.0426 (2.8350)  grad_norm: 0.0004 (0.0010)  time: 0.4314  data: 0.0004  max mem: 10402
[2024-06-05 17:58:34 root] (utils.py 285): INFO Epoch: [0]  [ 590/5004]  eta: 0:33:41  lr_architecture: 0.010000  loss_cls: 3.1681 (3.1475)  loss_etrr_per_merge: 0.1672 (0.1162)  loss_tome: 0.1736 (0.1142)  etrr_loss: 0.0024 (0.0100)  loss_flops: 0.3084 (0.1314)  flops: 3.0553 (2.8389)  grad_norm: 0.0004 (0.0009)  time: 0.4315  data: 0.0004  max mem: 10404
[2024-06-05 17:58:39 root] (engine.py 138): INFO merge kept number:[197, 197, 178, 159, 141, 122, 122, 91, 101, 91, 91, 101]
[2024-06-05 17:58:39 root] (utils.py 285): INFO Epoch: [0]  [ 600/5004]  eta: 0:33:34  lr_architecture: 0.010000  loss_cls: 3.0692 (3.1442)  loss_etrr_per_merge: 0.1701 (0.1171)  loss_tome: 0.1736 (0.1152)  etrr_loss: 0.0019 (0.0099)  loss_flops: 0.3374 (0.1351)  flops: 3.0809 (2.8431)  grad_norm: 0.0003 (0.0009)  time: 0.4315  data: 0.0004  max mem: 10405
